[
  {
    "objectID": "trabajos.html",
    "href": "trabajos.html",
    "title": "Trabajos",
    "section": "",
    "text": "Proximamente…"
  },
  {
    "objectID": "slides/ejemplo.html#correlacional",
    "href": "slides/ejemplo.html#correlacional",
    "title": "Cohesión barrial",
    "section": "Correlacional",
    "text": "Correlacional\nAcá correlacional o bivariados"
  },
  {
    "objectID": "slides/ejemplo.html#regresiones",
    "href": "slides/ejemplo.html#regresiones",
    "title": "Cohesión barrial",
    "section": "Regresiones",
    "text": "Regresiones\n\n\nEl gráfico muestra que por cada año que aumenta la edad, la variable dependiente aumenta en 0.05 unidades, con un 99% de confianza."
  },
  {
    "objectID": "slides/ejemplo.html#conclusión",
    "href": "slides/ejemplo.html#conclusión",
    "title": "Cohesión barrial",
    "section": "Conclusión",
    "text": "Conclusión\n\n\nEn esta investigación quisimos demostrar…\nNuestros principales resultados indican que…"
  },
  {
    "objectID": "slides/01-clase1/01-clase1.html#section",
    "href": "slides/01-clase1/01-clase1.html#section",
    "title": "Estadística IV",
    "section": "",
    "text": "Introducción al flujo de investigación reproducible\n\nEstadística IV\n\nUniversidad Alberto Hurtado\nKevin Carrasco - COES"
  },
  {
    "objectID": "slides/01-clase1/01-clase1.html#ciencia-abierta",
    "href": "slides/01-clase1/01-clase1.html#ciencia-abierta",
    "title": "Estadística IV",
    "section": "Ciencia abierta",
    "text": "Ciencia abierta"
  },
  {
    "objectID": "slides/01-clase1/01-clase1.html#sitio-web",
    "href": "slides/01-clase1/01-clase1.html#sitio-web",
    "title": "Estadística IV",
    "section": "Sitio web",
    "text": "Sitio web"
  },
  {
    "objectID": "slides/01-clase1/01-clase1.html#reproducibilidad",
    "href": "slides/01-clase1/01-clase1.html#reproducibilidad",
    "title": "Estadística IV",
    "section": "Reproducibilidad",
    "text": "Reproducibilidad\n\nEs la posibilidad de regenerar de manera independiente los resultados usando los materiales originales de una investigación ya publicada.\nEn términos simples: obtener los mismos resultados de una investigación utilizando los mismos datos."
  },
  {
    "objectID": "slides/01-clase1/01-clase1.html#qué-porcentaje-de-los-estudios-publicados-son-reproducibles",
    "href": "slides/01-clase1/01-clase1.html#qué-porcentaje-de-los-estudios-publicados-son-reproducibles",
    "title": "Estadística IV",
    "section": "¿Qué porcentaje de los estudios publicados son reproducibles?",
    "text": "¿Qué porcentaje de los estudios publicados son reproducibles?\n\n\n\n\nAlrededor de un 40%! dependiendo de la disciplina"
  },
  {
    "objectID": "slides/01-clase1/01-clase1.html#hay-crisis-de-reproducibilidad",
    "href": "slides/01-clase1/01-clase1.html#hay-crisis-de-reproducibilidad",
    "title": "Estadística IV",
    "section": "¿Hay crisis de reproducibilidad?",
    "text": "¿Hay crisis de reproducibilidad?\n\n\n\n\nFuente: Baker (2016) 1,500 scientists lift the lid on reproducibility - Nature"
  },
  {
    "objectID": "slides/01-clase1/01-clase1.html#y-en-la-práctica-cómo-afecta-la-reproducibilidad",
    "href": "slides/01-clase1/01-clase1.html#y-en-la-práctica-cómo-afecta-la-reproducibilidad",
    "title": "Estadística IV",
    "section": "¿y en la práctica cómo afecta la reproducibilidad?",
    "text": "¿y en la práctica cómo afecta la reproducibilidad?\n\n\n\n\nBreznau, et. al, (2023) coordinó una investigación con 161 investigadores de 73 equipos de investigación.\nLos equipos informaron tanto hallazgos numéricos como conclusiones sustanciales muy diversas"
  },
  {
    "objectID": "slides/01-clase1/01-clase1.html#alternativas",
    "href": "slides/01-clase1/01-clase1.html#alternativas",
    "title": "Estadística IV",
    "section": "Alternativas",
    "text": "Alternativas\n\n\n\nA. ad-hoc\n\ncada investigador define numero de archivos, nombres, carpetas y organización\nexplicar al resto cómo se organiza\ndocumentar en un archivo cómo se organiza\n\n–&gt; reproducibilidad y transparencia LIMITADA\n\n\n\nB. Protocolo reproducible\n\nestructura de carpetas y archivos interconectados que refieren a reglas conocidas (estándares)\nautocontenido: toda la información necesaria para la reproducibilidad se encuentra en la carpeta raíz o directorio de trabajo."
  },
  {
    "objectID": "slides/01-clase1/01-clase1.html#propuesta-protocolo-ipo",
    "href": "slides/01-clase1/01-clase1.html#propuesta-protocolo-ipo",
    "title": "Estadística IV",
    "section": "Propuesta: Protocolo IPO",
    "text": "Propuesta: Protocolo IPO"
  },
  {
    "objectID": "slides/01-clase1/01-clase1.html#estructura-ipo",
    "href": "slides/01-clase1/01-clase1.html#estructura-ipo",
    "title": "Estadística IV",
    "section": "Estructura IPO",
    "text": "Estructura IPO"
  },
  {
    "objectID": "slides/01-clase1/01-clase1.html#mayores-detalles-y-plantilla-de-carpetas",
    "href": "slides/01-clase1/01-clase1.html#mayores-detalles-y-plantilla-de-carpetas",
    "title": "Estadística IV",
    "section": "Mayores detalles y plantilla de carpetas:",
    "text": "Mayores detalles y plantilla de carpetas:\n\nhttps://lisa-coes.com/ipo-repro/\nhttps://github.com/lisa-coes/ipo"
  },
  {
    "objectID": "slides/01-clase1/01-clase1.html#carpeta-autocontenida",
    "href": "slides/01-clase1/01-clase1.html#carpeta-autocontenida",
    "title": "Estadística IV",
    "section": "Carpeta autocontenida",
    "text": "Carpeta autocontenida\n\nproyecto autocontenido: reproducible sin necesidad de archivos externos\nrequisito: establecer directorio de trabajo\n\nposición de referencia de todas las operaciones al interior del proyecto\ntambién llamado directorio raíz"
  },
  {
    "objectID": "slides/01-clase1/01-clase1.html#directorio-de-trabajo",
    "href": "slides/01-clase1/01-clase1.html#directorio-de-trabajo",
    "title": "Estadística IV",
    "section": "Directorio de trabajo",
    "text": "Directorio de trabajo\n\nej. forma tradicional en hoja de código R:\n\nsetwd(ruta-a-carpeta-de-proyecto)\nproblemas: hace referencia a ruta local en el computador donde se está trabajando, por lo tanto no es reproducible y se debe evitar\n\nalternativa sugerida en R: RStudio Projects"
  },
  {
    "objectID": "slides/01-clase1/01-clase1.html#rstudio-projects",
    "href": "slides/01-clase1/01-clase1.html#rstudio-projects",
    "title": "Estadística IV",
    "section": "RStudio Projects",
    "text": "RStudio Projects\n\nLa funcionalidad Projects de RStudio permite establecer claramente un directorio de trabajo de manera eficiente\nPara ello, genera un archivo de extensión .Rproj en el directorio raiz de la carpeta del proyecto\nLuego se facilita acceder a la carpeta del proyecto en RStudio ejecutando desde el administrador de archivos del computador (file manager) el archivo .Rproj\npara comprobar, ejecutar getwd() y debería dar la ruta hacia la carpeta del proyecto"
  },
  {
    "objectID": "slides/01-clase1/01-clase1.html#section-3",
    "href": "slides/01-clase1/01-clase1.html#section-3",
    "title": "Estadística IV",
    "section": "",
    "text": "La escritura en texto simple (como Markdown o Quarto) permite implementar un sistema de control de versiones, además de herramientas de respaldo, colaboración y comunicación"
  },
  {
    "objectID": "slides/01-clase1/01-clase1.html#el-origen-abriendo-un-sistema-operativo",
    "href": "slides/01-clase1/01-clase1.html#el-origen-abriendo-un-sistema-operativo",
    "title": "Estadística IV",
    "section": "El origen: Abriendo un sistema operativo",
    "text": "El origen: Abriendo un sistema operativo\n\n\n\n\n\nLinus Torvalds, 1991 (21 años)\nCrea sistema operativo libre (Linux) y lo abre a la colaboración. Postea:\n\n“I’m doing a (free) operating system (just a hobby, won’t be big and professional…”\n\nTED talk"
  },
  {
    "objectID": "slides/01-clase1/01-clase1.html#git",
    "href": "slides/01-clase1/01-clase1.html#git",
    "title": "Estadística IV",
    "section": "Git",
    "text": "Git\n\n\n\n\n\nes una especie de memoria o registro local que guarda información sobre:\n\nquién hizo un cambio\ncuándo lo hizo\nqué hizo\n\nmantiene la información de todos los cambios en la historia de la carpeta / repositorio local\nse puede sincronizar con un repositorio remoto (ej. Github)"
  },
  {
    "objectID": "slides/01-clase1/01-clase1.html#gitgithub",
    "href": "slides/01-clase1/01-clase1.html#gitgithub",
    "title": "Estadística IV",
    "section": "Git/github",
    "text": "Git/github\n\nactualmente, Git / Github posee más de 100 millones de repositorios\nmayor fuente de código en el mundo\nha transitado desde el mundo de desarrollo de software hacia distintos ámbitos de trabajo colaborativo y abierto\nentorno de trabajo que favorece la ciencia abierta"
  },
  {
    "objectID": "slides/01-clase1/01-clase1.html#section-4",
    "href": "slides/01-clase1/01-clase1.html#section-4",
    "title": "Estadística IV",
    "section": "",
    "text": "Git no es un registro de versiones de archivos específicos, sino de una carpeta completa\nGuarda “fotos” de momentos específicos de la carpeta, y esta foto se saca mediante un commit"
  },
  {
    "objectID": "slides/01-clase1/01-clase1.html#commits",
    "href": "slides/01-clase1/01-clase1.html#commits",
    "title": "Estadística IV",
    "section": "Commits",
    "text": "Commits\n\nEl commit es el procedimiento fundamental del control de versiones\nGit no registra cualquier cambio que se “guarda”, sino los que se “comprometen” (commit).\nEn un commit\n\nse seleccionan los archivos cuyo cambio se desea registrar (stage)\nse registra lo que se está comprometiendo en el cambio (mensaje de commit)"
  },
  {
    "objectID": "slides/01-clase1/01-clase1.html#cuándo-hacer-un-commit",
    "href": "slides/01-clase1/01-clase1.html#cuándo-hacer-un-commit",
    "title": "Estadística IV",
    "section": "¿Cuándo hacer un commit?",
    "text": "¿Cuándo hacer un commit?\n\nsegún conveniencia\nsugerencias:\n\nque sea un momento que requiera registro (momento de foto)\nno para cambios menores\nno esperar muchos cambios distintos que puedan hacer perder el sentido del commit"
  },
  {
    "objectID": "slides/01-clase1/01-clase1.html#section-6",
    "href": "slides/01-clase1/01-clase1.html#section-6",
    "title": "Estadística IV",
    "section": "",
    "text": "Introducción al flujo de investigación reproducible\n\nEstadística IV\n\nUniversidad Alberto Hurtado\nKevin Carrasco - COES"
  },
  {
    "objectID": "practicos/index.html",
    "href": "practicos/index.html",
    "title": "Actividades prácticas en R",
    "section": "",
    "text": "En esta sección encontrarán todas las sesiones prácticas de R, realizadas durante el segundo bloque de clases, y que son fundamentales para la correcta realización de los trabajos."
  },
  {
    "objectID": "practicos/06-content.html",
    "href": "practicos/06-content.html",
    "title": "Práctico 6. Análisis factorial Exploratorio",
    "section": "",
    "text": "Para el taller práctico de hoy utilizaremos la base de datos del Estudio Longitudinal Social de Chile, realizado por el Centro de estudios del conflicto y la cohesión social COES.\nEl Estudio Longitudinal Social del Chile ELSOC, único en Chile y América Latina, consiste en encuestar a casi 3.000 chilenos, anualmente, a lo largo de una década. ELSOC ha sido diseñado para evaluar la manera cómo piensan, sienten y se comportan los chilenos en torno a un conjunto de temas referidos al conflicto y la cohesión social en Chile. La población objetivo son hombres y mujeres entre 15 y 75 años de edad, tiene una representación de la población nacional urbana, donde se obtuvo una muestra original de 2927 casos en el año 2016 y mantiene 1728 en 2022, además de una muestra de refresco en 2018.\n\n\n\nEl objetivo de este ejercicio práctico es comprender y estimar un análisis factorial exploratorio con el fin de reducir la dimensionalidad de una batería de variables.\n\n\n\n\n\nCódigo\npacman::p_load(tidyverse, #Conjunto de paquetes, sobre todo dplyr y ggplot2\n               car, #Para recodificar\n               haven,\n               summarytools, #Para descriptivos\n               sjmisc,\n               psych,     # para Alfa de Chronbach\n               sjPlot,\n               psy, # scree plot function\n               nFactors, # parallel\n               GPArotation, # Rotación\n               sjlabelled)\n\noptions(scipen = 999) # para desactivar notacion cientifica\nrm(list = ls()) # para limpiar el entorno de trabajo\n\n\n\n\n\n\nCódigo\nload(url(\"https://dataverse.harvard.edu/api/access/datafile/7245118\")) #Cargar base de datos\n\n\n\n\n\n\n\nCódigo\ndim(elsoc_long_2016_2022.2)\n\n\n[1] 18035   750\n\n\nDebido a la naturaleza longitudinal de ELSOC, la base de datos contiene 18035 casos (las mismas personas durante 6 años) y 750 variables (las mismas variables en 6 periodos distintos). Por lo tanto, para simplificar el proceso de análisis de este práctico trabajaremos solo con los casos y variables de quienes participaron en la cuarta ola (2019)\n\n\n\n\nPara estimar AFE, utilizaremos específicamente el módulo de Ciudadanía. De este módulo utilizaremos un concepto en particular llamado Confianza en instituciones con los ítems:\n\nGrado de acuerdo: Mujeres son mas refinadas\nGrado de acuerdo: Mujeres deberian ser protegidas\nGrado de acuerdo: Mujeres consiguen privilegios en nombre de igualdad\nGrado de acuerdo: Mujeres derrotadas se quejan de discriminacion\n\nLa idea general es ver si esque todas estas variables miden algún tipo de Confianza en instituciones o si esque existen dimensiones subyacentes.\n\n\n\nFiltraremos la base de datos para quedarnos con las observaciones correspondientes solamente a la ola 4, y además seleccionaremos los ítems de interés.\n\n\nCódigo\ndata &lt;- elsoc_long_2016_2022.2 %&gt;% filter(ola==4) %&gt;%  # seleccionamos solo los casos de la ola 1\n  select(son_refinadas=g01_01,\n         ser_protegidas=g01_02,\n         consiguen_privilegios=g01_03,\n         quejan_discriminacion=g01_04\n         )\n\nhead(data)\n\n\n  son_refinadas ser_protegidas consiguen_privilegios quejan_discriminacion\n1             5              4                     4                     4\n2             4              5                     5                     2\n3             4              5                     4                     4\n4             3              4                     3                     4\n5             4              4                     4                     4\n6             4              4                     4                     4\n\n\nCódigo\ntable(data$son_refinadas)\n\n\n\n-999 -888    1    2    3    4    5 \n   6   15  108  473  590 1731  494 \n\n\nCódigo\ntable(data$ser_protegidas)\n\n\n\n-999 -888    1    2    3    4    5 \n   2    1   35  148  244 1784 1203 \n\n\nCódigo\ntable(data$consiguen_privilegios)\n\n\n\n-999 -888    1    2    3    4    5 \n   4   57   79  487  611 1887  292 \n\n\nCódigo\ntable(data$quejan_discriminacion)\n\n\n\n-999 -888    1    2    3    4    5 \n   8   64  106  717  669 1641  212 \n\n\nEstos ítems cuentan con las mismas categorías de respuesta: (1) totalmente desacuerdo, a (5) Totalmente de acuerdo. Además de los valores codificados como -888 y -999.\n\n\nRecodificamos los valores -888 y -999 en NA y eliminamos los NAs.\n\n\nCódigo\ndata$son_refinadas &lt;- car::recode(data$son_refinadas, \"c(-999,-888)=NA\")\ndata$ser_protegidas &lt;- car::recode(data$ser_protegidas, \"c(-999,-888)=NA\")\ndata$consiguen_privilegios &lt;- car::recode(data$consiguen_privilegios, \"c(-999,-888)=NA\")\ndata$quejan_discriminacion &lt;- car::recode(data$quejan_discriminacion, \"c(-999,-888)=NA\")\n\ndata$son_refinadas &lt;- set_labels(data$son_refinadas,\n            labels=c( \"Totalmente desacuerdo\"=1,\n                      \"Desacuerdo\"=2,\n                      \"Ni de acuerdo ni desacuerdo\"=3,\n                      \"De acuerdo\"=4,\n                      \"Totalmente de acuerdo\"=5))\n\ndata$ser_protegidas &lt;- set_labels(data$ser_protegidas,\n            labels=c( \"Totalmente desacuerdo\"=1,\n                      \"Desacuerdo\"=2,\n                      \"Ni de acuerdo ni desacuerdo\"=3,\n                      \"De acuerdo\"=4,\n                      \"Totalmente de acuerdo\"=5))\n\ndata$consiguen_privilegios &lt;- set_labels(data$consiguen_privilegios,\n            labels=c( \"Totalmente desacuerdo\"=1,\n                      \"Desacuerdo\"=2,\n                      \"Ni de acuerdo ni desacuerdo\"=3,\n                      \"De acuerdo\"=4,\n                      \"Totalmente de acuerdo\"=5))\n\ndata$quejan_discriminacion &lt;- set_labels(data$quejan_discriminacion,\n            labels=c( \"Totalmente desacuerdo\"=1,\n                      \"Desacuerdo\"=2,\n                      \"Ni de acuerdo ni desacuerdo\"=3,\n                      \"De acuerdo\"=4,\n                      \"Totalmente de acuerdo\"=5))\n\n\n\n\n\n\n\n\nCódigo\ndata %&gt;% \n  plot_stackfrq() + theme(legend.position=\"bottom\")\n\n\n\n\n\n\n\n\n\nCódigo\ntab_corr(data, triangle = \"lower\")\n\n\n\n\n\n\n\n\n\n\n\n\n \nGrado de acuerdo: Mujeres son mas\nrefinadas\nGrado de acuerdo: Mujeres deberian ser\nprotegidas\nGrado de acuerdo: Mujeres consiguen\nprivilegios en nombre de igualdad\nGrado de acuerdo: Mujeres derrotadas se\nquejan de discriminacion\n\n\nGrado de acuerdo: Mujeres son mas\nrefinadas\n \n \n \n \n\n\nGrado de acuerdo: Mujeres deberian ser\nprotegidas\n0.364***\n \n \n \n\n\nGrado de acuerdo: Mujeres consiguen\nprivilegios en nombre de igualdad\n0.224***\n0.199***\n \n \n\n\nGrado de acuerdo: Mujeres derrotadas se\nquejan de discriminacion\n0.183***\n0.163***\n0.453***\n \n\n\nComputed correlation used pearson-method with listwise-deletion.\n\n\n\n\n\nPodemos observar que todas las correlaciones son positivas, por lo que no quedaron ítems invertidos.\n\n\n\n\n¿Qué se puede deducir de la matriz de correlaciones en relación a la estructura subyacente en términos de variables latentes? No hay claridad de grupos de indicadores asociados entre sí.\n\n\nKMO (Kaiser, Meyer, Olkin Measure of Sampling Adequacy):\n\nVaría entre 0 y 1. Contrasta si las correlaciones parciales entre las variables son pequeñas\nValores pequeños (menores a 0.5) indican que los datos no serían adecuados para AFE, ya que las correlaciones entre pares de variables no pueden ser explicadas por otras variables.\n\n\n\nCódigo\ncorMat  &lt;- data %&gt;% \n  cor(use = \"complete.obs\")  # estimar matriz pearson\n\nKMO(corMat)\n\n\nKaiser-Meyer-Olkin factor adequacy\nCall: KMO(r = corMat)\nOverall MSA =  0.61\nMSA for each item = \n        son_refinadas        ser_protegidas consiguen_privilegios \n                 0.63                  0.62                  0.59 \nquejan_discriminacion \n                 0.59 \n\n\nEn este caso las correlaciones son altas, por lo que los datos sí son adecuados para AFE.\n\n\n\nSe utiliza para evluar la hipótesis que la matriz de correlaciones es una matriz identidad (diagonal=1 y bajo la diagonal=0)\n\nSe busca significación (p &lt; 0.05) ya que se espera que las variables estén correlacionadas\n\n\n\nCódigo\ncortest.bartlett(corMat, n = 3417)\n\n\n$chisq\n[1] 1542.697\n\n$p.value\n[1] 0\n\n$df\n[1] 6\n\n\nEn este caso el valor p es 0, así que hay significación estadística\n\n\n\n\n\nCódigo\nscree.plot(data)\n\n\n\n\n\n\n\nCódigo\nfa.parallel(corMat, n.obs=3417)\n\n\n\n\n\nParallel analysis suggests that the number of factors =  2  and the number of components =  2 \n\n\n\n\n\n\nejes principales\n\n\n\nCódigo\nfac_pa &lt;- fa(r = data, nfactors = 2, fm= \"pa\")\n#summary(fac_pa)\nfac_pa\n\n\nFactor Analysis using method =  pa\nCall: fa(r = data, nfactors = 2, fm = \"pa\")\nStandardized loadings (pattern matrix) based upon correlation matrix\n                        PA1   PA2   h2   u2 com\nson_refinadas          0.02  0.60 0.37 0.63   1\nser_protegidas        -0.01  0.60 0.35 0.65   1\nconsiguen_privilegios  0.67  0.03 0.47 0.53   1\nquejan_discriminacion  0.68 -0.03 0.44 0.56   1\n\n                       PA1  PA2\nSS loadings           0.90 0.72\nProportion Var        0.23 0.18\nCumulative Var        0.23 0.41\nProportion Explained  0.56 0.44\nCumulative Proportion 0.56 1.00\n\n With factor correlations of \n     PA1  PA2\nPA1 1.00 0.47\nPA2 0.47 1.00\n\nMean item complexity =  1\nTest of the hypothesis that 2 factors are sufficient.\n\ndf null model =  6  with the objective function =  0.45 with Chi Square =  1522.89\ndf of  the model are -1  and the objective function was  0 \n\nThe root mean square of the residuals (RMSR) is  0 \nThe df corrected root mean square of the residuals is  NA \n\nThe harmonic n.obs is  3354 with the empirical chi square  0.01  with prob &lt;  NA \nThe total n.obs was  3417  with Likelihood Chi Square =  0.01  with prob &lt;  NA \n\nTucker Lewis Index of factoring reliability =  1.004\nFit based upon off diagonal values = 1\nMeasures of factor score adequacy             \n                                                   PA1  PA2\nCorrelation of (regression) scores with factors   0.80 0.75\nMultiple R square of scores with factors          0.64 0.56\nMinimum correlation of possible factor scores     0.28 0.13\n\n\n\nMaximum likelihood\n\nMaximiza la posibilidad de que los parámetros reproduzcan los datos observados\n\n\nCódigo\nfac_ml &lt;- fa(r = data, nfactors = 2, fm= \"ml\")\nfac_ml\n\n\nFactor Analysis using method =  ml\nCall: fa(r = data, nfactors = 2, fm = \"ml\")\nStandardized loadings (pattern matrix) based upon correlation matrix\n                        ML1   ML2   h2   u2 com\nson_refinadas          0.01  0.62 0.38 0.62   1\nser_protegidas        -0.01  0.58 0.34 0.66   1\nconsiguen_privilegios  0.67  0.03 0.47 0.53   1\nquejan_discriminacion  0.68 -0.03 0.44 0.56   1\n\n                       ML1  ML2\nSS loadings           0.90 0.72\nProportion Var        0.23 0.18\nCumulative Var        0.23 0.41\nProportion Explained  0.56 0.44\nCumulative Proportion 0.56 1.00\n\n With factor correlations of \n     ML1  ML2\nML1 1.00 0.47\nML2 0.47 1.00\n\nMean item complexity =  1\nTest of the hypothesis that 2 factors are sufficient.\n\ndf null model =  6  with the objective function =  0.45 with Chi Square =  1522.89\ndf of  the model are -1  and the objective function was  0 \n\nThe root mean square of the residuals (RMSR) is  0 \nThe df corrected root mean square of the residuals is  NA \n\nThe harmonic n.obs is  3354 with the empirical chi square  0  with prob &lt;  NA \nThe total n.obs was  3417  with Likelihood Chi Square =  0  with prob &lt;  NA \n\nTucker Lewis Index of factoring reliability =  1.004\nFit based upon off diagonal values = 1\nMeasures of factor score adequacy             \n                                                   ML1  ML2\nCorrelation of (regression) scores with factors   0.80 0.75\nMultiple R square of scores with factors          0.64 0.56\nMinimum correlation of possible factor scores     0.28 0.13\n\n\n\n\n\n\nVarimax (ortogonal)\n\n\n\nCódigo\nfac_ml_var &lt;- fa(r = data, nfactors = 2, fm= \"ml\", rotate=\"varimax\") # ortogonal\nfac_ml_var\n\n\nFactor Analysis using method =  ml\nCall: fa(r = data, nfactors = 2, rotate = \"varimax\", fm = \"ml\")\nStandardized loadings (pattern matrix) based upon correlation matrix\n                       ML1  ML2   h2   u2 com\nson_refinadas         0.14 0.60 0.38 0.62 1.1\nser_protegidas        0.12 0.57 0.34 0.66 1.1\nconsiguen_privilegios 0.65 0.21 0.47 0.53 1.2\nquejan_discriminacion 0.65 0.15 0.44 0.56 1.1\n\n                       ML1  ML2\nSS loadings           0.88 0.75\nProportion Var        0.22 0.19\nCumulative Var        0.22 0.41\nProportion Explained  0.54 0.46\nCumulative Proportion 0.54 1.00\n\nMean item complexity =  1.1\nTest of the hypothesis that 2 factors are sufficient.\n\ndf null model =  6  with the objective function =  0.45 with Chi Square =  1522.89\ndf of  the model are -1  and the objective function was  0 \n\nThe root mean square of the residuals (RMSR) is  0 \nThe df corrected root mean square of the residuals is  NA \n\nThe harmonic n.obs is  3354 with the empirical chi square  0  with prob &lt;  NA \nThe total n.obs was  3417  with Likelihood Chi Square =  0  with prob &lt;  NA \n\nTucker Lewis Index of factoring reliability =  1.004\nFit based upon off diagonal values = 1\nMeasures of factor score adequacy             \n                                                   ML1  ML2\nCorrelation of (regression) scores with factors   0.76 0.71\nMultiple R square of scores with factors          0.58 0.51\nMinimum correlation of possible factor scores     0.17 0.01\n\n\n\nPromax (oblicua)\n\n\n\nCódigo\nfac_ml_pro &lt;- fa(r = data, nfactors = 2, fm= \"ml\", rotate=\"promax\")\nfac_ml_pro\n\n\nFactor Analysis using method =  ml\nCall: fa(r = data, nfactors = 2, rotate = \"promax\", fm = \"ml\")\nStandardized loadings (pattern matrix) based upon correlation matrix\n                        ML1   ML2   h2   u2 com\nson_refinadas          0.01  0.62 0.38 0.62   1\nser_protegidas        -0.01  0.58 0.34 0.66   1\nconsiguen_privilegios  0.67  0.04 0.47 0.53   1\nquejan_discriminacion  0.67 -0.03 0.44 0.56   1\n\n                       ML1  ML2\nSS loadings           0.90 0.73\nProportion Var        0.23 0.18\nCumulative Var        0.23 0.41\nProportion Explained  0.55 0.45\nCumulative Proportion 0.55 1.00\n\n With factor correlations of \n     ML1  ML2\nML1 1.00 0.47\nML2 0.47 1.00\n\nMean item complexity =  1\nTest of the hypothesis that 2 factors are sufficient.\n\ndf null model =  6  with the objective function =  0.45 with Chi Square =  1522.89\ndf of  the model are -1  and the objective function was  0 \n\nThe root mean square of the residuals (RMSR) is  0 \nThe df corrected root mean square of the residuals is  NA \n\nThe harmonic n.obs is  3354 with the empirical chi square  0  with prob &lt;  NA \nThe total n.obs was  3417  with Likelihood Chi Square =  0  with prob &lt;  NA \n\nTucker Lewis Index of factoring reliability =  1.004\nFit based upon off diagonal values = 1\nMeasures of factor score adequacy             \n                                                   ML1  ML2\nCorrelation of (regression) scores with factors   0.80 0.75\nMultiple R square of scores with factors          0.64 0.56\nMinimum correlation of possible factor scores     0.28 0.13\n\n\n\n\n\n\n\nCódigo\nsjPlot::tab_fa(data, method = \"ml\", rotation = \"promax\", show.comm = TRUE, title = \"Análisis factorial de sexismo\")\n\n\nParallel analysis suggests that the number of factors =  2  and the number of components =  NA \n\n\n\nAnálisis factorial de sexismo\n\n\n\n\n\n\n\n\n \nFactor 1\nFactor 2\nCommunality\n\n\nGrado de acuerdo: Mujeres son mas\nrefinadas\n0.01\n0.62\n0.38\n\n\nGrado de acuerdo: Mujeres deberian ser\nprotegidas\n-0.01\n0.58\n0.34\n\n\nGrado de acuerdo: Mujeres consiguen\nprivilegios en nombre de igualdad\n0.67\n0.04\n0.47\n\n\nGrado de acuerdo: Mujeres derrotadas se\nquejan de discriminacion\n0.67\n-0.03\n0.44\n\n\nTotal Communalities\n\n1.63\n\n\nCronbach's α\n0.62\n0.52\n\n\n\n\n\n\nLuego de realizar el Análisis factorial exploratorio existen varias alternativas sobre los pasos a seguir. Por ejemplo, es posible estimar un promedio simple entre cada una de las variables de los factores. Otra opción es estimar puntajes factoriales."
  },
  {
    "objectID": "practicos/06-content.html#presentación",
    "href": "practicos/06-content.html#presentación",
    "title": "Práctico 6. Análisis factorial Exploratorio",
    "section": "",
    "text": "Para el taller práctico de hoy utilizaremos la base de datos del Estudio Longitudinal Social de Chile, realizado por el Centro de estudios del conflicto y la cohesión social COES.\nEl Estudio Longitudinal Social del Chile ELSOC, único en Chile y América Latina, consiste en encuestar a casi 3.000 chilenos, anualmente, a lo largo de una década. ELSOC ha sido diseñado para evaluar la manera cómo piensan, sienten y se comportan los chilenos en torno a un conjunto de temas referidos al conflicto y la cohesión social en Chile. La población objetivo son hombres y mujeres entre 15 y 75 años de edad, tiene una representación de la población nacional urbana, donde se obtuvo una muestra original de 2927 casos en el año 2016 y mantiene 1728 en 2022, además de una muestra de refresco en 2018."
  },
  {
    "objectID": "practicos/06-content.html#objetivo-general",
    "href": "practicos/06-content.html#objetivo-general",
    "title": "Práctico 6. Análisis factorial Exploratorio",
    "section": "",
    "text": "El objetivo de este ejercicio práctico es comprender y estimar un análisis factorial exploratorio con el fin de reducir la dimensionalidad de una batería de variables."
  },
  {
    "objectID": "practicos/06-content.html#cargar-paquetes",
    "href": "practicos/06-content.html#cargar-paquetes",
    "title": "Práctico 6. Análisis factorial Exploratorio",
    "section": "",
    "text": "Código\npacman::p_load(tidyverse, #Conjunto de paquetes, sobre todo dplyr y ggplot2\n               car, #Para recodificar\n               haven,\n               summarytools, #Para descriptivos\n               sjmisc,\n               psych,     # para Alfa de Chronbach\n               sjPlot,\n               psy, # scree plot function\n               nFactors, # parallel\n               GPArotation, # Rotación\n               sjlabelled)\n\noptions(scipen = 999) # para desactivar notacion cientifica\nrm(list = ls()) # para limpiar el entorno de trabajo\n\n\n\n\n\n\nCódigo\nload(url(\"https://dataverse.harvard.edu/api/access/datafile/7245118\")) #Cargar base de datos\n\n\n\n\n\n\n\nCódigo\ndim(elsoc_long_2016_2022.2)\n\n\n[1] 18035   750\n\n\nDebido a la naturaleza longitudinal de ELSOC, la base de datos contiene 18035 casos (las mismas personas durante 6 años) y 750 variables (las mismas variables en 6 periodos distintos). Por lo tanto, para simplificar el proceso de análisis de este práctico trabajaremos solo con los casos y variables de quienes participaron en la cuarta ola (2019)"
  },
  {
    "objectID": "practicos/06-content.html#datos-y-variables",
    "href": "practicos/06-content.html#datos-y-variables",
    "title": "Práctico 6. Análisis factorial Exploratorio",
    "section": "",
    "text": "Para estimar AFE, utilizaremos específicamente el módulo de Ciudadanía. De este módulo utilizaremos un concepto en particular llamado Confianza en instituciones con los ítems:\n\nGrado de acuerdo: Mujeres son mas refinadas\nGrado de acuerdo: Mujeres deberian ser protegidas\nGrado de acuerdo: Mujeres consiguen privilegios en nombre de igualdad\nGrado de acuerdo: Mujeres derrotadas se quejan de discriminacion\n\nLa idea general es ver si esque todas estas variables miden algún tipo de Confianza en instituciones o si esque existen dimensiones subyacentes."
  },
  {
    "objectID": "practicos/06-content.html#filtrar-base-de-datos",
    "href": "practicos/06-content.html#filtrar-base-de-datos",
    "title": "Práctico 6. Análisis factorial Exploratorio",
    "section": "",
    "text": "Filtraremos la base de datos para quedarnos con las observaciones correspondientes solamente a la ola 4, y además seleccionaremos los ítems de interés.\n\n\nCódigo\ndata &lt;- elsoc_long_2016_2022.2 %&gt;% filter(ola==4) %&gt;%  # seleccionamos solo los casos de la ola 1\n  select(son_refinadas=g01_01,\n         ser_protegidas=g01_02,\n         consiguen_privilegios=g01_03,\n         quejan_discriminacion=g01_04\n         )\n\nhead(data)\n\n\n  son_refinadas ser_protegidas consiguen_privilegios quejan_discriminacion\n1             5              4                     4                     4\n2             4              5                     5                     2\n3             4              5                     4                     4\n4             3              4                     3                     4\n5             4              4                     4                     4\n6             4              4                     4                     4\n\n\nCódigo\ntable(data$son_refinadas)\n\n\n\n-999 -888    1    2    3    4    5 \n   6   15  108  473  590 1731  494 \n\n\nCódigo\ntable(data$ser_protegidas)\n\n\n\n-999 -888    1    2    3    4    5 \n   2    1   35  148  244 1784 1203 \n\n\nCódigo\ntable(data$consiguen_privilegios)\n\n\n\n-999 -888    1    2    3    4    5 \n   4   57   79  487  611 1887  292 \n\n\nCódigo\ntable(data$quejan_discriminacion)\n\n\n\n-999 -888    1    2    3    4    5 \n   8   64  106  717  669 1641  212 \n\n\nEstos ítems cuentan con las mismas categorías de respuesta: (1) totalmente desacuerdo, a (5) Totalmente de acuerdo. Además de los valores codificados como -888 y -999.\n\n\nRecodificamos los valores -888 y -999 en NA y eliminamos los NAs.\n\n\nCódigo\ndata$son_refinadas &lt;- car::recode(data$son_refinadas, \"c(-999,-888)=NA\")\ndata$ser_protegidas &lt;- car::recode(data$ser_protegidas, \"c(-999,-888)=NA\")\ndata$consiguen_privilegios &lt;- car::recode(data$consiguen_privilegios, \"c(-999,-888)=NA\")\ndata$quejan_discriminacion &lt;- car::recode(data$quejan_discriminacion, \"c(-999,-888)=NA\")\n\ndata$son_refinadas &lt;- set_labels(data$son_refinadas,\n            labels=c( \"Totalmente desacuerdo\"=1,\n                      \"Desacuerdo\"=2,\n                      \"Ni de acuerdo ni desacuerdo\"=3,\n                      \"De acuerdo\"=4,\n                      \"Totalmente de acuerdo\"=5))\n\ndata$ser_protegidas &lt;- set_labels(data$ser_protegidas,\n            labels=c( \"Totalmente desacuerdo\"=1,\n                      \"Desacuerdo\"=2,\n                      \"Ni de acuerdo ni desacuerdo\"=3,\n                      \"De acuerdo\"=4,\n                      \"Totalmente de acuerdo\"=5))\n\ndata$consiguen_privilegios &lt;- set_labels(data$consiguen_privilegios,\n            labels=c( \"Totalmente desacuerdo\"=1,\n                      \"Desacuerdo\"=2,\n                      \"Ni de acuerdo ni desacuerdo\"=3,\n                      \"De acuerdo\"=4,\n                      \"Totalmente de acuerdo\"=5))\n\ndata$quejan_discriminacion &lt;- set_labels(data$quejan_discriminacion,\n            labels=c( \"Totalmente desacuerdo\"=1,\n                      \"Desacuerdo\"=2,\n                      \"Ni de acuerdo ni desacuerdo\"=3,\n                      \"De acuerdo\"=4,\n                      \"Totalmente de acuerdo\"=5))"
  },
  {
    "objectID": "practicos/06-content.html#análisis",
    "href": "practicos/06-content.html#análisis",
    "title": "Práctico 6. Análisis factorial Exploratorio",
    "section": "",
    "text": "Código\ndata %&gt;% \n  plot_stackfrq() + theme(legend.position=\"bottom\")\n\n\n\n\n\n\n\n\n\nCódigo\ntab_corr(data, triangle = \"lower\")\n\n\n\n\n\n\n\n\n\n\n\n\n \nGrado de acuerdo: Mujeres son mas\nrefinadas\nGrado de acuerdo: Mujeres deberian ser\nprotegidas\nGrado de acuerdo: Mujeres consiguen\nprivilegios en nombre de igualdad\nGrado de acuerdo: Mujeres derrotadas se\nquejan de discriminacion\n\n\nGrado de acuerdo: Mujeres son mas\nrefinadas\n \n \n \n \n\n\nGrado de acuerdo: Mujeres deberian ser\nprotegidas\n0.364***\n \n \n \n\n\nGrado de acuerdo: Mujeres consiguen\nprivilegios en nombre de igualdad\n0.224***\n0.199***\n \n \n\n\nGrado de acuerdo: Mujeres derrotadas se\nquejan de discriminacion\n0.183***\n0.163***\n0.453***\n \n\n\nComputed correlation used pearson-method with listwise-deletion.\n\n\n\n\n\nPodemos observar que todas las correlaciones son positivas, por lo que no quedaron ítems invertidos."
  },
  {
    "objectID": "practicos/06-content.html#análisis-factorial-exploratorio",
    "href": "practicos/06-content.html#análisis-factorial-exploratorio",
    "title": "Práctico 6. Análisis factorial Exploratorio",
    "section": "",
    "text": "¿Qué se puede deducir de la matriz de correlaciones en relación a la estructura subyacente en términos de variables latentes? No hay claridad de grupos de indicadores asociados entre sí.\n\n\nKMO (Kaiser, Meyer, Olkin Measure of Sampling Adequacy):\n\nVaría entre 0 y 1. Contrasta si las correlaciones parciales entre las variables son pequeñas\nValores pequeños (menores a 0.5) indican que los datos no serían adecuados para AFE, ya que las correlaciones entre pares de variables no pueden ser explicadas por otras variables.\n\n\n\nCódigo\ncorMat  &lt;- data %&gt;% \n  cor(use = \"complete.obs\")  # estimar matriz pearson\n\nKMO(corMat)\n\n\nKaiser-Meyer-Olkin factor adequacy\nCall: KMO(r = corMat)\nOverall MSA =  0.61\nMSA for each item = \n        son_refinadas        ser_protegidas consiguen_privilegios \n                 0.63                  0.62                  0.59 \nquejan_discriminacion \n                 0.59 \n\n\nEn este caso las correlaciones son altas, por lo que los datos sí son adecuados para AFE.\n\n\n\nSe utiliza para evluar la hipótesis que la matriz de correlaciones es una matriz identidad (diagonal=1 y bajo la diagonal=0)\n\nSe busca significación (p &lt; 0.05) ya que se espera que las variables estén correlacionadas\n\n\n\nCódigo\ncortest.bartlett(corMat, n = 3417)\n\n\n$chisq\n[1] 1542.697\n\n$p.value\n[1] 0\n\n$df\n[1] 6\n\n\nEn este caso el valor p es 0, así que hay significación estadística\n\n\n\n\n\nCódigo\nscree.plot(data)\n\n\n\n\n\n\n\nCódigo\nfa.parallel(corMat, n.obs=3417)\n\n\n\n\n\nParallel analysis suggests that the number of factors =  2  and the number of components =  2 \n\n\n\n\n\n\nejes principales\n\n\n\nCódigo\nfac_pa &lt;- fa(r = data, nfactors = 2, fm= \"pa\")\n#summary(fac_pa)\nfac_pa\n\n\nFactor Analysis using method =  pa\nCall: fa(r = data, nfactors = 2, fm = \"pa\")\nStandardized loadings (pattern matrix) based upon correlation matrix\n                        PA1   PA2   h2   u2 com\nson_refinadas          0.02  0.60 0.37 0.63   1\nser_protegidas        -0.01  0.60 0.35 0.65   1\nconsiguen_privilegios  0.67  0.03 0.47 0.53   1\nquejan_discriminacion  0.68 -0.03 0.44 0.56   1\n\n                       PA1  PA2\nSS loadings           0.90 0.72\nProportion Var        0.23 0.18\nCumulative Var        0.23 0.41\nProportion Explained  0.56 0.44\nCumulative Proportion 0.56 1.00\n\n With factor correlations of \n     PA1  PA2\nPA1 1.00 0.47\nPA2 0.47 1.00\n\nMean item complexity =  1\nTest of the hypothesis that 2 factors are sufficient.\n\ndf null model =  6  with the objective function =  0.45 with Chi Square =  1522.89\ndf of  the model are -1  and the objective function was  0 \n\nThe root mean square of the residuals (RMSR) is  0 \nThe df corrected root mean square of the residuals is  NA \n\nThe harmonic n.obs is  3354 with the empirical chi square  0.01  with prob &lt;  NA \nThe total n.obs was  3417  with Likelihood Chi Square =  0.01  with prob &lt;  NA \n\nTucker Lewis Index of factoring reliability =  1.004\nFit based upon off diagonal values = 1\nMeasures of factor score adequacy             \n                                                   PA1  PA2\nCorrelation of (regression) scores with factors   0.80 0.75\nMultiple R square of scores with factors          0.64 0.56\nMinimum correlation of possible factor scores     0.28 0.13\n\n\n\nMaximum likelihood\n\nMaximiza la posibilidad de que los parámetros reproduzcan los datos observados\n\n\nCódigo\nfac_ml &lt;- fa(r = data, nfactors = 2, fm= \"ml\")\nfac_ml\n\n\nFactor Analysis using method =  ml\nCall: fa(r = data, nfactors = 2, fm = \"ml\")\nStandardized loadings (pattern matrix) based upon correlation matrix\n                        ML1   ML2   h2   u2 com\nson_refinadas          0.01  0.62 0.38 0.62   1\nser_protegidas        -0.01  0.58 0.34 0.66   1\nconsiguen_privilegios  0.67  0.03 0.47 0.53   1\nquejan_discriminacion  0.68 -0.03 0.44 0.56   1\n\n                       ML1  ML2\nSS loadings           0.90 0.72\nProportion Var        0.23 0.18\nCumulative Var        0.23 0.41\nProportion Explained  0.56 0.44\nCumulative Proportion 0.56 1.00\n\n With factor correlations of \n     ML1  ML2\nML1 1.00 0.47\nML2 0.47 1.00\n\nMean item complexity =  1\nTest of the hypothesis that 2 factors are sufficient.\n\ndf null model =  6  with the objective function =  0.45 with Chi Square =  1522.89\ndf of  the model are -1  and the objective function was  0 \n\nThe root mean square of the residuals (RMSR) is  0 \nThe df corrected root mean square of the residuals is  NA \n\nThe harmonic n.obs is  3354 with the empirical chi square  0  with prob &lt;  NA \nThe total n.obs was  3417  with Likelihood Chi Square =  0  with prob &lt;  NA \n\nTucker Lewis Index of factoring reliability =  1.004\nFit based upon off diagonal values = 1\nMeasures of factor score adequacy             \n                                                   ML1  ML2\nCorrelation of (regression) scores with factors   0.80 0.75\nMultiple R square of scores with factors          0.64 0.56\nMinimum correlation of possible factor scores     0.28 0.13\n\n\n\n\n\n\nVarimax (ortogonal)\n\n\n\nCódigo\nfac_ml_var &lt;- fa(r = data, nfactors = 2, fm= \"ml\", rotate=\"varimax\") # ortogonal\nfac_ml_var\n\n\nFactor Analysis using method =  ml\nCall: fa(r = data, nfactors = 2, rotate = \"varimax\", fm = \"ml\")\nStandardized loadings (pattern matrix) based upon correlation matrix\n                       ML1  ML2   h2   u2 com\nson_refinadas         0.14 0.60 0.38 0.62 1.1\nser_protegidas        0.12 0.57 0.34 0.66 1.1\nconsiguen_privilegios 0.65 0.21 0.47 0.53 1.2\nquejan_discriminacion 0.65 0.15 0.44 0.56 1.1\n\n                       ML1  ML2\nSS loadings           0.88 0.75\nProportion Var        0.22 0.19\nCumulative Var        0.22 0.41\nProportion Explained  0.54 0.46\nCumulative Proportion 0.54 1.00\n\nMean item complexity =  1.1\nTest of the hypothesis that 2 factors are sufficient.\n\ndf null model =  6  with the objective function =  0.45 with Chi Square =  1522.89\ndf of  the model are -1  and the objective function was  0 \n\nThe root mean square of the residuals (RMSR) is  0 \nThe df corrected root mean square of the residuals is  NA \n\nThe harmonic n.obs is  3354 with the empirical chi square  0  with prob &lt;  NA \nThe total n.obs was  3417  with Likelihood Chi Square =  0  with prob &lt;  NA \n\nTucker Lewis Index of factoring reliability =  1.004\nFit based upon off diagonal values = 1\nMeasures of factor score adequacy             \n                                                   ML1  ML2\nCorrelation of (regression) scores with factors   0.76 0.71\nMultiple R square of scores with factors          0.58 0.51\nMinimum correlation of possible factor scores     0.17 0.01\n\n\n\nPromax (oblicua)\n\n\n\nCódigo\nfac_ml_pro &lt;- fa(r = data, nfactors = 2, fm= \"ml\", rotate=\"promax\")\nfac_ml_pro\n\n\nFactor Analysis using method =  ml\nCall: fa(r = data, nfactors = 2, rotate = \"promax\", fm = \"ml\")\nStandardized loadings (pattern matrix) based upon correlation matrix\n                        ML1   ML2   h2   u2 com\nson_refinadas          0.01  0.62 0.38 0.62   1\nser_protegidas        -0.01  0.58 0.34 0.66   1\nconsiguen_privilegios  0.67  0.04 0.47 0.53   1\nquejan_discriminacion  0.67 -0.03 0.44 0.56   1\n\n                       ML1  ML2\nSS loadings           0.90 0.73\nProportion Var        0.23 0.18\nCumulative Var        0.23 0.41\nProportion Explained  0.55 0.45\nCumulative Proportion 0.55 1.00\n\n With factor correlations of \n     ML1  ML2\nML1 1.00 0.47\nML2 0.47 1.00\n\nMean item complexity =  1\nTest of the hypothesis that 2 factors are sufficient.\n\ndf null model =  6  with the objective function =  0.45 with Chi Square =  1522.89\ndf of  the model are -1  and the objective function was  0 \n\nThe root mean square of the residuals (RMSR) is  0 \nThe df corrected root mean square of the residuals is  NA \n\nThe harmonic n.obs is  3354 with the empirical chi square  0  with prob &lt;  NA \nThe total n.obs was  3417  with Likelihood Chi Square =  0  with prob &lt;  NA \n\nTucker Lewis Index of factoring reliability =  1.004\nFit based upon off diagonal values = 1\nMeasures of factor score adequacy             \n                                                   ML1  ML2\nCorrelation of (regression) scores with factors   0.80 0.75\nMultiple R square of scores with factors          0.64 0.56\nMinimum correlation of possible factor scores     0.28 0.13\n\n\n\n\n\n\n\nCódigo\nsjPlot::tab_fa(data, method = \"ml\", rotation = \"promax\", show.comm = TRUE, title = \"Análisis factorial de sexismo\")\n\n\nParallel analysis suggests that the number of factors =  2  and the number of components =  NA \n\n\n\nAnálisis factorial de sexismo\n\n\n\n\n\n\n\n\n \nFactor 1\nFactor 2\nCommunality\n\n\nGrado de acuerdo: Mujeres son mas\nrefinadas\n0.01\n0.62\n0.38\n\n\nGrado de acuerdo: Mujeres deberian ser\nprotegidas\n-0.01\n0.58\n0.34\n\n\nGrado de acuerdo: Mujeres consiguen\nprivilegios en nombre de igualdad\n0.67\n0.04\n0.47\n\n\nGrado de acuerdo: Mujeres derrotadas se\nquejan de discriminacion\n0.67\n-0.03\n0.44\n\n\nTotal Communalities\n\n1.63\n\n\nCronbach's α\n0.62\n0.52\n\n\n\n\n\n\nLuego de realizar el Análisis factorial exploratorio existen varias alternativas sobre los pasos a seguir. Por ejemplo, es posible estimar un promedio simple entre cada una de las variables de los factores. Otra opción es estimar puntajes factoriales."
  },
  {
    "objectID": "practicos/04-content.html",
    "href": "practicos/04-content.html",
    "title": "Correlación y regresión",
    "section": "",
    "text": "El desarrollo de esta guía tiene por objetivo revisar algunos procedimientos para la estimación de regresiones lineales y múltiples en R.\nPor temas de orden y reproducibilidad, en este curso hemos separado en dos momentos el trabajo con datos, y dos archivos de código correspondientes."
  },
  {
    "objectID": "practicos/04-content.html#antecedentes-de-los-datos-a-utilizar",
    "href": "practicos/04-content.html#antecedentes-de-los-datos-a-utilizar",
    "title": "Correlación y regresión",
    "section": "Antecedentes de los datos a utilizar",
    "text": "Antecedentes de los datos a utilizar\nCohesión barrial con elsoc 2016. Código de preparación disponible en: https://r-data-analisis.netlify.app/practicos/resumen-content#preparaci%C3%B3n"
  },
  {
    "objectID": "practicos/04-content.html#librerias",
    "href": "practicos/04-content.html#librerias",
    "title": "Correlación y regresión",
    "section": "1. Librerías principales (de R) a utilizar en el análisis",
    "text": "1. Librerías principales (de R) a utilizar en el análisis\n\n\nCódigo\npacman::p_load(dplyr, car, sjmisc, sjPlot, sjlabelled, stargazer, kableExtra, corrplot, texreg, ggplot2, ggpubr)\n\n\no desde internet:\n\n\nCódigo\nload(url(\"https://github.com/Kevin-carrasco/R-data-analisis/raw/main/practicos/files/elsoc2016_proc.RData\"))"
  },
  {
    "objectID": "practicos/04-content.html#análisis-descriptivo",
    "href": "practicos/04-content.html#análisis-descriptivo",
    "title": "Correlación y regresión",
    "section": "Análisis descriptivo",
    "text": "Análisis descriptivo\n\n\nCódigo\nsjmisc::descr(proc_data,\n      show = c(\"label\",\"range\", \"mean\", \"sd\", \"NA.prc\", \"n\"))%&gt;% # Selecciona estadísticos\n      kable(.,\"markdown\") # Esto es para que se vea bien en quarto\n\n\n\n\nTabla 1: Descriptivos\n\n\n\n\n\n\n\n\n\n\n\n\n\nvar\nlabel\nn\nNA.prc\nmean\nsd\nrange\n\n\n\n\n2\nideal\nEste barrio es ideal para mi\n2926\n0.0341647\n2.615174\n1.0202541\n4 (0-4)\n\n\n4\nintegracion\nMe siento integrado en este barrio\n2923\n0.1366587\n2.565515\n0.9993502\n4 (0-4)\n\n\n3\nidentificacion\nMe identifico con la gente de este barrio\n2923\n0.1366587\n2.523777\n0.9884856\n4 (0-4)\n\n\n8\npertenencia\nMe siento parte de este barrio\n2925\n0.0683293\n2.627692\n0.9878809\n4 (0-4)\n\n\n5\nm01\nNivel educacional\n2925\n0.0683293\n5.260513\n2.2015019\n9 (1-10)\n\n\n7\nm0_sexo\nSexo del entrevistado\n2927\n0.0000000\n1.602665\n0.4894300\n1 (1-2)\n\n\n6\nm0_edad\nEdad del entrevistado\n2927\n0.0000000\n46.090878\n15.2867983\n70 (18-88)\n\n\n1\ncohesion_barrial\ncohesion_barrial\n2917\n0.3416467\n10.333562\n3.3978552\n16 (0-16)\n\n\n\n\n\n\nEn la Tabla 1 podemos observar los descriptivos generales de la base de datos procesada que utilizamos en el práctico anterior. Contiene ya creado el índice de cohesión barrial cuya media es de 10,33"
  },
  {
    "objectID": "practicos/04-content.html#asociación-de-variables",
    "href": "practicos/04-content.html#asociación-de-variables",
    "title": "Correlación y regresión",
    "section": "Asociación de variables",
    "text": "Asociación de variables\nSeleccionamos las principales variables y cambiamos su nombre. No seleccionaremos las variables originales que construyeron el índice.\n\n\nCódigo\nproc_data &lt;- proc_data %&gt;% select(cohesion_barrial, edad=m0_edad, educacion=m01, sexo=m0_sexo)\n\n\n\n\n\n\n\n\nNota\n\n\n\n¿Qué era la correlación?\nLa correlación es una medida de asociación entre variables, que describe el sentido (dirección) y fuerza de la asociación.\nEn otras palabras, nos permite conocer cómo y cuánto se relaciona la variación de una variable, con la variación de otra variable."
  },
  {
    "objectID": "practicos/04-content.html#medias-condicionales",
    "href": "practicos/04-content.html#medias-condicionales",
    "title": "Correlación y regresión",
    "section": "Medias condicionales",
    "text": "Medias condicionales\nAntes de avanzar desde la correlación al método de regresión es importante conocer el concepto de media condicional.\nImaginemos un juego de tacataca con dos variables: cantidad de juegos previos y puntos obtenidos en un partido. En estas variables, el promedio de puntos es 4. Es decir, si conocemos a algún individuo que pertence al grupo de “datos”, sabemos que su puntaje se encuentra probablemente cercano a 4. ¿Podemos mejorar nuestra estimación utilizando el puntaje de X? Si el sujeto nos dice que ha jugado antes 6 veces, probablemente vamos a estimar un puntaje superior de puntos, tal vez más cercano a 6.\nLo que estamos haciendo es utilizar la información que conocemos de X para dar una estimación de Y, que sea más precisa que el promedio bruto.\n\nMirando el gráfico de nube de puntos, sabemos que tres personas han jugado antes una vez, pero una de ellas tuvo 2 puntos, otra 3 y otra 4. Con estos datos podemos calcular la media de Y para X=1, que sería igual a 3. En otras palabras, la media condicional de Y cuando X=1 es 3. Con esto, uno podría calcular la media condicional para cada punto de X y hacer una estimación más precisa de Y. Sin embargo, este proceso todavía no nos permite generalizar más eficientemte la relación entre X e Y.\n¿Cuántos puntos (Y) se obtienen según la experiencia previa de juego (X)? Esta pregunta nos conduce al cálculo de una recta que atraviese los puntos y que generalice la relación entre X e Y."
  },
  {
    "objectID": "practicos/04-content.html#residuos",
    "href": "practicos/04-content.html#residuos",
    "title": "Correlación y regresión",
    "section": "Residuos",
    "text": "Residuos\nEn el gráfico anterior vemos que la línea resume la relación entre X e Y, pero claramente es una simplificación que no abarca toda la variabilidad de los datos.\nPor ejemplo, para el sujeto cuya experiencia es haber jugado 1 vez y luego gana 3 puntos, esta línea predice exáctamente su puntaje basada en su experiencia. Sin embargo, el sujeto que ha jugado 3 veces y saca 6 puntos se encuentra más lejos de la línea y por lo tanto esta línea o “modelo predictivo” no representa tan bien su puntaje. A esto se refieren los residuos, que es la diferencia entre el valor predicho (o \\(\\widehat{Y}\\)) y el observado \\(Y\\), siendo los valores predichos de Y los que pasan por la recta a la altura de cada valor de X. Por lo tanto, la mejor recta será aquella que minimice al máximo los residuos.\n\nEl sentido de la recta que resume de mejor manera la relación entre dos variables es que minimice la suma de todos los residuos. ¿Cómo realizar este procedimiento?\n\nPara realizar la suma de los residuos estos se elevan al cuadrado, lo que se denomina Suma de residuos al cuadrado o \\(SS_{residual}\\). Se eleva al cuadrado ya que como hay residuos positivos y negativos, unos cancelarían a otros y la suma seía 0, tal como sucede en la formula de la varianza.\nDe la infinita cantidad de rectas que se pueden trazar, siempre hay una que tiene un valor menor de \\(SS_{residual}\\). Este procedimiento es el que da nombre al proceso de estimación: mínimos (residuos) cuadrados ordinarios, o OLS (Ordinary Least Squares).\n\n¿Cómo funciona esto con nuestro ejemplo?\n\n\nCódigo\n#Grafico x1 = ACT\ngraph1 &lt;- ggplot(proc_data, aes(x = edad, y = cohesion_barrial)) +\n  geom_point(size = 1) +  # Puntos\n  geom_smooth(method = \"lm\", se = FALSE) +  # Recta de regresión\n  labs(x = \"Edad\", y = \"Cohesión Barrial\")  # Etiquetas de ejes\n\n# Gráfico 2\ngraph2 &lt;- ggplot(proc_data, aes(x = educacion, y = cohesion_barrial)) +\n  geom_point(size = 1) +\n  geom_smooth(method = \"lm\", se = FALSE) +\n  labs(x = \"Educación\", y = \"Cohesión Barrial\")\nggarrange(graph1, graph2, nrow = 1) # Unir graficos\n\n\n\n\n\nCon el gráfico anterior podemos notar que, si bien ambas variables tienen una asociación distinta con la cohesión barrial, el tamaño efecto de esta relación es distinto. Edad tiene una asociación positiva, mientras que educación tiene una asociación negativa. El tamaño de efecto de edad es ‘grande’, mientras que el tamaño de educación es casi nulo."
  },
  {
    "objectID": "practicos/04-content.html#regresiones",
    "href": "practicos/04-content.html#regresiones",
    "title": "Correlación y regresión",
    "section": "Regresiones",
    "text": "Regresiones\nPara facilitar la interpretación de los coeficientes de regresión vamos a recodificar la variable de educación (10 categorías) en tres categorías (básica, media y universitaria).\nAdemás, nos aseguramos que las variables categóricas estén como variables categóricas con as_factor. De esta forma nos aseguramos que la estimación de los modelos sea correcta ya que no se úede interpretar educación como si fuera una variable numérica.\n\n\nCódigo\nproc_data$educacion &lt;- car::recode(proc_data$educacion, \"c(1,2,3)=1; c(4,5)=2; c(6,7,8,9,10)=3\")\n\nproc_data$educacion &lt;- set_labels(proc_data$educacion,\n            labels=c( \"Educacion básica\"=1,\n                      \"Educación media\"=2,\n                      \"Educación superior\"=3))\n\nfrq(proc_data$educacion)\n\n\nNivel educacional (x) &lt;numeric&gt; \n# total N=2927 valid N=2925 mean=2.12 sd=0.75\n\nValue |              Label |    N | Raw % | Valid % | Cum. %\n------------------------------------------------------------\n    1 |   Educacion básica |  656 | 22.41 |   22.43 |  22.43\n    2 |    Educación media | 1251 | 42.74 |   42.77 |  65.20\n    3 | Educación superior | 1018 | 34.78 |   34.80 | 100.00\n &lt;NA&gt; |               &lt;NA&gt; |    2 |  0.07 |    &lt;NA&gt; |   &lt;NA&gt;\n\n\nCódigo\nproc_data$educacion &lt;- as_factor(proc_data$educacion)\nproc_data$sexo &lt;- as_factor(proc_data$sexo)\n\nproc_data &lt;- na.omit(proc_data)\n\nreg1 &lt;- lm(cohesion_barrial ~ 1, data=proc_data)\n\nstargazer(reg1, type=\"text\")\n\n\n\n===============================================\n                        Dependent variable:    \n                    ---------------------------\n                         cohesion_barrial      \n-----------------------------------------------\nConstant                     10.336***         \n                              (0.063)          \n                                               \n-----------------------------------------------\nObservations                   2,915           \nR2                             0.000           \nAdjusted R2                    0.000           \nResidual Std. Error      3.397 (df = 2914)     \n===============================================\nNote:               *p&lt;0.1; **p&lt;0.05; ***p&lt;0.01\n\n\n¿Qué valor toma una regresión lineal cuando no incluímos predictores en nuestro modelo?\nEn este caso, lo que nos interesa observar es el intercepto. Un intercepto de 10.336 nos indica la media de la cohesión barrial.\n\nRegresión lineal simple\nUna regresión lineal simple es aquel modelo que incluye solo un predictor. En este caso construiremos tres modelos distintos con tres variables independientes, es decir, reg2 que incluye como predictor ‘edad’, reg3 incluye educación y reg4 incluye sexo.\n\nCódigo\nreg2 &lt;- lm(cohesion_barrial ~ edad, data=proc_data)\nreg3 &lt;- lm(cohesion_barrial ~ educacion, data=proc_data)\nreg4 &lt;- lm(cohesion_barrial ~ sexo, data=proc_data)\n\nknitreg(list(reg2, reg3, reg4), \n        custom.model.names = c(\"Modelo 1\",\n                               \"Modelo 2\",\n                               \"Modelo 3\"),\n        custom.note = \"*** p &lt; 0.001; ** p &lt; 0.01; * p &lt; 0.05\",\n        custom.coef.names = c(\"Intercepto\", \n                              \"Edad\",\n                              \"Educación media &lt;br&gt; &lt;i&gt;(Ref. Ed. básica)&lt;/i&gt;\", \n                              \"Educación superior\", \n                              \"Mujer &lt;br&gt; &lt;i&gt;(Ref. Hombre)&lt;/i&gt;\"),\n        caption = \"Cohesión barrial\",\n        caption.above = TRUE)\n\n\n\n\nCohesión barrial\n\n\n\n\n \n\n\nModelo 1\n\n\nModelo 2\n\n\nModelo 3\n\n\n\n\n\n\nIntercepto\n\n\n8.42***\n\n\n10.51***\n\n\n10.49***\n\n\n\n\n \n\n\n(0.20)\n\n\n(0.13)\n\n\n(0.10)\n\n\n\n\nEdad\n\n\n0.04***\n\n\n \n\n\n \n\n\n\n\n \n\n\n(0.00)\n\n\n \n\n\n \n\n\n\n\nEducación media  (Ref. Ed. básica)\n\n\n \n\n\n-0.13\n\n\n \n\n\n\n\n \n\n\n \n\n\n(0.16)\n\n\n \n\n\n\n\nEducación superior\n\n\n \n\n\n-0.35*\n\n\n \n\n\n\n\n \n\n\n \n\n\n(0.17)\n\n\n \n\n\n\n\nMujer  (Ref. Hombre)\n\n\n \n\n\n \n\n\n-0.26*\n\n\n\n\n \n\n\n \n\n\n \n\n\n(0.13)\n\n\n\n\nR2\n\n\n0.03\n\n\n0.00\n\n\n0.00\n\n\n\n\nAdj. R2\n\n\n0.03\n\n\n0.00\n\n\n0.00\n\n\n\n\nNum. obs.\n\n\n2915\n\n\n2915\n\n\n2915\n\n\n\n\n\n\n*** p &lt; 0.001; ** p &lt; 0.01; * p &lt; 0.05\n\n\n\n\n\nLa interpretación de una tabla de regresión debe seguir el orden de presentación de los modelos y el orden de los coeficientes de regresión. En este ejemplo se dará el paso a paso de cómo interpretar las tablas:\nEn el Modelo 1 se incluye edad como predictor, que tiene un coeficiente de regresión de 0,04. Esto indica que por cada unidad que aumenta edad, la cohesión barrial aumenta en promedio 0,04 unidades, efecto que podemos extrapolar a la población con un 99,9% de confianza (p&lt;0,001). El intercepto es de 8,42, lo que indica que (teóricamente) una persona con edad 0 tendría un promedio de cohesión barrial de 8,42. Finalmente, el modelo 1 logra explicar el 3% de la varianza de la variable dependiente (R2=0,03).\nEl Modelo 2 incluye la edad de los/as encuestados como variable independiente, teniendo la categoría de ‘educación básica’ como categoría de referencia. Este Modelo indica que las personas con educación media tienen en promedio -0,13 unidades en el índice de cohesión barrial que las personas con educación básica, sin embargo, este coeficiente no es estadísticamente significativo. En cuanto a las personas con educación superior, estas tendrían en promedio -0,35 unidades en la escala de cohesión barrial en comparación con las personas con educación básica, efecto que es estadísticamente significativo (p&lt;0,05). Si observamos el intercepto, este nos indica que el promedio de cohesión barrial para las personas con educación básica es de 10,51, por lo que el promedio de cohesión barrial para las personas con educación media sería de 10,38 y para las personas con educación superior sería 10,16.\nEl modelo 3 indica que las mujeres tendrían -0,26 unidades en la escala de cohesión barrial que los hombres, efecto que podemos extrapolar a la población con un 95% de confianza. El intercepto indica que el promedio de cohesión barrial de los hombres es 10,49, por lo que el promedio para las mujeres sería de 10,23.\n\n\nRegresión lineal múltiple\nUna regresión lineal múltiple es aquel modelo que incluye más de un predictor en las estimaciones. Idealmente, la inclusión de nuevas variables independientes, así como el orden de presentación de los modelos debe seguir un sentido teórico y/o acorde a las hipótesis de investigación. En este caso, y solo como ejemplo, construiremos cuatro modelos distintos que incluyen todas las combinaciones de variables posibles para ver cómo cambian los efectos según el control estadístico (parcialización)\n\nCódigo\nreg5 &lt;- lm(cohesion_barrial ~ edad + educacion, data=proc_data)\nreg6 &lt;- lm(cohesion_barrial ~ edad + sexo, data=proc_data)\nreg7 &lt;- lm(cohesion_barrial ~ educacion + sexo, data=proc_data)\nreg8 &lt;- lm(cohesion_barrial ~ edad + educacion + sexo, data=proc_data)\n\nknitreg(list(reg5, reg6, reg7, reg8), \n        custom.model.names = c(\"Modelo 1\",\n                               \"Modelo 2\",\n                               \"Modelo 3\",\n                               \"Modelo 4\"),\n        custom.note = \"*** p &lt; 0.001; ** p &lt; 0.01; * p &lt; 0.05\",\n        custom.coef.names = c(\"Intercepto\", \n                              \"Edad\",\n                              \"Educación media &lt;br&gt; &lt;i&gt;(Ref. Ed. básica)&lt;/i&gt;\", \n                              \"Educación superior\", \n                              \"Mujer &lt;br&gt; &lt;i&gt;(Ref. Hombre)&lt;/i&gt;\"),\n        caption = \"Cohesión barrial\",\n        caption.above = TRUE)\n\n\n\n\nCohesión barrial\n\n\n\n\n \n\n\nModelo 1\n\n\nModelo 2\n\n\nModelo 3\n\n\nModelo 4\n\n\n\n\n\n\nIntercepto\n\n\n7.99***\n\n\n8.60***\n\n\n10.71***\n\n\n8.19***\n\n\n\n\n \n\n\n(0.28)\n\n\n(0.21)\n\n\n(0.16)\n\n\n(0.29)\n\n\n\n\nEdad\n\n\n0.04***\n\n\n0.04***\n\n\n \n\n\n0.05***\n\n\n\n\n \n\n\n(0.00)\n\n\n(0.00)\n\n\n \n\n\n(0.00)\n\n\n\n\nEducación media  (Ref. Ed. básica)\n\n\n0.35*\n\n\n \n\n\n-0.16\n\n\n0.33\n\n\n\n\n \n\n\n(0.17)\n\n\n \n\n\n(0.16)\n\n\n(0.17)\n\n\n\n\nEducación superior\n\n\n0.36*\n\n\n \n\n\n-0.38*\n\n\n0.33\n\n\n\n\n \n\n\n(0.18)\n\n\n \n\n\n(0.17)\n\n\n(0.18)\n\n\n\n\nMujer  (Ref. Hombre)\n\n\n \n\n\n-0.34**\n\n\n-0.28*\n\n\n-0.33**\n\n\n\n\n \n\n\n \n\n\n(0.13)\n\n\n(0.13)\n\n\n(0.13)\n\n\n\n\nR2\n\n\n0.04\n\n\n0.04\n\n\n0.00\n\n\n0.04\n\n\n\n\nAdj. R2\n\n\n0.04\n\n\n0.04\n\n\n0.00\n\n\n0.04\n\n\n\n\nNum. obs.\n\n\n2915\n\n\n2915\n\n\n2915\n\n\n2915\n\n\n\n\n\n\n*** p &lt; 0.001; ** p &lt; 0.01; * p &lt; 0.05\n\n\n\n\n\nEl Modelo 1 incluye edad y educación como variables independientes. Este modelo indica que por cada unidad que aumenta la edad, la cohesión barrial aumenta en 0,04 unidades, manteniendo la educación constante, efecto que es estadísticamente significativo (p&lt;0,001). En cuanto a la educación, tener educación media (b=0,35) y tener educación superior (b=0,36) tienen un efecto positivo sobre la cohesión barrial en comparación con quienes tienen educación básica, menteniendo la edad constante, efecto que es estadísticamente significativo (p&lt;0,05).\nEn el Modelo 2 el efecto de edad se mantiene igual que en el modelo 1. Al incluir edad (y no educación) este modelo indica que las mujeres tendrían -0,34 unidades en la escala de cohesión barrial que los hombres, manteniendo la edad constante, efecto que podemos extrapolar a la población con un 99% de confianza.\nEl Modelo 3 incluye las variables educación y sexo, por lo que es interesante notar que al no controlar por edad, el efecto de la educación cambia de positivo a negativo y solo encontramos diferencias estadísticamente significativas al tener educación superior. El efecto del sexo disminuye, pero mantiene su sentido y significancia.\nEl Modelo 4 incluye todas las variables independientes. Este modelo indica que por cada unidad que aumenta la edad, la cohesión barrial aumenta en 0,05 unidades, manteniendo el resto de las variables constantes, efecto que es estadísticamente significativo (p&lt;0,001). En cuanto a la educación, tener educación media (b=0,33) y tener educación superior (b=0,33) tienen un efecto positivo sobre la cohesión barrial en comparación con quienes tienen educación básica, menteniendo el resto de las variables constantes, sin embargo, estas diferencias no son estadísticamente significativas. Finalmente, las mujeres tendrían -0,33 unidades en la escala de cohesión barrial que los hombres, manteniendo el resto de variables constantes, efecto que podemos extrapolar a la población con un 99% de confianza.\nLos modelos 1, 2 y 4 logran explicar el 4% de la varianza de la variable dependiente (R2=0,04).\n\n\nGraficar\n\n\nCódigo\nplot_model(reg8, \n            title = \"\", #quitar titulo\n            show.values = TRUE, #mostrar valor de efectos\n            dot.size = 3, #tamaño circulos\n            line.size = 1, #tamaño CI\n            value.size = 4, #tamaño valor efectoss\n            spacing = 1, #espacio entre efectos\n            vline.color = \"red\", # linea roja en punto neutro (0)\n            axis.labels = rev(c(\"Edad\",\n                              \"Educación media\", \n                              \"Educación superior\", \n                              \"Mujer\")), #con rev porque automatico los tira en otro orden\n            show.legend = FALSE) + # variables dependientes\n  theme_bw()"
  },
  {
    "objectID": "practicos/02-content.html",
    "href": "practicos/02-content.html",
    "title": "Análisis de correspondencia simple",
    "section": "",
    "text": "Objetivo de la práctica\nLa siguiente práctica tiene el objetivo de introducir la idea central del análisis de correspondencia. Para ello, utilizaremos la base de datos de la cuarta ola del Estudio Longitudinal Social de Chile 2019 con el objetivo de analizar agrupaciones de variables categóricas nominales.\n\n\nPreparación datos\nComencemos por preparar nuestros datos. Iniciamos cargando las librerías necesarias.\n\n\nCódigo\npacman::p_load(tidyverse, # Manipulacion datos\n               sjPlot, # Tablas\n               psych, # Correlaciones\n               DescTools, # Tablas\n               gginference, # Visualizacion \n               rempsyc, # Reporte\n               broom) # Varios\n\noptions(scipen = 999) # para desactivar notacion cientifica\nrm(list = ls()) # para limpiar el entorno de trabajo\n\n\nCargamos los datos directamente desde internet.\n\n\nCódigo\n#cargamos la base de datos desde internet\nload(url(\"https://dataverse.harvard.edu/api/access/datafile/7245118\")) \n\ndim(elsoc_long_2016_2022.2)\n\n\n[1] 18035   750\n\n\nContamos con 750 variables (columnas) y 18035 observaciones (filas).\n\n\nCódigo\nproc_data &lt;- elsoc_long_2016_2022.2 %&gt;% filter(ola==\"4\") %&gt;% \n  select(c29, # Confianza generalizada\n         m01# nivel educacional\n         )\n\nproc_data &lt;- proc_data %&gt;% sjlabelled::set_na(., na = c(-999, -888, -777, -666))\n# Comprobar\nnames(proc_data)\n\n\n[1] \"c29\" \"m01\"\n\n\nCódigo\nproc_data$educacion &lt;- car::recode(proc_data$m01, \"c(1,2,3)=1; c(4,5)=2; c(6,7,8,9,10)=3\")\n\nproc_data$educacion &lt;- sjlabelled::set_labels(proc_data$educacion,\n            labels=c( \"Educación básica\"=1,\n                      \"Educación media\"=2,\n                      \"Educación superior\"=3))\n\nsjmisc::frq(proc_data$educacion)\n\n\nNivel educacional (x) &lt;numeric&gt; \n# total N=3417 valid N=3413 mean=2.12 sd=0.75\n\nValue |              Label |    N | Raw % | Valid % | Cum. %\n------------------------------------------------------------\n    1 |   Educación básica |  781 | 22.86 |   22.88 |  22.88\n    2 |    Educación media | 1432 | 41.91 |   41.96 |  64.84\n    3 | Educación superior | 1200 | 35.12 |   35.16 | 100.00\n &lt;NA&gt; |               &lt;NA&gt; |    4 |  0.12 |    &lt;NA&gt; |   &lt;NA&gt;\n\n\n\n\nTablas de contingencia\nUna tabla de contingencia es una de las maneras más simples y útiles para representar el cruce entre dos variables categóricas.\nCon ella, podemos obtener en las celdas las frecuencias conjuntas entre ambas variables, es decir, cuántos casos de una determinada categoría de la variable Y ocurren conjuntamente con una determinada categoría de la variable X.\nAdemás, podemos presentar los totales de cada fila y columna al exterior de la tabla, también conocidas como frecuencias marginales.\nVeamos un ejemplo con ss_salud y universitaria:\n\n\nCódigo\nsjPlot::sjt.xtab(var.row = proc_data$educacion, var.col = proc_data$c29, \n                 show.summary = F, emph.total = T, encoding = \"UTF-8\")\n\n\n\n\n\n\n\n\n\n\n\n\nNivel educacional\nMecanismo de cambio\nde Constitucion\nTotal\n\n\nQue sea un grupo de\nexpertos los que\nredacten una nueva\nConstitucion\nQue el parlamento\nredacte una nueva\nConstitucion\nQue los ciudadanos\nelijan una Asamblea\nconstituyente para\nque redacte una\nnueva Constitucion\n\n\nEducación básica\n138\n30\n446\n614\n\n\nEducación media\n277\n31\n964\n1272\n\n\nEducación superior\n286\n17\n843\n1146\n\n\nTotal\n701\n78\n2253\n3032\n\n\n\n\n\nSumado a esto, tenemos:\n\nFrecuencias absolutas: números que aparencen en la tabla (ya sean conjuntas o marginales)\nFrecuencias relativas:\n\nporcentaje fila: % que cada frecuencia conjunta representa sobre la marginal de su fila\nporcentaje columna: % que cada frecuencia conjunta representa sobre la marginal de su columna\nporcentaje total: % que cada frecuencia conjunta representa sobre el número total de casos de la tabla\n\n\nVeamos cómo incorporar el porcentaje fila y columna en la tabla.\n\n\nCódigo\nsjPlot::sjt.xtab(var.row = proc_data$educacion, \n                 var.col = proc_data$c29, \n                 show.summary = F, \n                 emph.total = T, \n                 show.row.prc = T, # porcentaje fila\n                 show.col.prc = T, # porcentaje columna\n                 encoding= \"UTF-8\")\n\n\n\n\n\n\n\n\n\n\n\n\nNivel educacional\nMecanismo de cambio\nde Constitucion\nTotal\n\n\nQue sea un grupo de\nexpertos los que\nredacten una nueva\nConstitucion\nQue el parlamento\nredacte una nueva\nConstitucion\nQue los ciudadanos\nelijan una Asamblea\nconstituyente para\nque redacte una\nnueva Constitucion\n\n\nEducación básica\n138\n22.5 %\n19.7 %\n30\n4.9 %\n38.5 %\n446\n72.6 %\n19.8 %\n614\n100 %\n20.3 %\n\n\nEducación media\n277\n21.8 %\n39.5 %\n31\n2.4 %\n39.7 %\n964\n75.8 %\n42.8 %\n1272\n100 %\n42 %\n\n\nEducación superior\n286\n25 %\n40.8 %\n17\n1.5 %\n21.8 %\n843\n73.6 %\n37.4 %\n1146\n100 %\n37.8 %\n\n\nTotal\n701\n23.1 %\n100 %\n78\n2.6 %\n100 %\n2253\n74.3 %\n100 %\n3032\n100 %\n100 %\n\n\n\n\n\nAquí, los porcentajes fila aparecen en azul y los porcentajes columna en verde.\n\n\nPrueba de hipótesis con Chi-cuadrado\ncálculo directo en R:\n\n\nCódigo\nchi_results &lt;- chisq.test(table(proc_data$educacion, proc_data$c29))\n\nstats.table &lt;- tidy(chi_results, conf_int = T)\nnice_table(stats.table)\n\n\n\nstatisticpparameterMethod21.61&lt; .001***4Pearson's Chi-squared test\n\n\nVisualicemos la distribución de esta prueba y su zona de rechazo.\n\n\nCódigo\nggchisqtest(chi_results)\n\n\n\n\n\n\n\nAnálisis de correspondencias simple\n\n\nCódigo\npacman::p_load(ade4, FactoMineR, factoextra)\n\n\n\n  There is a binary version available but the source version is later:\n                binary   source needs_compilation\nRcppArmadillo 14.0.2-1 14.2.0-1              TRUE\n\n  Binaries will be installed\npackage 'pixmap' successfully unpacked and MD5 sums checked\npackage 'sp' successfully unpacked and MD5 sums checked\npackage 'RcppArmadillo' successfully unpacked and MD5 sums checked\npackage 'ade4' successfully unpacked and MD5 sums checked\n\nThe downloaded binary packages are in\n    C:\\Users\\danie\\AppData\\Local\\Temp\\Rtmp88h1j1\\downloaded_packages\n\n\npackage 'crosstalk' successfully unpacked and MD5 sums checked\npackage 'DT' successfully unpacked and MD5 sums checked\npackage 'ellipse' successfully unpacked and MD5 sums checked\npackage 'flashClust' successfully unpacked and MD5 sums checked\npackage 'leaps' successfully unpacked and MD5 sums checked\npackage 'multcompView' successfully unpacked and MD5 sums checked\npackage 'scatterplot3d' successfully unpacked and MD5 sums checked\npackage 'FactoMineR' successfully unpacked and MD5 sums checked\n\nThe downloaded binary packages are in\n    C:\\Users\\danie\\AppData\\Local\\Temp\\Rtmp88h1j1\\downloaded_packages\n\n\npackage 'dendextend' successfully unpacked and MD5 sums checked\npackage 'factoextra' successfully unpacked and MD5 sums checked\n\nThe downloaded binary packages are in\n    C:\\Users\\danie\\AppData\\Local\\Temp\\Rtmp88h1j1\\downloaded_packages\n\n\n\n\nCódigo\nproc_data &lt;- proc_data %&gt;% select(-m01)\ntabla &lt;- prop.table(table(proc_data$educacion, proc_data$c29))\ndimnames(tabla) &lt;- list(educacion=c(\"Básica\", \"Media\", \"Universitaria\"),\n                        constitucion=c(\"Expertos\", \"Parlamento\", \"Asamblea\")\n                        )\ntabla\n\n\n               constitucion\neducacion          Expertos  Parlamento    Asamblea\n  Básica        0.045514512 0.009894459 0.147097625\n  Media         0.091358839 0.010224274 0.317941953\n  Universitaria 0.094327177 0.005606860 0.278034301\n\n\nCódigo\nchisq.test(tabla)\n\n\n\n    Pearson's Chi-squared test\n\ndata:  tabla\nX-squared = 0.0071286, df = 4, p-value = 1\n\n\nCódigo\nACS &lt;- CA(tabla, ncp=2, graph = FALSE)\n\n\n\n\nCódigo\n#Perfiles fila\nvariables_fila=get_ca_row(ACS)\nvariables_fila$inertia\n\n\n[1] 0.0043252569 0.0004808203 0.0023224997\n\n\nCódigo\n#Nube de individuos fila\nfviz_ca_row(ACS, repel = TRUE)+ggtitle(\"\") + ylab(\"Eje 2(11.55%)\")+xlab(\"Eje 1(88.45%)\")+ylim(-0.5,.5)+xlim(-.5,.5)\n\n\n\n\n\n\n\nCódigo\n#Perfiles columna\nvariables_columna=get_ca_col(ACS)\nvariables_columna$inertia\n\n\n[1] 0.0009150867 0.0059857229 0.0002277674\n\n\nCódigo\n#Nube de individuos columna\nfviz_ca_col(ACS)+ggtitle(\"\")+ylab(\"Eje 2(11.55%)\")+xlab(\"Eje 1(88.45%)\")+ylim(-0.5,.5)+xlim(-0.5,.5)\n\n\n\n\n\n\n\nCódigo\n#Representación simultánea\nplot.CA(ACS)"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "\n            Estadística IV\n        ",
    "section": "",
    "text": "Estadística IV\n        \n        \n            Departamento de Sociología - Facultad de Ciencias Sociales de la Universidad Alberto Hurtado\n        \n        \n            CSSOCIAL 6601-SOC1 (1357) • Segundo semestre 2024Departamento de SociologíaUniversidad Alberto Hurtado\n        \n    \n    \n      \n        \n        \n        \n      \n    \n\n\n\n\nEquipo docente\nProfesores\n\n   Daniela Olivares\n danielaolivarescollio@gmail.com\n\n\n\n   Kevin Carrasco\n kevin.carrasco@ug.uchile.cl\n\n\nAyudante\n\n   María Fernanda Núñez\n maria.nunez.2@ug.uchile.cl\n\n\n\nInformación del curso\n\n   Miércoles\n   Agosto 14 - Diciembre 11 2024\n   08:30 a 09:50 y 10:00 a 11:20\n   Sala Lab. E67"
  },
  {
    "objectID": "herramientas/01-content.html",
    "href": "herramientas/01-content.html",
    "title": "Github",
    "section": "",
    "text": "Github es una plataforma de desarrollo colaborativo que permite alojar proyectos utilizando el sistema de control de versiones Git. Se utiliza principalmente para la creación de código fuente de programas (software).\n\n\n\n\n\n\nNota\n\n\n\nEl 4 de junio de 2018 Microsoft compró GitHub por la cantidad de 7500 millones de dólares. Al inicio, el cambio de propietario generó preocupaciones y la salida de algunos proyectos de este sitio; sin embargo, no fueron representativos. GitHub continúa siendo la plataforma más importante de colaboración para proyectos de código abierto.\n\n\n\n\n\nUn repositorio contiene todo el código, tus archivos y el historial de revisiones y cambios de cada uno de ellos. Es el elemento más básico de Github.\nLos repositorios pueden contar con múltiples colaboradores y pueden ser públicos o privados.\n\n\n\n\n\n\n\n\n\n\nTérmino\nDefinición\n\n\n\n\nBranch\nUna versión paralela del código contenido en el repositorio, pero que no afecta a la rama principal.\n\n\nClonar\nPara descargar una copia completa de los datos de un repositorio de GitHub.com, incluidas todas las versiones de cada archivo y carpeta.\n\n\nFork\nUn nuevo repositorio que comparte la configuración de visibilidad y código con el repositorio «ascendente» original.\n\n\nMerge\nPara aplicar los cambios de una rama y en otra.\n\n\nPull request\nUna solicitud para combinar los cambios de una branch en otra.\n\n\nRemote\nUn repositorio almacenado en GitHub, no en el equipo.\n\n\nUpstream\nLa branch de un repositorio original que se ha forkeado o clonado. La branch correspondiente de la branch clonada o forkeada se denomina «descendente».\n\n\n\n\n\n\n\nAcceder a la página de github\n\nRegistrarse ingresando correo electrónico y siguiendo los pasos siguientes (crear contraseña y nombre de usuario)\n\nLa personalización de la cuenta se puede saltar haciendo click en skip abajo de la selección de opciones\n\nDescargar e instalar Github Desktop\n\n\n\n\n\nEn la página principal de github hacer click en el ícono de usuario de la esquina superior derecha y luego ir a Tus repositorios\n\nUna vez accedemos a Tus repositorios hacemos click en New/Nuevo\n\nLuego le ponemos un nombre a nuestro repositorio, evitando siempre espacios, ñ y tíldes, y apretamos Crear repositorio\n\n\n\n\nUna vez creado un repositorio, lo que nos interesa es descargarlo. Al abrir la aplicación de Github desktop por primera vez (descargada anteriormente), nos debería aparecer la opción de clonar nuestro repositorio R-data-analisis en la pantalla de inicio. Lo clonamos y seleccionamos una carpeta de nuestro computador para almacenarlo.\nPara todas las siguientes veces, las instrucciones son estas:\n1- Apretamos Repositorio actual en la esquina superior izquierda\n2- Apretamos añadir\n3- Apretamos clonar repositorio…\n\n4- Seleccionamos nuestro repositorio\n5- seleccionamos la carpeta donde se almacenará. Siempre evitando tener tíldes, ñ y espacios en la dirección de almacenamiento."
  },
  {
    "objectID": "herramientas/01-content.html#descripción",
    "href": "herramientas/01-content.html#descripción",
    "title": "Github",
    "section": "",
    "text": "Github es una plataforma de desarrollo colaborativo que permite alojar proyectos utilizando el sistema de control de versiones Git. Se utiliza principalmente para la creación de código fuente de programas (software).\n\n\n\n\n\n\nNota\n\n\n\nEl 4 de junio de 2018 Microsoft compró GitHub por la cantidad de 7500 millones de dólares. Al inicio, el cambio de propietario generó preocupaciones y la salida de algunos proyectos de este sitio; sin embargo, no fueron representativos. GitHub continúa siendo la plataforma más importante de colaboración para proyectos de código abierto."
  },
  {
    "objectID": "herramientas/01-content.html#repositorios",
    "href": "herramientas/01-content.html#repositorios",
    "title": "Github",
    "section": "",
    "text": "Un repositorio contiene todo el código, tus archivos y el historial de revisiones y cambios de cada uno de ellos. Es el elemento más básico de Github.\nLos repositorios pueden contar con múltiples colaboradores y pueden ser públicos o privados."
  },
  {
    "objectID": "herramientas/01-content.html#principales-términos",
    "href": "herramientas/01-content.html#principales-términos",
    "title": "Github",
    "section": "",
    "text": "Término\nDefinición\n\n\n\n\nBranch\nUna versión paralela del código contenido en el repositorio, pero que no afecta a la rama principal.\n\n\nClonar\nPara descargar una copia completa de los datos de un repositorio de GitHub.com, incluidas todas las versiones de cada archivo y carpeta.\n\n\nFork\nUn nuevo repositorio que comparte la configuración de visibilidad y código con el repositorio «ascendente» original.\n\n\nMerge\nPara aplicar los cambios de una rama y en otra.\n\n\nPull request\nUna solicitud para combinar los cambios de una branch en otra.\n\n\nRemote\nUn repositorio almacenado en GitHub, no en el equipo.\n\n\nUpstream\nLa branch de un repositorio original que se ha forkeado o clonado. La branch correspondiente de la branch clonada o forkeada se denomina «descendente»."
  },
  {
    "objectID": "herramientas/01-content.html#crear-cuenta-e-instalación",
    "href": "herramientas/01-content.html#crear-cuenta-e-instalación",
    "title": "Github",
    "section": "",
    "text": "Acceder a la página de github\n\nRegistrarse ingresando correo electrónico y siguiendo los pasos siguientes (crear contraseña y nombre de usuario)\n\nLa personalización de la cuenta se puede saltar haciendo click en skip abajo de la selección de opciones\n\nDescargar e instalar Github Desktop"
  },
  {
    "objectID": "herramientas/01-content.html#crear-repositorio",
    "href": "herramientas/01-content.html#crear-repositorio",
    "title": "Github",
    "section": "",
    "text": "En la página principal de github hacer click en el ícono de usuario de la esquina superior derecha y luego ir a Tus repositorios\n\nUna vez accedemos a Tus repositorios hacemos click en New/Nuevo\n\nLuego le ponemos un nombre a nuestro repositorio, evitando siempre espacios, ñ y tíldes, y apretamos Crear repositorio"
  },
  {
    "objectID": "herramientas/01-content.html#github-desktop",
    "href": "herramientas/01-content.html#github-desktop",
    "title": "Github",
    "section": "",
    "text": "Una vez creado un repositorio, lo que nos interesa es descargarlo. Al abrir la aplicación de Github desktop por primera vez (descargada anteriormente), nos debería aparecer la opción de clonar nuestro repositorio R-data-analisis en la pantalla de inicio. Lo clonamos y seleccionamos una carpeta de nuestro computador para almacenarlo.\nPara todas las siguientes veces, las instrucciones son estas:\n1- Apretamos Repositorio actual en la esquina superior izquierda\n2- Apretamos añadir\n3- Apretamos clonar repositorio…\n\n4- Seleccionamos nuestro repositorio\n5- seleccionamos la carpeta donde se almacenará. Siempre evitando tener tíldes, ñ y espacios en la dirección de almacenamiento."
  },
  {
    "objectID": "content/03-content.html#lecturas",
    "href": "content/03-content.html#lecturas",
    "title": "Presentación",
    "section": "Lecturas",
    "text": "Lecturas\nR for Data Science"
  },
  {
    "objectID": "content/01-content.html#video-de-la-sesión",
    "href": "content/01-content.html#video-de-la-sesión",
    "title": "Presentación",
    "section": "Video de la sesión",
    "text": "Video de la sesión\nEsta clase fue suspendida por paro, si alguien está interesado en aprender los contenidos puede revisar este video:"
  },
  {
    "objectID": "content/01-content.html#lecturas",
    "href": "content/01-content.html#lecturas",
    "title": "Presentación",
    "section": "Lecturas",
    "text": "Lecturas\nR for Data Science"
  },
  {
    "objectID": "assignment/04-examen.html",
    "href": "assignment/04-examen.html",
    "title": "Examen",
    "section": "",
    "text": "Examen\nLa investigación final (examen) de este curso representa el 30% de la nota final.\nEsta investigación consiste en una evaluación final individual que aplica los conocimientos y herramientas entregadas a lo largo del curso y en las tareas realizadas, a un proyecto de investigación de elección por el/la estudiante. Se espera que este proyecto incluya todo el trabajo realizado en las tareas del curso, así como la incorporación de comentarios y sugerencias de retroalimentación de las evaluaciones.\nPor lo tanto, esta investigación debe incluir los 4 trabajos anteriores en un solo documento, sumando una sección final de conclusiones.\nA continuación se detalla la rubrica específica de evaluación:\n\n\n\n\n\n\n\n\nÍtem\nObjetivo\nPuntaje\n\n\n\n\n1. Introducción y bibliografía automática\nL-s estudiantes plantean un problema de investigación relevante y lo justifican con bibliografía automatizada (Trabajo 1)\n2pts\n\n\n2. Operacionalización de variables\nL-s estudiantes son capaces de operacionalizar correctamente las variables de interés. (Trabajo 2)\n2pts\n\n\n3. Visualización de resultados\nL-s estudiantes son capaces de visualizar correctamente las variables de interés. Se espera que el reporte incluya una tabla descriptiva y dos gráficos univariados (Trabajo 2)\n2ptos\n\n\n4. Asociación de variables\nL-s estudiantes son capaces de reportar y visualizar correctamente la asociación entre sus variables. Se espera que el reporte incluya al menos una tabla y/o gráfico (trabajo 3)\n2ptos\n\n\n5. Construcción de índices y escalas\nL-s estudiantes son capaces de construir al menos un índice ponderado (reportando un autor o informe que justifique la ponderación) y/o una escala con el reporte de su consistencia interna (Trabajo 3)\n2ptos\n\n\n6. Estimación de modelos de regresión\nL-s estudiantes son capaces de reportar y visualizar correctamente distintos modelos de regresión (Trabajo 4)\n3ptos\n\n\n7. Interpretación de resultados\nL-s estudiantes son capaces de interpretar correctamente las tablas y gráficos presentados\n5pts\n\n\nTotal\n-\n18puntos"
  },
  {
    "objectID": "assignment/02-trabajo.html",
    "href": "assignment/02-trabajo.html",
    "title": "Trabajo 2. Procesamiento y visualización de análisis descriptivo",
    "section": "",
    "text": "El objetivo de este trabajo es realizar un reporte dinámico a través de Quarto, que contenga el análisis descriptivo del problema de investigación propuesto en el Trabajo 1. El documento final debe ser subido a Github Pages y se debe enviar el link a este documento para su revisión."
  },
  {
    "objectID": "assignment/02-trabajo.html#objetivos-del-trabajo",
    "href": "assignment/02-trabajo.html#objetivos-del-trabajo",
    "title": "Trabajo 2. Procesamiento y visualización de análisis descriptivo",
    "section": "",
    "text": "El objetivo de este trabajo es realizar un reporte dinámico a través de Quarto, que contenga el análisis descriptivo del problema de investigación propuesto en el Trabajo 1. El documento final debe ser subido a Github Pages y se debe enviar el link a este documento para su revisión."
  },
  {
    "objectID": "assignment/02-trabajo.html#instrucciones-generales",
    "href": "assignment/02-trabajo.html#instrucciones-generales",
    "title": "Trabajo 2. Procesamiento y visualización de análisis descriptivo",
    "section": "Instrucciones generales",
    "text": "Instrucciones generales\n\nDescargar la base de datos que se utilizará en la investigación y guardarla en la carpeta correspondiente (input)\nOperacionalización: Script de R llamado “Preparacion” y guardado en la carpeta que corresponde (Procesamiento). Manipulación de datos para obtener las variables utilizadas en la investigación. Se espera que l-s estudiantes sean capaces de seleccionar las variables relevantes para la problemática escogida, agruparlas, reordenarlas y asignarles los nombres y etiquetas según corresponda.\nVisualización de datos: Elaboración de tablas y/o gráficos, en el contexto de un reporte científico de investigación, que intente responder, ejemplificar y/o demostrar los principales hallazgos de la investigación. Para esta primera entrega se espera que sean capaces de generar una tabla descriptiva que muestre las medidas de tendencia central de las variables utilizadas en la investigación, así como su contraparte de tablas de frecuencias en el caso de variables categóricas. También se espera que sean capaces de elaborar dos gráficos descriptivos que permitan visualizar la distribución de las principales variables de interés.\nNo es necesario elaborar un informe teórico sobre el tema de investigación. En la introducción de este reporte debe ir la propuesta elaborada en el Trabajo 1, pero es importante mencionar la fuente de datos utilizada. El objetivo del trabajo es que sean capaces de operacionalizar variables, escoger la mejor forma de visualizar sus medidas de tendencia central y/o frecuencias e interpretar estas tablas/gráficos.\n\nEntrega:\n\nJueves 18 de Abril a través de Teams.\nSe debe enviar el link al repositorio de github\nNo más de 5000 palabras\nSe deben mantener las referencias de la literatura / bases de datos revisadas\natrasos, 0,5 por día de atraso.\n\nRúbrica de evaluación:\n\n\n\n\n\n\n\n\nÍtem\nObjetivo\nPuntaje\n\n\n\n\n1. Cargar base de datos\nL-s estudiantes son capaces de descargar la base de datos y posteriormente cargarla en R\n2pts\n\n\n2. Selección de variables\nL-s estudiantes son capaces de seleccionar las variables relevantes según su problema de investigación\n2pts\n\n\n3. Operacionalización de variables\nL-s estudiantes son capaces de operacionalizar correctamente las variables de interés. Las variables deben tener un correcto nivel de medición (2pto), correcto paso a NA (1pto), correcto orden de medición, es decir, valores positivos como valores más altos (1pto) y etiquetas correctas (1pto)\n5pts\n\n\n4. Visualización de resultados\nL-s estudiantes son capaces de visualizar correctamente las variables de interés. Se espera que el reporte incluya una tabla descriptiva (3ptos) y dos gráficos univariados (3ptos)\n6ptos\n\n\n5. Interpretación de resultados\nL-s estudiantes son capaces de interpretar correctamente las tablas y gráficos presentados\n3pts\n\n\nTotal\n-\n18puntos"
  },
  {
    "objectID": "assignment/01-trabajo.html",
    "href": "assignment/01-trabajo.html",
    "title": "Trabajo 1. Reporte en Quarto",
    "section": "",
    "text": "El objetivo de este trabajo es realizar un reporte dinámico a través de Quarto, que contenga la introducción y planteamiento de un problema de investigación, fundamentado a través de referencias automáticas desde Zotero. El documento final debe ser subido a Github Pages y se debe enviar el link a este documento para su revisión.\n\n\n\n\nTítulo: Breve, lo principal es hacer alusión al objeto central del estudio.\nIntroducción: Definición de la problemática a abordar, su relevancia y sus principales conceptos asociados (MÁXIMO 1000 palabras)\n\nEs importante considerar\n\nRelevancia del problema de investigación: además de que el “tema” pueda ser relevante (ej: aumento de desigualdad económica, disminución de niveles de participación), la relevancia del problema se refiere al aporte distintivo desde una perspectiva académica y disciplinar (sociología) (ej: “existe evidencia que los bajos niveles de participación se ven afectados por el nivel educacional (Pérez, 1999”).\nPrecisar el concepto central que se va a investigar: Ejemplo “vamos a estudiar participación política de estudiantes, entendiendo por ello la frecuencia de participación en actividades como marchas, tomas y en redes sociales”.\nPrecisar argumento / hipótesis central, que tiene que ver con el predictor principal: “Se espera que a medida que aumenta el nivel de percepción de desigualdad económica, aumenta la participación política de los/as estudiantes”\nSe deben incluir al menos 4 referencias correctamente citadas, según el procedimiento visto en clases de vinculación entre Zotero y RStudio\nEl documento final debe ser subido a Github Pages y se debe enviar el link a este documento para su revisión."
  },
  {
    "objectID": "assignment/01-trabajo.html#objetivos-del-trabajo",
    "href": "assignment/01-trabajo.html#objetivos-del-trabajo",
    "title": "Trabajo 1. Reporte en Quarto",
    "section": "",
    "text": "El objetivo de este trabajo es realizar un reporte dinámico a través de Quarto, que contenga la introducción y planteamiento de un problema de investigación, fundamentado a través de referencias automáticas desde Zotero. El documento final debe ser subido a Github Pages y se debe enviar el link a este documento para su revisión."
  },
  {
    "objectID": "assignment/01-trabajo.html#secciones-del-trabajo",
    "href": "assignment/01-trabajo.html#secciones-del-trabajo",
    "title": "Trabajo 1. Reporte en Quarto",
    "section": "",
    "text": "Título: Breve, lo principal es hacer alusión al objeto central del estudio.\nIntroducción: Definición de la problemática a abordar, su relevancia y sus principales conceptos asociados (MÁXIMO 1000 palabras)\n\nEs importante considerar\n\nRelevancia del problema de investigación: además de que el “tema” pueda ser relevante (ej: aumento de desigualdad económica, disminución de niveles de participación), la relevancia del problema se refiere al aporte distintivo desde una perspectiva académica y disciplinar (sociología) (ej: “existe evidencia que los bajos niveles de participación se ven afectados por el nivel educacional (Pérez, 1999”).\nPrecisar el concepto central que se va a investigar: Ejemplo “vamos a estudiar participación política de estudiantes, entendiendo por ello la frecuencia de participación en actividades como marchas, tomas y en redes sociales”.\nPrecisar argumento / hipótesis central, que tiene que ver con el predictor principal: “Se espera que a medida que aumenta el nivel de percepción de desigualdad económica, aumenta la participación política de los/as estudiantes”\nSe deben incluir al menos 4 referencias correctamente citadas, según el procedimiento visto en clases de vinculación entre Zotero y RStudio\nEl documento final debe ser subido a Github Pages y se debe enviar el link a este documento para su revisión."
  },
  {
    "objectID": "assignment/03-trabajo.html",
    "href": "assignment/03-trabajo.html",
    "title": "Trabajo 3. Asociación de variables y construcción de índices",
    "section": "",
    "text": "El objetivo de este trabajo es realizar un reporte dinámico a través de Quarto, que contenga el análisis descriptivo (trabajo 2) del problema de investigación propuesto en el Trabajo 1 y la visualización e interpretación de la asociación de estas variables. El documento final debe ser subido a Github Pages y se debe enviar el link a este documento para su revisión."
  },
  {
    "objectID": "assignment/03-trabajo.html#objetivos-del-trabajo",
    "href": "assignment/03-trabajo.html#objetivos-del-trabajo",
    "title": "Trabajo 3. Asociación de variables y construcción de índices",
    "section": "",
    "text": "El objetivo de este trabajo es realizar un reporte dinámico a través de Quarto, que contenga el análisis descriptivo (trabajo 2) del problema de investigación propuesto en el Trabajo 1 y la visualización e interpretación de la asociación de estas variables. El documento final debe ser subido a Github Pages y se debe enviar el link a este documento para su revisión."
  },
  {
    "objectID": "assignment/03-trabajo.html#instrucciones-generales",
    "href": "assignment/03-trabajo.html#instrucciones-generales",
    "title": "Trabajo 3. Asociación de variables y construcción de índices",
    "section": "Instrucciones generales",
    "text": "Instrucciones generales\n\nDescargar la base de datos que se utilizará en la investigación y guardarla en la carpeta correspondiente (input)\nOperacionalización: Script de R llamado “Preparacion” y guardado en la carpeta que corresponde (Procesamiento). Manipulación de datos para obtener las variables utilizadas en la investigación. Se espera que l-s estudiantes sean capaces de seleccionar las variables relevantes para la problemática escogida, agruparlas, reordenarlas y asignarles los nombres y etiquetas según corresponda.\nVisualización de datos: Elaboración de tablas y/o gráficos, en el contexto de un reporte científico de investigación, que intente responder, ejemplificar y/o demostrar los principales hallazgos de la investigación. Para esta segunda entrega se espera que sean capaces de generar una tabla de correlaciones que muestre el grado de asociación de las variables utilizadas en la investigación. También se espera que sean capaces de elaborar al menos un índice ponderado y/o una escalados con su respectivo reporte de consistencia interna (alfa de cronbach) según corresponda.\nNo es necesario elaborar un informe teórico sobre el tema de investigación. En la introducción de este reporte debe ir la propuesta elaborada en el Trabajo 1, mencionando la fuente de datos utilizada. En la segunda sección debe ir el reporte descriptivo del trabajo 2. El objetivo de este trabajo 3 es que sean capaces de operacionalizar variables, estimar y visualizar su grado de asociación y construir índices y/o escalas.\n\nEntrega:\n\nJueves 09 de mayo a través de Teams.\nSi se entrega a través de github pages se otorgarán 0,5 décimas adicionales\nNo más de 5000 palabras\nSe deben mantener las referencias de la literatura / bases de datos revisadas\natrasos, 0,5 por día de atraso.\n\nRúbrica de evaluación:\n\n\n\n\n\n\n\n\nÍtem\nObjetivo\nPuntaje\n\n\n\n\n1. Carga y Selección de variables\nL-s estudiantes son capaces de seleccionar las variables relevantes según su problema de investigación\n2pts\n\n\n2. Operacionalización de variables\nL-s estudiantes son capaces de operacionalizar correctamente las variables de interés.\n3pts\n\n\n3. Asociación de variables\nL-s estudiantes son capaces de reportar y visualizar correctamente la asociación entre sus variables. Se espera que el reporte incluya al menos una tabla y/o gráfico\n5ptos\n\n\n4. Construcción de índices y escalas\nL-s estudiantes son capaces de construir al menos un índice ponderado (reportando un autor o informe que justifique la ponderación) y/o una escala con el reporte de su consistencia interna\n5ptos\n\n\n5. Interpretación de resultados\nL-s estudiantes son capaces de interpretar correctamente las tablas y gráficos presentados\n3pts\n\n\nTotal\n-\n18puntos"
  },
  {
    "objectID": "assignment/index.html",
    "href": "assignment/index.html",
    "title": "Trabajos",
    "section": "",
    "text": "En esta sección se encuentran las instrucciones de los Trabajos a realizar durante el curso.\n\nEvaluaciones\nEl curso tendrá tres instancias de evaluación (fechas en pestaña de planificación y en el programa del curso):\n3 trabajos en pares (25% c/u).\n1 examen (25%)."
  },
  {
    "objectID": "ayudantias/index.html",
    "href": "ayudantias/index.html",
    "title": "Sobre el contenido de este apartado",
    "section": "",
    "text": "¡Hola bienvenid_s! Este es un espacio en el que pueden encontrar de forma más detallada lo que se observará de forma práctica en las sesiones de ayudantía. La idea es que este sea un documento muy explicativo y les sirva de recurso al que ustedes puedan recurrir cuando les surja alguna duda. En caso de que la duda persista, no duden en contactarme.\nEspero que les sirva en su camino de aprendizaje por este curso!\n¡¡Muchos saludos!! María Fernanda :)"
  },
  {
    "objectID": "content/02-content.html#lecturas",
    "href": "content/02-content.html#lecturas",
    "title": "Presentación",
    "section": "Lecturas",
    "text": "Lecturas\nR for Data Science"
  },
  {
    "objectID": "content/index.html",
    "href": "content/index.html",
    "title": "Clases",
    "section": "",
    "text": "En esta sección podrán encontrar todas las clases del curso. Se irán subiendo semana a semana."
  },
  {
    "objectID": "herramientas/index.html",
    "href": "herramientas/index.html",
    "title": "Herramientas",
    "section": "",
    "text": "En esta sección encontrarán todas las herramientas y softwares que facilitan el trabajo reproducible.\nEn construcción…"
  },
  {
    "objectID": "practicos/01-content.html",
    "href": "practicos/01-content.html",
    "title": "Asociación con categóricas y Chi-cuadrado",
    "section": "",
    "text": "Tal vez una de las dificultades más comunes o cotidianas del uso de R es el orden de trabajo, en donde tenemos cientos de archivos, scripts, gráficos, bases de datos u otros repartidos desordenadamente en nuestro computador. También se da mucho el caso en que, cuando queremos trabajar con alguien, tenemos que cambiar las rutas de los archivos, por ejemplo en dónde están las bases de datos, ya que nuestros ordenadores y usuarios se llaman y son escencialmente distintos.\n¿Cómo podemos sortear eso? Siguiendo un flujo de trabajo reproducible, autocontenido y ordenado. En este curso trabajaremos R con un flujo de trabajo reproducible, basado en el sistema IPO. El protocolor IPO es una plantilla/protocolo de estructura digital de carpetas que tiene por objetivo el organizar, procesar y documentar los datos de un proyecto de investigación con miras a la apertura de los datos en un repositorio público y de acceso libre. En concreto, el sistema IPO se propone abordar brevemente todo lo referente a los Datos, Métodos y Resultados.\nLleva este nombre por el sistema de carpetas que se implementan: Input, Procesamiento y Output. En la carpeta Input guardaremos todos aquellso recursos iniciales que usaremos, como las bases de datos, el libro de códigos, entre otros. En la carpeta de Procesamiento, como dice el nombre, guardaremos todos los archivos que procesen y analicen datos. En la carpeta Output guardaremos todo aquello que hayamos producido en los archivos de procesamiento, como las bases de datos procesadas listas para compartir o publicas, los documentos de reporte, informes o analísis, gráficos o tablas.\n\n\n\n\n\n\n\n\n\nLa implementación de la reproducibilidad en este tipo de protocolos se basa en generar un conjunto de archivos auto-contenidos organizado en una estructura de proyecto que cualquier persona pueda compartir y ejecutar. En otras palabras, debe tener todo lo que necesita para ejecutar y volver a ejecutar el análisis. Para conocer más, visita el Laboratorio de Ciencia Abierta.\n\n\n\n\n\n\n\n\n\n\n\nUn Rproject es una herramienta de R que nos permite establecer un directorio de trabajo en una carpeta de nuestro computador. Al hacerlo, establecemos un espacio de trabajo que permite crear una estructura de carpetas donde guardar los documentos asociados al proyecto. De esta forma, creamos un conjunto de archivos autocontenidos en un solo lugar que nos permite organizar nuestro trabajo y facilitar la reproducibilidad. En las próximas sesiones estableceremos un protocolo de trabajo que permite organizar y armonizar el trabajo: el protocolo IPO.\nPara crear un Rproject:\n\nAbrir Rstudio\nSeleccionar Archivo -&gt; Nuevo proyecto\n\n\n\nSeleccionamos la opción de directorio existente\nSeleccionamos la carpeta donde descargamos nuestro repositorio de Github en el paso anterior\nApretamos el botón de crear proyecto"
  },
  {
    "objectID": "practicos/01-content.html#rproject",
    "href": "practicos/01-content.html#rproject",
    "title": "Asociación con categóricas y Chi-cuadrado",
    "section": "",
    "text": "Un Rproject es una herramienta de R que nos permite establecer un directorio de trabajo en una carpeta de nuestro computador. Al hacerlo, establecemos un espacio de trabajo que permite crear una estructura de carpetas donde guardar los documentos asociados al proyecto. De esta forma, creamos un conjunto de archivos autocontenidos en un solo lugar que nos permite organizar nuestro trabajo y facilitar la reproducibilidad. En las próximas sesiones estableceremos un protocolo de trabajo que permite organizar y armonizar el trabajo: el protocolo IPO.\nPara crear un Rproject:\n\nAbrir Rstudio\nSeleccionar Archivo -&gt; Nuevo proyecto\n\n\n\nSeleccionamos la opción de directorio existente\nSeleccionamos la carpeta donde descargamos nuestro repositorio de Github en el paso anterior\nApretamos el botón de crear proyecto"
  },
  {
    "objectID": "practicos/01-content.html#recursos-de-la-práctica",
    "href": "practicos/01-content.html#recursos-de-la-práctica",
    "title": "Asociación con categóricas y Chi-cuadrado",
    "section": "Recursos de la práctica",
    "text": "Recursos de la práctica\nEn esta práctica trabajaremos con un subconjunto de datos previamente procesados de la Encuesta de Caracterización Socioeconómica (CASEN) del año 2022, elaborada por el Ministerio de Desarrollo Social y Familia. Para este ejercicio, obtendremos directamente esta base desde internet. No obstante, también tienes la opción de acceder a la misma información a través del siguiente enlace:  CASEN 20222. Desde allí, podrás descargar el archivo que contiene el subconjunto procesado de la base de datos CASEN 2022."
  },
  {
    "objectID": "practicos/03-content.html",
    "href": "practicos/03-content.html",
    "title": "Análisis de correspondencia múltiple",
    "section": "",
    "text": "La siguiente práctica tiene el objetivo de introducir la idea central del análisis de correspondencia. Para ello, utilizaremos la base de datos de la cuarta ola del Estudio Longitudinal Social de Chile (2019) con el objetivo de analizar agrupaciones de variables categóricas nominales."
  },
  {
    "objectID": "practicos/03-content.html#probemos-otra-correspondencia-simple",
    "href": "practicos/03-content.html#probemos-otra-correspondencia-simple",
    "title": "Análisis de correspondencia múltiple",
    "section": "Probemos otra correspondencia simple",
    "text": "Probemos otra correspondencia simple\n\n\nCódigo\ntabla &lt;- prop.table(table(proc_data$educacion, proc_data$aut_demo))\ndimnames(tabla) &lt;- list(educacion=c(\"Básica\", \"Media\", \"Universitaria\"),\n                        aut_demo=c(\"Democracia\", \"Autoritarismo\", \"Da lo mismo\",\"Ninguno\")\n                        )\ntabla\n\n\n               aut_demo\neducacion       Democracia Autoritarismo Da lo mismo    Ninguno\n  Básica        0.10680191    0.01998807  0.07875895 0.02058473\n  Media         0.23359189    0.03550119  0.11634845 0.03490453\n  Universitaria 0.25924821    0.03251790  0.03729117 0.02446301\n\n\nCódigo\nACS &lt;- CA(tabla, ncp=2, graph = FALSE)\nsummary(ACS)\n\n\n\nCall:\nCA(X = tabla, ncp = 2, graph = FALSE) \n\nThe chi square of independence between the two variables is equal to 0.06017212 (p-value =  0.9999956 ).\n\nEigenvalues\n                       Dim.1   Dim.2\nVariance               0.060   0.000\n% of var.             99.875   0.125\nCumulative % of var.  99.875 100.000\n\nRows\n                Iner*1000    Dim.1    ctr   cos2    Dim.2    ctr   cos2  \nBásica        |    19.531 |  0.294 32.443  0.998 |  0.012 44.944  0.002 |\nMedia         |     5.028 |  0.109  8.304  0.993 | -0.009 49.662  0.007 |\nUniversitaria |    35.614 | -0.317 59.254  1.000 |  0.003  5.394  0.000 |\n\nColumns\n                Iner*1000    Dim.1    ctr   cos2    Dim.2    ctr   cos2  \nDemocracia    |    18.006 | -0.173 29.949  1.000 | -0.003  9.468  0.000 |\nAutoritarismo |     0.124 | -0.027  0.107  0.518 |  0.026 79.512  0.482 |\nDa lo mismo   |    41.134 |  0.421 68.441  1.000 | -0.004  4.276  0.000 |\nNinguno       |     0.908 |  0.106  1.503  0.994 |  0.008  6.744  0.006 |\n\n\n\n\nCódigo\n#Representación simultánea\nplot.CA(ACS)"
  },
  {
    "objectID": "practicos/03-content.html#y-con-más-categorías-de-respuesta",
    "href": "practicos/03-content.html#y-con-más-categorías-de-respuesta",
    "title": "Análisis de correspondencia múltiple",
    "section": "Y con más categorías de respuesta?",
    "text": "Y con más categorías de respuesta?\n\n\nCódigo\ntabla &lt;- prop.table(table(proc_data$educacion, proc_data$coalicion))\ndimnames(tabla) &lt;- list(educacion=c(\"Básica\", \"Media\", \"Universitaria\"),\n                        coalicion=c(\"Chile vamos\", \"Nueva mayoría\", \"Frente Amplio\", \"Otro\", \"Ninguno\")\n                        )\ntabla\n\n\n               coalicion\neducacion       Chile vamos Nueva mayoría Frente Amplio        Otro     Ninguno\n  Básica        0.018412315   0.012677332   0.008753396 0.000000000 0.185934199\n  Media         0.029882282   0.017506791   0.022638092 0.002112889 0.347721099\n  Universitaria 0.031995171   0.023845457   0.039239360 0.003923936 0.255357682\n\n\nCódigo\nACS &lt;- CA(tabla, ncp=2, graph = FALSE)\nsummary(ACS)\n\n\n\nCall:\nCA(X = tabla, ncp = 2, graph = FALSE) \n\nThe chi square of independence between the two variables is equal to 0.02238892 (p-value =  1 ).\n\nEigenvalues\n                       Dim.1   Dim.2\nVariance               0.021   0.002\n% of var.             92.772   7.228\nCumulative % of var.  92.772 100.000\n\nRows\n                Iner*1000    Dim.1    ctr   cos2    Dim.2    ctr   cos2  \nBásica        |     4.972 | -0.134 19.419  0.811 |  0.064 58.004  0.189 |\nMedia         |     4.164 | -0.091 16.838  0.840 | -0.040 41.176  0.160 |\nUniversitaria |    13.253 |  0.193 63.744  0.999 |  0.006  0.820  0.001 |\n\nColumns\n                Iner*1000    Dim.1    ctr   cos2    Dim.2    ctr   cos2  \nChile vamos   |     0.881 |  0.086  2.866  0.676 |  0.060 17.633  0.324 |\nNueva mayoría |     2.354 |  0.169  7.441  0.656 |  0.122 49.971  0.344 |\nFrente Amplio |    12.973 |  0.427 62.062  0.994 | -0.034  5.119  0.006 |\nOtro          |     2.922 |  0.650 12.285  0.873 | -0.248 22.892  0.127 |\nNinguno       |     3.259 | -0.064 15.346  0.978 | -0.009  4.384  0.022 |\n\n\n\n\nCódigo\n#Representación simultánea\nplot.CA(ACS)"
  },
  {
    "objectID": "practicos/03-content.html#y-si-juntamos-otras-cuál-sería-nuestra-variable-dependiente",
    "href": "practicos/03-content.html#y-si-juntamos-otras-cuál-sería-nuestra-variable-dependiente",
    "title": "Análisis de correspondencia múltiple",
    "section": "Y si juntamos otras? ¿cuál sería nuestra variable dependiente?",
    "text": "Y si juntamos otras? ¿cuál sería nuestra variable dependiente?\n\n\nCódigo\ntabla &lt;- prop.table(table(proc_data$coalicion, proc_data$aut_demo))\ndimnames(tabla) &lt;- list(coalicion=c(\"Chile vamos\", \"Nueva mayoría\", \"Frente Amplio\", \"Otro\", \"Ninguno\"),\n                        aut_demo=c(\"Democracia\", \"Autoritarismo\", \"Da lo mismo\",\"Ninguno\")\n                        )\ntabla\n\n\n               aut_demo\ncoalicion         Democracia Autoritarismo  Da lo mismo      Ninguno\n  Chile vamos   0.0459418070  0.0156202144 0.0165390505 0.0021439510\n  Nueva mayoría 0.0392036753  0.0055130168 0.0079632466 0.0015313936\n  Frente Amplio 0.0581929556  0.0033690658 0.0088820827 0.0009188361\n  Otro          0.0049004594  0.0006125574 0.0003062787 0.0003062787\n  Ninguno       0.4532924962  0.0606431853 0.1996937213 0.0744257274\n\n\nCódigo\nACS &lt;- CA(tabla, ncp=3, graph = FALSE)\n\n\n\n\nCódigo\n#Representación simultánea\nplot.CA(ACS)"
  },
  {
    "objectID": "practicos/03-content.html#eigen-values-varianza",
    "href": "practicos/03-content.html#eigen-values-varianza",
    "title": "Análisis de correspondencia múltiple",
    "section": "Eigen values / Varianza",
    "text": "Eigen values / Varianza\nSiguiendo la lógica del análisis que existe en el Análisis de Componentes Principales, que permite “reducir” las dimensiones de un data frame a partir de generar nuevos ejes o componentes que sirven a manera de “resumen” de las variables cuantitativas originales, en el análisis MCA también es posible construir dichos componentes o ejes a partir de variables categóricas.\nUna vez que se generan los nuevos componentes, es importante identificar la capacidad explicativa del total de los casos que cada una proporciona. Para ello es importante revisar la proporción de varianzas que “retiene” cada una de estas dimensiones o ejes. Y puede ser extraído a partir de la función get_eigenvalue() de la siguiente manera:\n\n\nCódigo\neig_val &lt;- factoextra::get_eigenvalue(ACM)\nhead(eig_val, 10)\n\n\n      eigenvalue variance.percent cumulative.variance.percent\nDim.1  0.4229843        14.099478                    14.09948\nDim.2  0.3833712        12.779041                    26.87852\nDim.3  0.3427139        11.423796                    38.30231\nDim.4  0.3387669        11.292229                    49.59454\nDim.5  0.3304430        11.014766                    60.60931\nDim.6  0.3247917        10.826389                    71.43570\nDim.7  0.2977398         9.924659                    81.36036\nDim.8  0.2850535         9.501784                    90.86214\nDim.9  0.2741358         9.137859                   100.00000\n\n\nEn la tabla anterior se muestran del lado de las columnas los componentes o ejes nuevos, resultados del análisis MCA, mientras que en la primer columna se muestran los eigenvalores o el tamaño de las varianzas que explica cada uno, mientras que en la segunda columna se muestra el porcentaje de la varianza total que es explicado por cada eje o dimensión. En la tercer columna se muestra el porcentaje de varianza acumulado.\nTambién es posible visualizar los porcentajes de varianza explicados por cada dimensión MCA, a partir de usar el comando fviz_screeplot(), con el que se puede crear un “scree plot.”\n\n\nCódigo\nfviz_screeplot(ACM, addlabels = TRUE)\n\n\n\n\n\nSi una dimensión explica, por ejemplo, el 14.1% de la inercia o varianza, significa que la mayoría de la variabilidad en las relaciones entre categorías puede entenderse a través de esta dimensión.\nEs importante interpretar el contenido de cada dimensión. A menudo, la primera dimensión puede representar la principal diferencia entre grupos de categorías (por ejemplo, ideología política en una encuesta de actitudes), mientras que la segunda dimensión podría representar una diferencia secundaria (como la educación o el nivel socioeconómico)."
  },
  {
    "objectID": "practicos/03-content.html#representación-gráfica",
    "href": "practicos/03-content.html#representación-gráfica",
    "title": "Análisis de correspondencia múltiple",
    "section": "Representación gráfica",
    "text": "Representación gráfica\n\n\nCódigo\nfviz_mca_var(ACM, #objeto tipo lista con resultados mca\n             col.var = \"contrib\", #definición de los colores a partir del valor cos2\n             gradient.cols = c(\"#00AFBB\", \"#E7B800\", \"#FC4E07\"), #definición de la paleta de colores\n             repel = TRUE, # evitar solapamientos de etiquetas,\n             max.overlaps = \"ggrepel.max.overlaps\", #aumentar el tamaño de solapamientos\n             ggtheme = theme_minimal()\n             )\n\n\n\n\n\nPodemos interpretar este gráfico de una forma similar al de un ACS, pero además podemos identificar de mejor manera la agrupación de ciertas categorías de variables. ¿Existe algún patrón que identificar?"
  },
  {
    "objectID": "practicos/03-content.html#con-todas-las-variables",
    "href": "practicos/03-content.html#con-todas-las-variables",
    "title": "Análisis de correspondencia múltiple",
    "section": "Con todas las variables",
    "text": "Con todas las variables\n\n\nCódigo\nACM &lt;- proc_data %&gt;% na.omit() %&gt;% \n    MCA(, graph = FALSE)\n\n\n\n\nCódigo\nfviz_screeplot(ACM, addlabels = TRUE)\n\n\n\n\n\n\n\nCódigo\nfviz_mca_var(ACM, #objeto tipo lista con resultados mca\n             col.var = \"cos2\", #definición de los colores a partir del valor cos2\n             gradient.cols = c(\"#00AFBB\", \"#E7B800\", \"#FC4E07\"), #definición de la paleta de colores\n             repel = TRUE, # evitar solapamientos de etiquetas,\n             max.overlaps = \"ggrepel.max.overlaps\", #aumentar el tamaño de solapamientos\n             ggtheme = theme_minimal()\n             )"
  },
  {
    "objectID": "practicos/05-content.html",
    "href": "practicos/05-content.html",
    "title": "Práctico 5. Índices y escalas",
    "section": "",
    "text": "El Programa de las Naciones Unidas para el Desarrollo (PNUD) es la agencia de la Organización de las Naciones Unidas encargada de promover el desarrollo sostenible a nivel mundial, y uno de sus enfoques es la erradicación de la pobreza. En este contexto, el PNUD reconoce la importancia de abordar la pobreza multidimensional para lograr un desarrollo sostenible y mejorar el bienestar de las personas en todas las dimensiones de sus vidas.\nDesde el año 2016 Chile cuenta con la medida actual de pobreza multidimensional. El propósito de esta medida es complementar la medición de la pobreza basada en ingresos con un indicador que refleje las condiciones de vida de la población en aspectos relevantes para el bienestar social y una vida digna. Desde su creación, se ha buscado obtener un diagnóstico más completo de la pobreza y contar con una herramienta útil para el diseño, implementación, monitoreo y evaluación de políticas públicas.\nInicialmente, la medida de pobreza multidimensional incluyó 4 dimensiones (Educación, Salud, Trabajo y Seguridad Social, y Vivienda) con tres indicadores por dimensión (12 indicadores en total), cada uno con igual ponderación (8,3%), por lo tanto, con dimensiones cuyo peso representan el 25% de la medida.Posteriormente, con los resultados de la encuesta Casen 2015 se incorpora una quinta dimensión de Redes y Cohesión Social y se amplía la dimensión de Vivienda para incluir el concepto de Entorno. Desde entonces, la medida ha estado compuesta por 5 dimensiones (Educación, Salud, Trabajo y Seguridad Social, Vivienda y Entorno, y Redes y Cohesión Social), manteniendo la definición de 3 indicadores por dimensión, de modo que la medida queda compuesta por 15 indicadores. Respecto del peso de las dimensiones, con el fin de favorecer cierta estabilidad de la medida, la dimensión de Redes y Cohesión Social se incorpora con un peso de 10% y se mantiene la igualdad de ponderación entre las demás dimensiones, ahora con una ponderación de 22,5%.\n\n\n\nEl objetivo de este ejercicio práctico es comprender y estimar el proceso de construcción de índices ponderados y no ponderados en R.\n\n\n\n\n\nCódigo\npacman::p_load(tidyverse, #Conjunto de paquetes, sobre todo dplyr y ggplot2\n               car, #Para recodificar\n               haven,\n               summarytools, #Para descriptivos\n               sjmisc,\n               psych,     # para Alfa de Chronbach\n               sjPlot)\n\noptions(scipen = 999) # para desactivar notacion cientifica\nrm(list = ls()) # para limpiar el entorno de trabajo\n\n\n\n\n\nLa base de datos a utilizar es la CASEN 2022 (Encuesta de Caracterización Socioeconómica Nacional). La base de datos está disponible en este link y el cuestionario en este link.\nSin embargo, para realizar este ejercicio práctico utilizaremos una muestra aleatoria de esta base de datos para simplificar el proceso de construcción de índices. El código que crea este subset está disponible acá\n\n\n\n\nCódigo\nload(url(\"https://github.com/cursos-metodos-facso/investigacion-cuantitativa/raw/main/files/data/casen2022.RData\")) #Cargar base de datos\n\n\n\n\n\n\n\nCódigo\nview(dfSummary(casen2022, headings=FALSE, graph.col = FALSE))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNo\nVariable\nLabel\nStats / Values\nFreqs (% of Valid)\nValid\nMissing\n\n\n\n\n1\nasistencia [haven_labelled, vctrs_vctr, double]\nHogar carente en asistencia\n\n\n\nMin : 0\n\n\nMean : 0\n\n\nMax : 1\n\n\n\n\n\n\n0\n:\n9815\n(\n98.2%\n)\n\n\n1\n:\n185\n(\n1.8%\n)\n\n\n\n10000 (100.0%)\n0 (0.0%)\n\n\n2\nrezago [haven_labelled, vctrs_vctr, double]\nHogar carente en rezago escolar\n\n\n\nMin : 0\n\n\nMean : 0\n\n\nMax : 1\n\n\n\n\n\n\n0\n:\n9911\n(\n99.1%\n)\n\n\n1\n:\n89\n(\n0.9%\n)\n\n\n\n10000 (100.0%)\n0 (0.0%)\n\n\n3\nescolaridad [haven_labelled, vctrs_vctr, double]\nHogar carente en escolaridad\n\n\n\nMin : 0\n\n\nMean : 0.3\n\n\nMax : 1\n\n\n\n\n\n\n0\n:\n6944\n(\n69.5%\n)\n\n\n1\n:\n3046\n(\n30.5%\n)\n\n\n\n9990 (99.9%)\n10 (0.1%)\n\n\n4\nmalnutricion [haven_labelled, vctrs_vctr, double]\nHogar carente en malnutrición en niños/as\n\n\n\nMin : 0\n\n\nMean : 0\n\n\nMax : 1\n\n\n\n\n\n\n0\n:\n9694\n(\n97.0%\n)\n\n\n1\n:\n301\n(\n3.0%\n)\n\n\n\n9995 (100.0%)\n5 (0.0%)\n\n\n5\nsist_salud [haven_labelled, vctrs_vctr, double]\nHogar carente en adscripción a sistema de salud\n\n\n\nMin : 0\n\n\nMean : 0\n\n\nMax : 1\n\n\n\n\n\n\n0\n:\n9592\n(\n96.1%\n)\n\n\n1\n:\n390\n(\n3.9%\n)\n\n\n\n9982 (99.8%)\n18 (0.2%)\n\n\n6\natencion [haven_labelled, vctrs_vctr, double]\nHogar carente en atención\n\n\n\nMin : 0\n\n\nMean : 0.1\n\n\nMax : 1\n\n\n\n\n\n\n0\n:\n9476\n(\n94.8%\n)\n\n\n1\n:\n521\n(\n5.2%\n)\n\n\n\n9997 (100.0%)\n3 (0.0%)\n\n\n7\nocupacion [haven_labelled, vctrs_vctr, double]\nHogar carente en ocupación\n\n\n\nMin : 0\n\n\nMean : 0.1\n\n\nMax : 1\n\n\n\n\n\n\n0\n:\n8994\n(\n89.9%\n)\n\n\n1\n:\n1006\n(\n10.1%\n)\n\n\n\n10000 (100.0%)\n0 (0.0%)\n\n\n8\nseg_social [haven_labelled, vctrs_vctr, double]\nHogar carente en seguridad social\n\n\n\nMin : 0\n\n\nMean : 0.3\n\n\nMax : 1\n\n\n\n\n\n\n0\n:\n7011\n(\n70.5%\n)\n\n\n1\n:\n2934\n(\n29.5%\n)\n\n\n\n9945 (99.4%)\n55 (0.5%)\n\n\n9\njubilacion [haven_labelled, vctrs_vctr, double]\nHogar carente en jubilaciones\n\n\n\nMin : 0\n\n\nMean : 0.1\n\n\nMax : 1\n\n\n\n\n\n\n0\n:\n8828\n(\n88.3%\n)\n\n\n1\n:\n1172\n(\n11.7%\n)\n\n\n\n10000 (100.0%)\n0 (0.0%)\n\n\n10\nhabitabilidad [haven_labelled, vctrs_vctr, double]\nHogar carente en habitabilidad\n\n\n\nMin : 0\n\n\nMean : 0.2\n\n\nMax : 1\n\n\n\n\n\n\n0\n:\n8372\n(\n83.8%\n)\n\n\n1\n:\n1620\n(\n16.2%\n)\n\n\n\n9992 (99.9%)\n8 (0.1%)\n\n\n11\nhacinamiento [haven_labelled, vctrs_vctr, double]\nHogar carente en hacinamiento\n\n\n\nMin : 0\n\n\nMean : 0\n\n\nMax : 1\n\n\n\n\n\n\n0\n:\n9576\n(\n95.8%\n)\n\n\n1\n:\n415\n(\n4.2%\n)\n\n\n\n9991 (99.9%)\n9 (0.1%)\n\n\n12\nvivienda [haven_labelled, vctrs_vctr, double]\nHogar carente en estado de la vivienda\n\n\n\nMin : 0\n\n\nMean : 0.1\n\n\nMax : 1\n\n\n\n\n\n\n0\n:\n8687\n(\n86.9%\n)\n\n\n1\n:\n1313\n(\n13.1%\n)\n\n\n\n10000 (100.0%)\n0 (0.0%)\n\n\n13\nserv_basicos [haven_labelled, vctrs_vctr, double]\nHogar carente en servicios básicos\n\n\n\nMin : 0\n\n\nMean : 0.1\n\n\nMax : 1\n\n\n\n\n\n\n0\n:\n9218\n(\n92.2%\n)\n\n\n1\n:\n782\n(\n7.8%\n)\n\n\n\n10000 (100.0%)\n0 (0.0%)\n\n\n14\nentorno [haven_labelled, vctrs_vctr, double]\nHogar carente en entorno\n\n\n\nMin : 0\n\n\nMean : 0.1\n\n\nMax : 1\n\n\n\n\n\n\n0\n:\n8772\n(\n88.0%\n)\n\n\n1\n:\n1191\n(\n12.0%\n)\n\n\n\n9963 (99.6%)\n37 (0.4%)\n\n\n15\nap_part_social [haven_labelled, vctrs_vctr, double]\nHogar carente en apoyo y participación social\n\n\n\nMin : 0\n\n\nMean : 0.1\n\n\nMax : 1\n\n\n\n\n\n\n0\n:\n9315\n(\n93.5%\n)\n\n\n1\n:\n652\n(\n6.5%\n)\n\n\n\n9967 (99.7%)\n33 (0.3%)\n\n\n16\ntrato [haven_labelled, vctrs_vctr, double]\nHogar carente en trato igualitario\n\n\n\nMin : 0\n\n\nMean : 0.2\n\n\nMax : 1\n\n\n\n\n\n\n0\n:\n8443\n(\n84.4%\n)\n\n\n1\n:\n1557\n(\n15.6%\n)\n\n\n\n10000 (100.0%)\n0 (0.0%)\n\n\n17\nseguridad [haven_labelled, vctrs_vctr, double]\nHogar carente en seguridad\n\n\n\nMin : 0\n\n\nMean : 0.1\n\n\nMax : 1\n\n\n\n\n\n\n0\n:\n9057\n(\n90.6%\n)\n\n\n1\n:\n943\n(\n9.4%\n)\n\n\n\n10000 (100.0%)\n0 (0.0%)\n\n\n18\nregion [haven_labelled, vctrs_vctr, double]\nRegión\n\n\n\nMean (sd) : 8.8 (4.3)\n\n\nmin ≤ med ≤ max:\n\n\n1 ≤ 8 ≤ 16\n\n\nIQR (CV) : 8 (0.5)\n\n\n\n16 distinct values\n10000 (100.0%)\n0 (0.0%)\n\n\n19\narea [haven_labelled, vctrs_vctr, double]\nÁrea\n\n\n\nMin : 1\n\n\nMean : 1.2\n\n\nMax : 2\n\n\n\n\n\n\n1\n:\n7907\n(\n79.1%\n)\n\n\n2\n:\n2093\n(\n20.9%\n)\n\n\n\n10000 (100.0%)\n0 (0.0%)\n\n\n\n\nGenerated by summarytools 1.0.1 (R version 4.3.2)2024-11-19\n\n\n\nEn esta base de datos, las variables de interés que están presentes (ej. asistencia, rezago, escolaridad) son variables dummy, es decir, variables que tienen como valores posibles 0 y 1. Donde 0 implica la ausencia de un atributo y 1 la presencia del mismo atributo.\nPara medir pobreza multidimensional, 1 indica la carencia de un servicio o cualidad, por ejemplo, se considera que un hogar es carente en escolaridad si al menos uno de sus integrantes mayores de 18 años ha alcanzado menos años de escolaridad que los establecidos por ley, de acuerdo a su edad. Por lo tanto, en la variable escolaridad 1) indica un hogar carente en escolaridad, que según nuestra base de datos corresponde a 3065 hogares (30.7% de nuestra sub-muestra).\n\n\n\n\n\nSeleccionamos solo los indicadores que eran utilizados hasta 2014\n\n\nCódigo\nindicadores2014 &lt;- casen2022 %&gt;% select(asistencia, \n                                        rezago, \n                                        escolaridad, \n                                        malnutricion, \n                                        sist_salud, \n                                        atencion, \n                                        ocupacion, \n                                        seg_social, \n                                        jubilacion, \n                                        hacinamiento, \n                                        estado_vivienda=vivienda, \n                                        serv_basicos)  %&gt;% \n  na.omit() %&gt;% # Eliminar Na's\n  mutate_all(~(as.numeric(.))) # Convertimos todas las variables a numéricas\n\n\nCon la función mutate creamos una nueva variable para cada dimensión, que contenga el promedio simple de los tres indicadores correspondientes.\n\n\nCódigo\nindicadores2014 = indicadores2014 %&gt;% \n  rowwise() %&gt;%\n  mutate(educ = mean(c(asistencia, rezago, escolaridad)),\n         salud = mean(c(malnutricion, sist_salud, atencion)),\n         trabajo= mean(c(ocupacion, seg_social, jubilacion)),\n         vivienda= mean(c(hacinamiento, estado_vivienda, serv_basicos))) %&gt;% \n  ungroup()\n\n\nLuego, como la pobreza multidimensional consideraba cuatro dimensiones equivalentes (sin ponderar), es posible obtener el índice de pobreza multidimensional a partir del promedio de las cuatro dimensiones.\n\n\nCódigo\nindicadores2014 = indicadores2014 %&gt;% \n  rowwise() %&gt;%\n  mutate(pobreza = mean(c(educ, salud, trabajo, vivienda))) %&gt;% \n  ungroup()\n\n\nLo que nos da este resultado:\n\n\nCódigo\nindicadores2014 %&gt;% select(pobreza) %&gt;% head(10) # Primeros 10 casos\n\n\n# A tibble: 10 × 1\n   pobreza\n     &lt;dbl&gt;\n 1  0.167 \n 2  0.25  \n 3  0     \n 4  0.167 \n 5  0.167 \n 6  0.167 \n 7  0     \n 8  0.167 \n 9  0     \n10  0.0833\n\n\nCódigo\nsummary(indicadores2014$pobreza) # Resumen\n\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n0.00000 0.00000 0.08333 0.10142 0.16667 0.66667 \n\n\n¿Cómo podemos conocer el porcentaje total de pobreza multidimensional del país?\nEl PNUD considera como límite para el índice de cuatro dimensiones un 25% de pobreza multidimensional (lo que equivale a tener carencia en los tres indicadores de una dimensión). Por lo tanto, podemos utilizar un condicional que indique “si” existe pobreza muldimensional cuando nuestra variable “pobreza” sea mayor o igual a 0.25 y que indique que “no” existe pobreza multidimensional cuando la variable “pobreza” sea menor a 0.25. case_when viene en dplyr.\n\n\nCódigo\nindicadores2014 &lt;- indicadores2014 %&gt;% mutate(pobreza = case_when(pobreza&gt;=0.25~\"si\",\n                                                      pobreza&lt;0.25~\"no\")\n                           )\nprop.table(table(indicadores2014$pobreza))*100\n\n\n\n      no       si \n87.03161 12.96839 \n\n\nSegún el análisis realizado con la submuestra aleatoria de la CASEN, considerando las cuatro dimensiones que se utilizaban hasta el 2014, existe un 12.97% de pobreza multidimensional en Chile\n\n\n\nVeamos ahora el mismo proceso, pero considerando la quinta dimensión que fue agregada en 2016 sobre Redes y Cohesión Social.\n\nEn esta operacionalización del índice de pobreza multidimensional las cuatro dimensiones originales equivalen a un 22.5% cada una, mientras que la nueva dimensión de redes y cohesión social equivale a un 10%.\nSeleccionemos solo los indicadores que son utilizados desde 2016.\n\n\nCódigo\nindicadores2016 &lt;- casen2022 %&gt;% select(asistencia, \n                                        rezago, \n                                        escolaridad, \n                                        malnutricion, \n                                        sist_salud, \n                                        atencion, \n                                        ocupacion, \n                                        seg_social, \n                                        jubilacion, \n                                        habitabilidad, \n                                        serv_basicos,\n                                        entorno,\n                                        ap_part_social,\n                                        trato,\n                                        seguridad,\n                                        area,\n                                        region) %&gt;% \n  na.omit() %&gt;% # Eliminar Na's\n  mutate_all(~(as.numeric(.))) # Convertimos todas las variables a numéricas\n\n\nSeguimos los mismos pasos que con el índice anterior, estimando un promedio simple para cada una de las dimensiones.\n\n\nCódigo\nindicadores2016 = indicadores2016 %&gt;% \n  rowwise() %&gt;%\n  mutate(educ = mean(c(asistencia, rezago, escolaridad)),\n         salud = mean(c(malnutricion, sist_salud, atencion)),\n         trabajo= mean(c(ocupacion, seg_social, jubilacion)),\n         vivienda= mean(c(habitabilidad, serv_basicos, entorno)),\n         redes_cohesion= mean(c(ap_part_social, trato, seguridad))) %&gt;% \n  ungroup()\n\n\nSin embargo, como en esta ocasión se trata de un índice ponderado (con dimensiones con distinto peso cada una), multiplicamos cada dimensión por su peso correspondiente y las sumamos.\n\n\nCódigo\nindicadores2016 = indicadores2016 %&gt;% \n  rowwise() %&gt;%\n  mutate(pobreza_pond = (educ*22.5) + (salud*22.5) + (trabajo*22.5) + (vivienda*22.5) + (redes_cohesion*10)) %&gt;%  \n  ungroup()\n\n\nLo que nos da este resultado:\n\n\nCódigo\nindicadores2016 %&gt;% select(pobreza_pond) %&gt;% head(10) # Primeros 10 casos\n\n\n# A tibble: 10 × 1\n   pobreza_pond\n          &lt;dbl&gt;\n 1        18.3 \n 2        22.5 \n 3         3.33\n 4        22.5 \n 5        15   \n 6        15   \n 7         0   \n 8        15   \n 9         0   \n10        18.3 \n\n\nCódigo\nsummary(indicadores2016$pobreza_pond) # Resumen\n\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  0.000   3.333   7.500  10.988  15.000  62.500 \n\n\n¿Cómo podemos conocer el porcentaje total de pobreza multidimensional del país?\nEl PNUD considera como límite para el índice de cinco dimensiones un 22.5% de pobreza multidimensional (lo que equivale a tener carencia en los tres indicadores de una dimensión). Por lo tanto, podemos utilizar un condicional que indique “si” existe pobreza muldimensional cuando nuestra variable “pobreza” sea mayor o igual a 22.5 y que indique que “no” existe pobreza multidimensional cuando la variable “pobreza” sea menor a 22.5.\n\n\nCódigo\nindicadores2016 &lt;- indicadores2016 %&gt;% mutate(pobreza = case_when(pobreza_pond&gt;=22.5~\"si\",\n                                                      pobreza_pond&lt;22.5~\"no\")\n                           )\n                          \nprop.table(table(indicadores2016$pobreza))*100\n\n\n\n      no       si \n84.18912 15.81088 \n\n\nSegún el análisis realizado con la submuestra aleatoria de la CASEN, considerando las cinco dimensiones que se comenzaron a utilizar en 2016, existe un 15.73% de pobreza multidimensional en Chile.\n\n\nPodemos utilizar otras variables de la CASEN para poder conocer cómo se distribuye la pobreza multidimensional en Chile. Por ejemplo, porcentaje de pobreza multidimensional por región:\n\n\nCódigo\nprop.table(table(indicadores2016$region, indicadores2016$pobreza), margin = 1)\n\n\n    \n            no        si\n  1  0.7965261 0.2034739\n  2  0.7975000 0.2025000\n  3  0.8097345 0.1902655\n  4  0.8484108 0.1515892\n  5  0.8487230 0.1512770\n  6  0.8826025 0.1173975\n  7  0.8703170 0.1296830\n  8  0.8543689 0.1456311\n  9  0.8083736 0.1916264\n  10 0.7571702 0.2428298\n  11 0.8910891 0.1089109\n  12 0.9531250 0.0468750\n  13 0.8496241 0.1503759\n  14 0.8079096 0.1920904\n  15 0.8575198 0.1424802\n  16 0.8536585 0.1463415\n\n\no pobreza multidimensional por zona geográfica 1) urbano 2) rural\n\n\nCódigo\nprop.table(table(indicadores2016$area, indicadores2016$pobreza), margin = 1)\n\n\n   \n           no        si\n  1 0.8735691 0.1264309\n  2 0.7223301 0.2776699"
  },
  {
    "objectID": "practicos/05-content.html#presentación",
    "href": "practicos/05-content.html#presentación",
    "title": "Práctico 5. Índices y escalas",
    "section": "",
    "text": "El Programa de las Naciones Unidas para el Desarrollo (PNUD) es la agencia de la Organización de las Naciones Unidas encargada de promover el desarrollo sostenible a nivel mundial, y uno de sus enfoques es la erradicación de la pobreza. En este contexto, el PNUD reconoce la importancia de abordar la pobreza multidimensional para lograr un desarrollo sostenible y mejorar el bienestar de las personas en todas las dimensiones de sus vidas.\nDesde el año 2016 Chile cuenta con la medida actual de pobreza multidimensional. El propósito de esta medida es complementar la medición de la pobreza basada en ingresos con un indicador que refleje las condiciones de vida de la población en aspectos relevantes para el bienestar social y una vida digna. Desde su creación, se ha buscado obtener un diagnóstico más completo de la pobreza y contar con una herramienta útil para el diseño, implementación, monitoreo y evaluación de políticas públicas.\nInicialmente, la medida de pobreza multidimensional incluyó 4 dimensiones (Educación, Salud, Trabajo y Seguridad Social, y Vivienda) con tres indicadores por dimensión (12 indicadores en total), cada uno con igual ponderación (8,3%), por lo tanto, con dimensiones cuyo peso representan el 25% de la medida.Posteriormente, con los resultados de la encuesta Casen 2015 se incorpora una quinta dimensión de Redes y Cohesión Social y se amplía la dimensión de Vivienda para incluir el concepto de Entorno. Desde entonces, la medida ha estado compuesta por 5 dimensiones (Educación, Salud, Trabajo y Seguridad Social, Vivienda y Entorno, y Redes y Cohesión Social), manteniendo la definición de 3 indicadores por dimensión, de modo que la medida queda compuesta por 15 indicadores. Respecto del peso de las dimensiones, con el fin de favorecer cierta estabilidad de la medida, la dimensión de Redes y Cohesión Social se incorpora con un peso de 10% y se mantiene la igualdad de ponderación entre las demás dimensiones, ahora con una ponderación de 22,5%."
  },
  {
    "objectID": "practicos/05-content.html#objetivo-general",
    "href": "practicos/05-content.html#objetivo-general",
    "title": "Práctico 5. Índices y escalas",
    "section": "",
    "text": "El objetivo de este ejercicio práctico es comprender y estimar el proceso de construcción de índices ponderados y no ponderados en R."
  },
  {
    "objectID": "practicos/05-content.html#cargar-paquetes",
    "href": "practicos/05-content.html#cargar-paquetes",
    "title": "Práctico 5. Índices y escalas",
    "section": "",
    "text": "Código\npacman::p_load(tidyverse, #Conjunto de paquetes, sobre todo dplyr y ggplot2\n               car, #Para recodificar\n               haven,\n               summarytools, #Para descriptivos\n               sjmisc,\n               psych,     # para Alfa de Chronbach\n               sjPlot)\n\noptions(scipen = 999) # para desactivar notacion cientifica\nrm(list = ls()) # para limpiar el entorno de trabajo"
  },
  {
    "objectID": "practicos/05-content.html#datos-y-variables",
    "href": "practicos/05-content.html#datos-y-variables",
    "title": "Práctico 5. Índices y escalas",
    "section": "",
    "text": "La base de datos a utilizar es la CASEN 2022 (Encuesta de Caracterización Socioeconómica Nacional). La base de datos está disponible en este link y el cuestionario en este link.\nSin embargo, para realizar este ejercicio práctico utilizaremos una muestra aleatoria de esta base de datos para simplificar el proceso de construcción de índices. El código que crea este subset está disponible acá\n\n\n\n\nCódigo\nload(url(\"https://github.com/cursos-metodos-facso/investigacion-cuantitativa/raw/main/files/data/casen2022.RData\")) #Cargar base de datos\n\n\n\n\n\n\n\nCódigo\nview(dfSummary(casen2022, headings=FALSE, graph.col = FALSE))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNo\nVariable\nLabel\nStats / Values\nFreqs (% of Valid)\nValid\nMissing\n\n\n\n\n1\nasistencia [haven_labelled, vctrs_vctr, double]\nHogar carente en asistencia\n\n\n\nMin : 0\n\n\nMean : 0\n\n\nMax : 1\n\n\n\n\n\n\n0\n:\n9815\n(\n98.2%\n)\n\n\n1\n:\n185\n(\n1.8%\n)\n\n\n\n10000 (100.0%)\n0 (0.0%)\n\n\n2\nrezago [haven_labelled, vctrs_vctr, double]\nHogar carente en rezago escolar\n\n\n\nMin : 0\n\n\nMean : 0\n\n\nMax : 1\n\n\n\n\n\n\n0\n:\n9911\n(\n99.1%\n)\n\n\n1\n:\n89\n(\n0.9%\n)\n\n\n\n10000 (100.0%)\n0 (0.0%)\n\n\n3\nescolaridad [haven_labelled, vctrs_vctr, double]\nHogar carente en escolaridad\n\n\n\nMin : 0\n\n\nMean : 0.3\n\n\nMax : 1\n\n\n\n\n\n\n0\n:\n6944\n(\n69.5%\n)\n\n\n1\n:\n3046\n(\n30.5%\n)\n\n\n\n9990 (99.9%)\n10 (0.1%)\n\n\n4\nmalnutricion [haven_labelled, vctrs_vctr, double]\nHogar carente en malnutrición en niños/as\n\n\n\nMin : 0\n\n\nMean : 0\n\n\nMax : 1\n\n\n\n\n\n\n0\n:\n9694\n(\n97.0%\n)\n\n\n1\n:\n301\n(\n3.0%\n)\n\n\n\n9995 (100.0%)\n5 (0.0%)\n\n\n5\nsist_salud [haven_labelled, vctrs_vctr, double]\nHogar carente en adscripción a sistema de salud\n\n\n\nMin : 0\n\n\nMean : 0\n\n\nMax : 1\n\n\n\n\n\n\n0\n:\n9592\n(\n96.1%\n)\n\n\n1\n:\n390\n(\n3.9%\n)\n\n\n\n9982 (99.8%)\n18 (0.2%)\n\n\n6\natencion [haven_labelled, vctrs_vctr, double]\nHogar carente en atención\n\n\n\nMin : 0\n\n\nMean : 0.1\n\n\nMax : 1\n\n\n\n\n\n\n0\n:\n9476\n(\n94.8%\n)\n\n\n1\n:\n521\n(\n5.2%\n)\n\n\n\n9997 (100.0%)\n3 (0.0%)\n\n\n7\nocupacion [haven_labelled, vctrs_vctr, double]\nHogar carente en ocupación\n\n\n\nMin : 0\n\n\nMean : 0.1\n\n\nMax : 1\n\n\n\n\n\n\n0\n:\n8994\n(\n89.9%\n)\n\n\n1\n:\n1006\n(\n10.1%\n)\n\n\n\n10000 (100.0%)\n0 (0.0%)\n\n\n8\nseg_social [haven_labelled, vctrs_vctr, double]\nHogar carente en seguridad social\n\n\n\nMin : 0\n\n\nMean : 0.3\n\n\nMax : 1\n\n\n\n\n\n\n0\n:\n7011\n(\n70.5%\n)\n\n\n1\n:\n2934\n(\n29.5%\n)\n\n\n\n9945 (99.4%)\n55 (0.5%)\n\n\n9\njubilacion [haven_labelled, vctrs_vctr, double]\nHogar carente en jubilaciones\n\n\n\nMin : 0\n\n\nMean : 0.1\n\n\nMax : 1\n\n\n\n\n\n\n0\n:\n8828\n(\n88.3%\n)\n\n\n1\n:\n1172\n(\n11.7%\n)\n\n\n\n10000 (100.0%)\n0 (0.0%)\n\n\n10\nhabitabilidad [haven_labelled, vctrs_vctr, double]\nHogar carente en habitabilidad\n\n\n\nMin : 0\n\n\nMean : 0.2\n\n\nMax : 1\n\n\n\n\n\n\n0\n:\n8372\n(\n83.8%\n)\n\n\n1\n:\n1620\n(\n16.2%\n)\n\n\n\n9992 (99.9%)\n8 (0.1%)\n\n\n11\nhacinamiento [haven_labelled, vctrs_vctr, double]\nHogar carente en hacinamiento\n\n\n\nMin : 0\n\n\nMean : 0\n\n\nMax : 1\n\n\n\n\n\n\n0\n:\n9576\n(\n95.8%\n)\n\n\n1\n:\n415\n(\n4.2%\n)\n\n\n\n9991 (99.9%)\n9 (0.1%)\n\n\n12\nvivienda [haven_labelled, vctrs_vctr, double]\nHogar carente en estado de la vivienda\n\n\n\nMin : 0\n\n\nMean : 0.1\n\n\nMax : 1\n\n\n\n\n\n\n0\n:\n8687\n(\n86.9%\n)\n\n\n1\n:\n1313\n(\n13.1%\n)\n\n\n\n10000 (100.0%)\n0 (0.0%)\n\n\n13\nserv_basicos [haven_labelled, vctrs_vctr, double]\nHogar carente en servicios básicos\n\n\n\nMin : 0\n\n\nMean : 0.1\n\n\nMax : 1\n\n\n\n\n\n\n0\n:\n9218\n(\n92.2%\n)\n\n\n1\n:\n782\n(\n7.8%\n)\n\n\n\n10000 (100.0%)\n0 (0.0%)\n\n\n14\nentorno [haven_labelled, vctrs_vctr, double]\nHogar carente en entorno\n\n\n\nMin : 0\n\n\nMean : 0.1\n\n\nMax : 1\n\n\n\n\n\n\n0\n:\n8772\n(\n88.0%\n)\n\n\n1\n:\n1191\n(\n12.0%\n)\n\n\n\n9963 (99.6%)\n37 (0.4%)\n\n\n15\nap_part_social [haven_labelled, vctrs_vctr, double]\nHogar carente en apoyo y participación social\n\n\n\nMin : 0\n\n\nMean : 0.1\n\n\nMax : 1\n\n\n\n\n\n\n0\n:\n9315\n(\n93.5%\n)\n\n\n1\n:\n652\n(\n6.5%\n)\n\n\n\n9967 (99.7%)\n33 (0.3%)\n\n\n16\ntrato [haven_labelled, vctrs_vctr, double]\nHogar carente en trato igualitario\n\n\n\nMin : 0\n\n\nMean : 0.2\n\n\nMax : 1\n\n\n\n\n\n\n0\n:\n8443\n(\n84.4%\n)\n\n\n1\n:\n1557\n(\n15.6%\n)\n\n\n\n10000 (100.0%)\n0 (0.0%)\n\n\n17\nseguridad [haven_labelled, vctrs_vctr, double]\nHogar carente en seguridad\n\n\n\nMin : 0\n\n\nMean : 0.1\n\n\nMax : 1\n\n\n\n\n\n\n0\n:\n9057\n(\n90.6%\n)\n\n\n1\n:\n943\n(\n9.4%\n)\n\n\n\n10000 (100.0%)\n0 (0.0%)\n\n\n18\nregion [haven_labelled, vctrs_vctr, double]\nRegión\n\n\n\nMean (sd) : 8.8 (4.3)\n\n\nmin ≤ med ≤ max:\n\n\n1 ≤ 8 ≤ 16\n\n\nIQR (CV) : 8 (0.5)\n\n\n\n16 distinct values\n10000 (100.0%)\n0 (0.0%)\n\n\n19\narea [haven_labelled, vctrs_vctr, double]\nÁrea\n\n\n\nMin : 1\n\n\nMean : 1.2\n\n\nMax : 2\n\n\n\n\n\n\n1\n:\n7907\n(\n79.1%\n)\n\n\n2\n:\n2093\n(\n20.9%\n)\n\n\n\n10000 (100.0%)\n0 (0.0%)\n\n\n\n\nGenerated by summarytools 1.0.1 (R version 4.3.2)2024-11-19\n\n\n\nEn esta base de datos, las variables de interés que están presentes (ej. asistencia, rezago, escolaridad) son variables dummy, es decir, variables que tienen como valores posibles 0 y 1. Donde 0 implica la ausencia de un atributo y 1 la presencia del mismo atributo.\nPara medir pobreza multidimensional, 1 indica la carencia de un servicio o cualidad, por ejemplo, se considera que un hogar es carente en escolaridad si al menos uno de sus integrantes mayores de 18 años ha alcanzado menos años de escolaridad que los establecidos por ley, de acuerdo a su edad. Por lo tanto, en la variable escolaridad 1) indica un hogar carente en escolaridad, que según nuestra base de datos corresponde a 3065 hogares (30.7% de nuestra sub-muestra)."
  },
  {
    "objectID": "practicos/05-content.html#medición-de-pobreza-multidimensional-en-cuatro-dimensiones-hasta-2014",
    "href": "practicos/05-content.html#medición-de-pobreza-multidimensional-en-cuatro-dimensiones-hasta-2014",
    "title": "Práctico 5. Índices y escalas",
    "section": "",
    "text": "Seleccionamos solo los indicadores que eran utilizados hasta 2014\n\n\nCódigo\nindicadores2014 &lt;- casen2022 %&gt;% select(asistencia, \n                                        rezago, \n                                        escolaridad, \n                                        malnutricion, \n                                        sist_salud, \n                                        atencion, \n                                        ocupacion, \n                                        seg_social, \n                                        jubilacion, \n                                        hacinamiento, \n                                        estado_vivienda=vivienda, \n                                        serv_basicos)  %&gt;% \n  na.omit() %&gt;% # Eliminar Na's\n  mutate_all(~(as.numeric(.))) # Convertimos todas las variables a numéricas\n\n\nCon la función mutate creamos una nueva variable para cada dimensión, que contenga el promedio simple de los tres indicadores correspondientes.\n\n\nCódigo\nindicadores2014 = indicadores2014 %&gt;% \n  rowwise() %&gt;%\n  mutate(educ = mean(c(asistencia, rezago, escolaridad)),\n         salud = mean(c(malnutricion, sist_salud, atencion)),\n         trabajo= mean(c(ocupacion, seg_social, jubilacion)),\n         vivienda= mean(c(hacinamiento, estado_vivienda, serv_basicos))) %&gt;% \n  ungroup()\n\n\nLuego, como la pobreza multidimensional consideraba cuatro dimensiones equivalentes (sin ponderar), es posible obtener el índice de pobreza multidimensional a partir del promedio de las cuatro dimensiones.\n\n\nCódigo\nindicadores2014 = indicadores2014 %&gt;% \n  rowwise() %&gt;%\n  mutate(pobreza = mean(c(educ, salud, trabajo, vivienda))) %&gt;% \n  ungroup()\n\n\nLo que nos da este resultado:\n\n\nCódigo\nindicadores2014 %&gt;% select(pobreza) %&gt;% head(10) # Primeros 10 casos\n\n\n# A tibble: 10 × 1\n   pobreza\n     &lt;dbl&gt;\n 1  0.167 \n 2  0.25  \n 3  0     \n 4  0.167 \n 5  0.167 \n 6  0.167 \n 7  0     \n 8  0.167 \n 9  0     \n10  0.0833\n\n\nCódigo\nsummary(indicadores2014$pobreza) # Resumen\n\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n0.00000 0.00000 0.08333 0.10142 0.16667 0.66667 \n\n\n¿Cómo podemos conocer el porcentaje total de pobreza multidimensional del país?\nEl PNUD considera como límite para el índice de cuatro dimensiones un 25% de pobreza multidimensional (lo que equivale a tener carencia en los tres indicadores de una dimensión). Por lo tanto, podemos utilizar un condicional que indique “si” existe pobreza muldimensional cuando nuestra variable “pobreza” sea mayor o igual a 0.25 y que indique que “no” existe pobreza multidimensional cuando la variable “pobreza” sea menor a 0.25. case_when viene en dplyr.\n\n\nCódigo\nindicadores2014 &lt;- indicadores2014 %&gt;% mutate(pobreza = case_when(pobreza&gt;=0.25~\"si\",\n                                                      pobreza&lt;0.25~\"no\")\n                           )\nprop.table(table(indicadores2014$pobreza))*100\n\n\n\n      no       si \n87.03161 12.96839 \n\n\nSegún el análisis realizado con la submuestra aleatoria de la CASEN, considerando las cuatro dimensiones que se utilizaban hasta el 2014, existe un 12.97% de pobreza multidimensional en Chile"
  },
  {
    "objectID": "practicos/05-content.html#medición-de-pobreza-multidimensional-en-cinco-dimensiones-desde-2016",
    "href": "practicos/05-content.html#medición-de-pobreza-multidimensional-en-cinco-dimensiones-desde-2016",
    "title": "Práctico 5. Índices y escalas",
    "section": "",
    "text": "Veamos ahora el mismo proceso, pero considerando la quinta dimensión que fue agregada en 2016 sobre Redes y Cohesión Social.\n\nEn esta operacionalización del índice de pobreza multidimensional las cuatro dimensiones originales equivalen a un 22.5% cada una, mientras que la nueva dimensión de redes y cohesión social equivale a un 10%.\nSeleccionemos solo los indicadores que son utilizados desde 2016.\n\n\nCódigo\nindicadores2016 &lt;- casen2022 %&gt;% select(asistencia, \n                                        rezago, \n                                        escolaridad, \n                                        malnutricion, \n                                        sist_salud, \n                                        atencion, \n                                        ocupacion, \n                                        seg_social, \n                                        jubilacion, \n                                        habitabilidad, \n                                        serv_basicos,\n                                        entorno,\n                                        ap_part_social,\n                                        trato,\n                                        seguridad,\n                                        area,\n                                        region) %&gt;% \n  na.omit() %&gt;% # Eliminar Na's\n  mutate_all(~(as.numeric(.))) # Convertimos todas las variables a numéricas\n\n\nSeguimos los mismos pasos que con el índice anterior, estimando un promedio simple para cada una de las dimensiones.\n\n\nCódigo\nindicadores2016 = indicadores2016 %&gt;% \n  rowwise() %&gt;%\n  mutate(educ = mean(c(asistencia, rezago, escolaridad)),\n         salud = mean(c(malnutricion, sist_salud, atencion)),\n         trabajo= mean(c(ocupacion, seg_social, jubilacion)),\n         vivienda= mean(c(habitabilidad, serv_basicos, entorno)),\n         redes_cohesion= mean(c(ap_part_social, trato, seguridad))) %&gt;% \n  ungroup()\n\n\nSin embargo, como en esta ocasión se trata de un índice ponderado (con dimensiones con distinto peso cada una), multiplicamos cada dimensión por su peso correspondiente y las sumamos.\n\n\nCódigo\nindicadores2016 = indicadores2016 %&gt;% \n  rowwise() %&gt;%\n  mutate(pobreza_pond = (educ*22.5) + (salud*22.5) + (trabajo*22.5) + (vivienda*22.5) + (redes_cohesion*10)) %&gt;%  \n  ungroup()\n\n\nLo que nos da este resultado:\n\n\nCódigo\nindicadores2016 %&gt;% select(pobreza_pond) %&gt;% head(10) # Primeros 10 casos\n\n\n# A tibble: 10 × 1\n   pobreza_pond\n          &lt;dbl&gt;\n 1        18.3 \n 2        22.5 \n 3         3.33\n 4        22.5 \n 5        15   \n 6        15   \n 7         0   \n 8        15   \n 9         0   \n10        18.3 \n\n\nCódigo\nsummary(indicadores2016$pobreza_pond) # Resumen\n\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  0.000   3.333   7.500  10.988  15.000  62.500 \n\n\n¿Cómo podemos conocer el porcentaje total de pobreza multidimensional del país?\nEl PNUD considera como límite para el índice de cinco dimensiones un 22.5% de pobreza multidimensional (lo que equivale a tener carencia en los tres indicadores de una dimensión). Por lo tanto, podemos utilizar un condicional que indique “si” existe pobreza muldimensional cuando nuestra variable “pobreza” sea mayor o igual a 22.5 y que indique que “no” existe pobreza multidimensional cuando la variable “pobreza” sea menor a 22.5.\n\n\nCódigo\nindicadores2016 &lt;- indicadores2016 %&gt;% mutate(pobreza = case_when(pobreza_pond&gt;=22.5~\"si\",\n                                                      pobreza_pond&lt;22.5~\"no\")\n                           )\n                          \nprop.table(table(indicadores2016$pobreza))*100\n\n\n\n      no       si \n84.18912 15.81088 \n\n\nSegún el análisis realizado con la submuestra aleatoria de la CASEN, considerando las cinco dimensiones que se comenzaron a utilizar en 2016, existe un 15.73% de pobreza multidimensional en Chile.\n\n\nPodemos utilizar otras variables de la CASEN para poder conocer cómo se distribuye la pobreza multidimensional en Chile. Por ejemplo, porcentaje de pobreza multidimensional por región:\n\n\nCódigo\nprop.table(table(indicadores2016$region, indicadores2016$pobreza), margin = 1)\n\n\n    \n            no        si\n  1  0.7965261 0.2034739\n  2  0.7975000 0.2025000\n  3  0.8097345 0.1902655\n  4  0.8484108 0.1515892\n  5  0.8487230 0.1512770\n  6  0.8826025 0.1173975\n  7  0.8703170 0.1296830\n  8  0.8543689 0.1456311\n  9  0.8083736 0.1916264\n  10 0.7571702 0.2428298\n  11 0.8910891 0.1089109\n  12 0.9531250 0.0468750\n  13 0.8496241 0.1503759\n  14 0.8079096 0.1920904\n  15 0.8575198 0.1424802\n  16 0.8536585 0.1463415\n\n\no pobreza multidimensional por zona geográfica 1) urbano 2) rural\n\n\nCódigo\nprop.table(table(indicadores2016$area, indicadores2016$pobreza), margin = 1)\n\n\n   \n           no        si\n  1 0.8735691 0.1264309\n  2 0.7223301 0.2776699"
  },
  {
    "objectID": "practicos/05-content.html#presentación-1",
    "href": "practicos/05-content.html#presentación-1",
    "title": "Práctico 5. Índices y escalas",
    "section": "Presentación",
    "text": "Presentación\nPara el taller práctico de hoy utilizaremos la base de datos del Estudio Longitudinal Social de Chile, realizado por el Centro de estudios del conflicto y la cohesión social COES.\nEl Estudio Longitudinal Social del Chile ELSOC, único en Chile y América Latina, consiste en encuestar a casi 3.000 chilenos, anualmente, a lo largo de una década. ELSOC ha sido diseñado para evaluar la manera cómo piensan, sienten y se comportan los chilenos en torno a un conjunto de temas referidos al conflicto y la cohesión social en Chile. La población objetivo son hombres y mujeres entre 15 y 75 años de edad, tiene una representación de la población nacional urbana, donde se obtuvo una muestra original de 2927 casos en el año 2016 y mantiene 1728 en 2022, además de una muestra de refresco en 2018."
  },
  {
    "objectID": "practicos/05-content.html#objetivo-general-1",
    "href": "practicos/05-content.html#objetivo-general-1",
    "title": "Práctico 5. Índices y escalas",
    "section": "Objetivo general",
    "text": "Objetivo general\nEl objetivo de este ejercicio del práctico es revisar el proceso de construcción y validación de escalas en R.\n\nCargar base de datos\n\n\nCódigo\nload(url(\"https://dataverse.harvard.edu/api/access/datafile/7245118\")) #Cargar base de datos\n\n\n\n\nVisualización de datos\n\n\nCódigo\ndim(elsoc_long_2016_2022.2)\n\n\n[1] 18035   750\n\n\nDebido a la naturaleza longitudinal de ELSOC, la base de datos contiene 18035 casos (las mismas personas durante 6 años) y 750 variables (las mismas variables en 6 periodos distintos). Por lo tanto, para simplificar el proceso de análisis de este práctico trabajaremos solo con los casos y variables de quienes participaron en la primera ola (2016)"
  },
  {
    "objectID": "practicos/05-content.html#datos-y-variables-1",
    "href": "practicos/05-content.html#datos-y-variables-1",
    "title": "Práctico 5. Índices y escalas",
    "section": "Datos y variables",
    "text": "Datos y variables\nPara el ejercicio de escalas, utilizaremos nuevamente la base de datos de ELSOC (que ya se enceuntra cargada), específicamente el módulo de Salud y Bienestar. De este módulo utilizaremos un concepto en particular llamado Estado de ánimo: sintomatología depresiva con los ítems:\n\nFrecuencia: Poco interés o alegría\nFrecuencia: Decaimiento, pesadez o desesperanza\nFrecuencia: Dificultad para dormir o exceso de sueño\nFrecuencia: Cansancio o sensación de falta de energía\nFrecuencia: Apetito disminuido o aumentado\nFrecuencia: Dificultad para concentrarse\nFrecuencia: Mala opinión de sí mismo\nFrecuencia: Enlentecimiento físico\nFrecuencia: Pensamiento de muerte o dañarse\n\nEsta escala tiene solamente una dimensión, por lo que no es necesario crear objetos que contengan a cada dimensión (como vimos la clase pasada)."
  },
  {
    "objectID": "practicos/05-content.html#filtrar-base-de-datos",
    "href": "practicos/05-content.html#filtrar-base-de-datos",
    "title": "Práctico 5. Índices y escalas",
    "section": "Filtrar base de datos",
    "text": "Filtrar base de datos\nFiltraremos la base de datos para quedarnos con las observaciones correspondientes solamente a la ola 1, y además seleccionaremos los ítems de interés.\n\n\nCódigo\ndata2 &lt;- elsoc_long_2016_2022.2 %&gt;% filter(ola==1) %&gt;%  # seleccionamos solo los casos de la ola 1\n  select(s11_01,s11_02,s11_03,s11_04,s11_05,s11_06,s11_07,s11_08,s11_09) # items sintomatologia depresiva\n\nhead(data2)\n\n\n  s11_01 s11_02 s11_03 s11_04 s11_05 s11_06 s11_07 s11_08 s11_09\n1      5      3      3      5      4      3      3      3      1\n2      2      2      3      2      3      4      3      4      2\n3      2      2      3      3      4      5      4      1      2\n4      1      3      3      1      1      2      3      5      1\n5      1      1      1      2      1      3      1      2      1\n6      1      1      1      1      1      1      1      1      1\n\n\nCódigo\ntable(data2$s11_01)\n\n\n\n-999 -888    1    2    3    4    5 \n   5    1 1279 1196  158  192   96 \n\n\nCódigo\ntable(data2$s11_02)\n\n\n\n-999 -888    1    2    3    4    5 \n   5    1 1302 1316  135  120   48 \n\n\nCódigo\ntable(data2$s11_03)\n\n\n\n-999 -888    1    2    3    4    5 \n   3    1 1336 1014  179  265  129 \n\n\nCódigo\ntable(data2$s11_04)\n\n\n\n-999 -888    1    2    3    4    5 \n   1    1  887 1414  223  261  140 \n\n\nEstos ítems cuentan con las mismas categorías de respuesta: (1) Nunca, (2) Algunos dias, (3) Mas de la mitad de los dias, (4) Casi todos los dias, y (5) Todos los dias. Además de los valores codificados como -888 y -999.\n\nRecodificar\nRecodificamos los valores -888 y -999 en NA y eliminamos los NAs.\n\n\nCódigo\ndata2 &lt;- data2 %&gt;% \n  set_na(., na = c(-888, -999)) %&gt;% \n  na.omit()\n\ndata2 &lt;- data2 %&gt;% mutate_at(vars(starts_with(\"s11\")), ~(5-.))"
  },
  {
    "objectID": "practicos/05-content.html#análisis",
    "href": "practicos/05-content.html#análisis",
    "title": "Práctico 5. Índices y escalas",
    "section": "Análisis",
    "text": "Análisis\n\nEstimar correlación\nDado que la escala tiene solamente una dimensión, estimaremos la correlación de toda la escala.\n\n\nCódigo\ntab_corr(data2, triangle = \"lower\")\n\n\n\n\n\n \ns11_01\ns11_02\ns11_03\ns11_04\ns11_05\ns11_06\ns11_07\ns11_08\ns11_09\n\n\ns11_01\n \n \n \n \n \n \n \n \n \n\n\ns11_02\n0.485***\n \n \n \n \n \n \n \n \n\n\ns11_03\n0.374***\n0.499***\n \n \n \n \n \n \n \n\n\ns11_04\n0.373***\n0.555***\n0.559***\n \n \n \n \n \n \n\n\ns11_05\n0.357***\n0.423***\n0.486***\n0.517***\n \n \n \n \n \n\n\ns11_06\n0.305***\n0.414***\n0.390***\n0.459***\n0.412***\n \n \n \n \n\n\ns11_07\n0.302***\n0.425***\n0.369***\n0.404***\n0.369***\n0.429***\n \n \n \n\n\ns11_08\n0.301***\n0.394***\n0.349***\n0.394***\n0.357***\n0.423***\n0.506***\n \n \n\n\ns11_09\n0.235***\n0.388***\n0.303***\n0.333***\n0.304***\n0.345***\n0.508***\n0.456***\n \n\n\nComputed correlation used pearson-method with listwise-deletion.\n\n\n\n\n\nPodemos observar que todas las correlaciones son positivas, por lo que no quedaron ítems invertidos.\n\n\nEstimar consistencia interna\n\nAlfa de Chronbach\nestimaremos la consistencia interna de cada dimensión con un Alfa de Chronbach.\n\n\nCódigo\npsych::alpha(data2)\n\n\n\nReliability analysis   \nCall: psych::alpha(x = data2)\n\n  raw_alpha std.alpha G6(smc) average_r S/N    ase mean   sd median_r\n      0.85      0.86    0.85       0.4 6.1 0.0039  3.3 0.64     0.39\n\n    95% confidence boundaries \n         lower alpha upper\nFeldt     0.85  0.85  0.86\nDuhachek  0.85  0.85  0.86\n\n Reliability if an item is dropped:\n       raw_alpha std.alpha G6(smc) average_r S/N alpha se  var.r med.r\ns11_01      0.85      0.85    0.85      0.42 5.8   0.0041 0.0050  0.41\ns11_02      0.83      0.84    0.83      0.39 5.1   0.0046 0.0062  0.37\ns11_03      0.84      0.84    0.83      0.40 5.3   0.0045 0.0058  0.40\ns11_04      0.83      0.84    0.83      0.39 5.1   0.0047 0.0051  0.39\ns11_05      0.84      0.84    0.84      0.40 5.4   0.0044 0.0065  0.39\ns11_06      0.84      0.84    0.84      0.40 5.4   0.0044 0.0072  0.39\ns11_07      0.84      0.84    0.83      0.40 5.3   0.0044 0.0065  0.39\ns11_08      0.84      0.84    0.84      0.40 5.4   0.0043 0.0067  0.40\ns11_09      0.85      0.85    0.84      0.42 5.7   0.0042 0.0051  0.41\n\n Item statistics \n          n raw.r std.r r.cor r.drop mean   sd\ns11_01 2888  0.62  0.61  0.53   0.49  3.2 1.01\ns11_02 2888  0.74  0.74  0.71   0.66  3.3 0.85\ns11_03 2888  0.73  0.70  0.66   0.62  3.1 1.13\ns11_04 2888  0.77  0.75  0.72   0.67  2.9 1.07\ns11_05 2888  0.71  0.69  0.63   0.59  3.2 1.07\ns11_06 2888  0.68  0.68  0.62   0.57  3.4 0.96\ns11_07 2888  0.67  0.70  0.65   0.58  3.6 0.80\ns11_08 2888  0.66  0.68  0.62   0.56  3.6 0.85\ns11_09 2888  0.58  0.63  0.56   0.50  3.8 0.61\n\nNon missing response frequency for each item\n          0    1    2    3    4 miss\ns11_01 0.03 0.06 0.05 0.41 0.44    0\ns11_02 0.02 0.04 0.05 0.45 0.45    0\ns11_03 0.04 0.09 0.06 0.35 0.46    0\ns11_04 0.05 0.09 0.08 0.48 0.31    0\ns11_05 0.04 0.07 0.05 0.33 0.51    0\ns11_06 0.03 0.05 0.05 0.26 0.63    0\ns11_07 0.01 0.03 0.03 0.21 0.72    0\ns11_08 0.02 0.03 0.03 0.19 0.73    0\ns11_09 0.01 0.01 0.02 0.10 0.86    0\n\n\n\n\nCódigo\ndata2 &lt;- data2 %&gt;% \n  rowwise() %&gt;% \n  mutate(sintomatologia_depresiva = sum(s11_01,s11_02,s11_03,s11_04,s11_05,s11_06,s11_07,s11_08,s11_09))\nsummary(data2$sintomatologia_depresiva)\n\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n   0.00   28.00   31.00   30.01   34.00   36.00"
  },
  {
    "objectID": "practicos/07-content.html",
    "href": "practicos/07-content.html",
    "title": "Práctico 7. AFE y puntajes factoriales",
    "section": "",
    "text": "Para el taller práctico de hoy utilizaremos la base de datos del Estudio Longitudinal Social de Chile, realizado por el Centro de estudios del conflicto y la cohesión social COES.\nEl Estudio Longitudinal Social del Chile ELSOC, único en Chile y América Latina, consiste en encuestar a casi 3.000 chilenos, anualmente, a lo largo de una década. ELSOC ha sido diseñado para evaluar la manera cómo piensan, sienten y se comportan los chilenos en torno a un conjunto de temas referidos al conflicto y la cohesión social en Chile. La población objetivo son hombres y mujeres entre 15 y 75 años de edad, tiene una representación de la población nacional urbana, donde se obtuvo una muestra original de 2927 casos en el año 2016 y mantiene 1728 en 2022, además de una muestra de refresco en 2018.\n\n\n\nEl objetivo de este ejercicio práctico es comprender y estimar un análisis factorial exploratorio con el fin de reducir la dimensionalidad de una batería de variables.\n\n\n\n\n\nCódigo\npacman::p_load(tidyverse, #Conjunto de paquetes, sobre todo dplyr y ggplot2\n               car, #Para recodificar\n               haven,\n               summarytools, #Para descriptivos\n               sjmisc,\n               psych,     # para Alfa de Chronbach\n               sjPlot,\n               psy, # scree plot function\n               nFactors, # parallel\n               GPArotation, # Rotación\n               sjlabelled)\n\noptions(scipen = 999) # para desactivar notacion cientifica\nrm(list = ls()) # para limpiar el entorno de trabajo\n\n\n\n\n\n\nCódigo\nload(url(\"https://dataverse.harvard.edu/api/access/datafile/7245118\")) #Cargar base de datos\n\n\n\n\n\n\n\nCódigo\ndim(elsoc_long_2016_2022.2)\n\n\n[1] 18035   750\n\n\nDebido a la naturaleza longitudinal de ELSOC, la base de datos contiene 18035 casos (las mismas personas durante 6 años) y 750 variables (las mismas variables en 6 periodos distintos). Por lo tanto, para simplificar el proceso de análisis de este práctico trabajaremos solo con los casos y variables de quienes participaron en la cuarta ola (2019)\n\n\n\n\nPara estimar AFE, utilizaremos específicamente el módulo de Ciudadanía. De este módulo utilizaremos un concepto en particular llamado Confianza en instituciones con los ítems:\n\nGrado de confianza: El Gobierno\nGrado de confianza: Los Partidos políticos\nGrado de confianza: Carabineros\nGrado de confianza: Los sindicatos\nGrado de confianza: Las empresas privadas\nGrado de confianza: El congreso nacional\nGrado de confianza: El presidente de la república\n\nLa idea general es ver si esque todas estas variables miden algún tipo de confianza o si esque existen dimensiones subyacentes.\nAsimismo, vamos a utilizar los promedios y/o puntajes de estas variables para ver cómo influyen en la Satisfacción con la democracia en Chile\n\n\n\nFiltraremos la base de datos para quedarnos con las observaciones correspondientes solamente a la ola 4, y además seleccionaremos los ítems de interés.\n\n\nCódigo\ndata &lt;- elsoc_long_2016_2022.2 %&gt;% filter(ola==4) %&gt;%  # seleccionamos solo los casos de la ola 1\n  select(satis_dem = c01,\n         conf_gob = c05_01,\n         conf_part = c05_02,\n         conf_carab = c05_03,\n         conf_sind = c05_04,\n         conf_empre = c05_06,\n         conf_cong = c05_07,\n         conf_pres = c05_08,\n         )\n\n\nEstos ítems cuentan con las mismas categorías de respuesta: (1) Nada, a (5) Mucho. Además de los valores codificados como -888 y -999.\n\n\nRecodificamos los valores -888 y -999 en NA y eliminamos los NAs.\n\n\nCódigo\ndata$satis_dem &lt;- car::recode(data$satis_dem, \"c(-999,-888)=NA\")\ndata$conf_gob &lt;- car::recode(data$conf_gob, \"c(-999,-888)=NA\")\ndata$conf_part &lt;- car::recode(data$conf_part, \"c(-999,-888)=NA\")\ndata$conf_carab &lt;- car::recode(data$conf_carab, \"c(-999,-888)=NA\")\ndata$conf_sind &lt;- car::recode(data$conf_sind, \"c(-999,-888)=NA\")\ndata$conf_empre &lt;- car::recode(data$conf_empre, \"c(-999,-888)=NA\")\ndata$conf_cong &lt;- car::recode(data$conf_cong, \"c(-999,-888)=NA\")\ndata$conf_pres &lt;- car::recode(data$conf_pres, \"c(-999,-888)=NA\")\n\n\ndata$conf_gob &lt;- set_labels(data$conf_gob,\n            labels=c( \"Nada\"=1,\n                      \"Poca\"=2,\n                      \"Algo\"=3,\n                      \"Bastante\"=4,\n                      \"Mucha\"=5))\n\ndata$conf_part &lt;- set_labels(data$conf_part,\n            labels=c( \"Nada\"=1,\n                      \"Poca\"=2,\n                      \"Algo\"=3,\n                      \"Bastante\"=4,\n                      \"Mucha\"=5))\n\ndata$conf_carab &lt;- set_labels(data$conf_carab,\n            labels=c( \"Nada\"=1,\n                      \"Poca\"=2,\n                      \"Algo\"=3,\n                      \"Bastante\"=4,\n                      \"Mucha\"=5))\n\ndata$conf_sind &lt;- set_labels(data$conf_sind,\n            labels=c( \"Nada\"=1,\n                      \"Poca\"=2,\n                      \"Algo\"=3,\n                      \"Bastante\"=4,\n                      \"Mucha\"=5))\ndata$conf_empre &lt;- set_labels(data$conf_empre,\n            labels=c( \"Nada\"=1,\n                      \"Poca\"=2,\n                      \"Algo\"=3,\n                      \"Bastante\"=4,\n                      \"Mucha\"=5))\ndata$conf_cong &lt;- set_labels(data$conf_cong,\n            labels=c( \"Nada\"=1,\n                      \"Poca\"=2,\n                      \"Algo\"=3,\n                      \"Bastante\"=4,\n                      \"Mucha\"=5))\ndata$conf_pres &lt;- set_labels(data$conf_pres,\n            labels=c( \"Nada\"=1,\n                      \"Poca\"=2,\n                      \"Algo\"=3,\n                      \"Bastante\"=4,\n                      \"Mucha\"=5))\n\n\n\n\n\n\n\n\nCódigo\ndata %&gt;% select(conf_gob:conf_pres) %&gt;% \n  plot_stackfrq() + theme(legend.position=\"bottom\")\n\n\n\n\n\n\n\n\n\nCódigo\ndata %&gt;% select(conf_gob:conf_pres) %&gt;% tab_corr(triangle = \"lower\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n \nGrado de confianza: El Gobierno\nGrado de confianza: Los Partidos\nPoliticos\nGrado de confianza: Carabineros\nGrado de confianza: Los Sindicatos\nGrado de confianza: Las Empresas\nPrivadas\nGrado de confianza: El Congreso Nacional\nGrado de confianza: El Presidente/a de\nla Republica\n\n\nGrado de confianza: El Gobierno\n \n \n \n \n \n \n \n\n\nGrado de confianza: Los Partidos\nPoliticos\n0.451***\n \n \n \n \n \n \n\n\nGrado de confianza: Carabineros\n0.517***\n0.232***\n \n \n \n \n \n\n\nGrado de confianza: Los Sindicatos\n0.175***\n0.280***\n0.201***\n \n \n \n \n\n\nGrado de confianza: Las Empresas\nPrivadas\n0.417***\n0.291***\n0.409***\n0.317***\n \n \n \n\n\nGrado de confianza: El Congreso Nacional\n0.470***\n0.523***\n0.321***\n0.331***\n0.450***\n \n \n\n\nGrado de confianza: El Presidente/a de\nla Republica\n0.719***\n0.355***\n0.524***\n0.127***\n0.378***\n0.442***\n \n\n\nComputed correlation used pearson-method with listwise-deletion.\n\n\n\n\n\nPodemos observar que todas las correlaciones son positivas, por lo que no quedaron ítems invertidos.\n\n\nCódigo\ndata %&gt;% select(conf_gob:conf_pres) %&gt;% psych::alpha()\n\n\n\nReliability analysis   \nCall: psych::alpha(x = .)\n\n  raw_alpha std.alpha G6(smc) average_r S/N    ase mean   sd median_r\n      0.79      0.81    0.81      0.38 4.2 0.0055  1.8 0.63     0.37\n\n    95% confidence boundaries \n         lower alpha upper\nFeldt     0.78  0.79   0.8\nDuhachek  0.78  0.79   0.8\n\n Reliability if an item is dropped:\n           raw_alpha std.alpha G6(smc) average_r S/N alpha se var.r med.r\nconf_gob        0.73      0.76    0.75      0.34 3.1   0.0070 0.013  0.33\nconf_part       0.77      0.79    0.79      0.38 3.8   0.0060 0.023  0.41\nconf_carab      0.76      0.79    0.79      0.38 3.7   0.0064 0.021  0.37\nconf_sind       0.80      0.82    0.82      0.43 4.5   0.0049 0.014  0.44\nconf_empre      0.75      0.78    0.79      0.38 3.6   0.0064 0.026  0.35\nconf_cong       0.75      0.77    0.77      0.36 3.3   0.0064 0.024  0.35\nconf_pres       0.74      0.77    0.76      0.36 3.3   0.0068 0.012  0.33\n\n Item statistics \n              n raw.r std.r r.cor r.drop mean   sd\nconf_gob   3405  0.78  0.78  0.77   0.67  1.6 0.87\nconf_part  3394  0.58  0.65  0.57   0.48  1.3 0.57\nconf_carab 3409  0.73  0.67  0.59   0.54  2.4 1.25\nconf_sind  3253  0.53  0.51  0.37   0.31  2.1 1.09\nconf_empre 3339  0.69  0.68  0.59   0.55  1.9 0.97\nconf_cong  3382  0.70  0.74  0.69   0.59  1.4 0.71\nconf_pres  3399  0.75  0.74  0.72   0.62  1.6 0.92\n\nNon missing response frequency for each item\n              1    2    3    4    5 miss\nconf_gob   0.60 0.24 0.13 0.03 0.01 0.00\nconf_part  0.79 0.16 0.04 0.01 0.00 0.01\nconf_carab 0.32 0.23 0.23 0.15 0.07 0.00\nconf_sind  0.42 0.23 0.25 0.09 0.02 0.05\nconf_empre 0.45 0.28 0.21 0.05 0.01 0.02\nconf_cong  0.68 0.21 0.09 0.01 0.00 0.01\nconf_pres  0.65 0.18 0.12 0.03 0.01 0.01\n\n\nSi sacamos conf_sind el alpha sube a 0.8\n\n\nCódigo\ndata %&gt;% select(conf_gob:conf_carab, conf_empre:conf_pres) %&gt;% psych::alpha()\n\n\n\nReliability analysis   \nCall: psych::alpha(x = .)\n\n  raw_alpha std.alpha G6(smc) average_r S/N    ase mean   sd median_r\n       0.8      0.82    0.82      0.43 4.5 0.0049  1.7 0.65     0.44\n\n    95% confidence boundaries \n         lower alpha upper\nFeldt     0.79   0.8  0.81\nDuhachek  0.79   0.8  0.81\n\n Reliability if an item is dropped:\n           raw_alpha std.alpha G6(smc) average_r S/N alpha se  var.r med.r\nconf_gob        0.74      0.76    0.74      0.39 3.2   0.0066 0.0089  0.39\nconf_part       0.80      0.81    0.80      0.46 4.3   0.0053 0.0118  0.44\nconf_carab      0.79      0.80    0.79      0.45 4.0   0.0055 0.0136  0.44\nconf_empre      0.79      0.81    0.80      0.45 4.2   0.0054 0.0178  0.46\nconf_cong       0.78      0.79    0.77      0.43 3.7   0.0056 0.0187  0.41\nconf_pres       0.75      0.77    0.75      0.41 3.4   0.0065 0.0089  0.43\n\n Item statistics \n              n raw.r std.r r.cor r.drop mean   sd\nconf_gob   3405  0.82  0.82  0.80   0.71  1.6 0.87\nconf_part  3394  0.57  0.65  0.55   0.46  1.3 0.57\nconf_carab 3409  0.76  0.69  0.60   0.56  2.4 1.25\nconf_empre 3339  0.69  0.67  0.56   0.51  1.9 0.97\nconf_cong  3382  0.69  0.74  0.66   0.57  1.4 0.71\nconf_pres  3399  0.80  0.78  0.76   0.68  1.6 0.92\n\nNon missing response frequency for each item\n              1    2    3    4    5 miss\nconf_gob   0.60 0.24 0.13 0.03 0.01 0.00\nconf_part  0.79 0.16 0.04 0.01 0.00 0.01\nconf_carab 0.32 0.23 0.23 0.15 0.07 0.00\nconf_empre 0.45 0.28 0.21 0.05 0.01 0.02\nconf_cong  0.68 0.21 0.09 0.01 0.00 0.01\nconf_pres  0.65 0.18 0.12 0.03 0.01 0.01\n\n\n\n\nCódigo\ndata &lt;- cbind(data, \n              \"conf_inst\"=rowMeans(data %&gt;%\n              dplyr::select(conf_gob:conf_carab, conf_empre:conf_pres), \n              na.rm=TRUE))\n\nsummary(data$conf_inst)\n\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n  1.000   1.167   1.500   1.700   2.167   5.000       6 \n\n\n\n\n\n\n¿Qué se puede deducir de la matriz de correlaciones en relación a la estructura subyacente en términos de variables latentes? No hay claridad de grupos de indicadores asociados entre sí.\n\n\nKMO (Kaiser, Meyer, Olkin Measure of Sampling Adequacy):\n\nVaría entre 0 y 1. Contrasta si las correlaciones parciales entre las variables son pequeñas\nValores pequeños (menores a 0.5) indican que los datos no serían adecuados para AFE, ya que las correlaciones entre pares de variables no pueden ser explicadas por otras variables.\n\n\n\nCódigo\ncorMat  &lt;- data %&gt;% select(conf_gob:conf_pres) %&gt;%\n  cor(use = \"complete.obs\")  # estimar matriz pearson\n\nKMO(corMat)\n\n\nKaiser-Meyer-Olkin factor adequacy\nCall: KMO(r = corMat)\nOverall MSA =  0.81\nMSA for each item = \n  conf_gob  conf_part conf_carab  conf_sind conf_empre  conf_cong  conf_pres \n      0.78       0.81       0.86       0.80       0.86       0.83       0.77 \n\n\nEn este caso las correlaciones son altas, por lo que los datos sí son adecuados para AFE.\n\n\n\nSe utiliza para evluar la hipótesis que la matriz de correlaciones es una matriz identidad (diagonal=1 y bajo la diagonal=0)\n\nSe busca significación (p &lt; 0.05) ya que se espera que las variables estén correlacionadas\n\n\n\nCódigo\ncortest.bartlett(corMat, n = 3417)\n\n\n$chisq\n[1] 7942.816\n\n$p.value\n[1] 0\n\n$df\n[1] 21\n\n\nEn este caso el valor p es 0, así que hay significación estadística\n\n\n\n\n\nCódigo\ndata %&gt;% select(conf_gob:conf_pres) %&gt;% scree.plot()\n\n\n\n\n\n\n\nCódigo\nfa.parallel(corMat, n.obs=3417)\n\n\n\n\n\nParallel analysis suggests that the number of factors =  3  and the number of components =  2 \n\n\n\n\n\n\nejes principales\n\n\n\nCódigo\nfac_pa &lt;- data %&gt;% select(conf_gob:conf_pres) %&gt;% fa(nfactors = 3, fm= \"pa\")\n#summary(fac_pa)\nfac_pa\n\n\nFactor Analysis using method =  pa\nCall: fa(r = ., nfactors = 3, fm = \"pa\")\nStandardized loadings (pattern matrix) based upon correlation matrix\n             PA1   PA2   PA3   h2   u2 com\nconf_gob    0.77  0.14  0.00 0.72 0.28 1.1\nconf_part   0.07  0.72 -0.04 0.55 0.45 1.0\nconf_carab  0.52 -0.13  0.32 0.45 0.55 1.8\nconf_sind  -0.19  0.29  0.42 0.27 0.73 2.2\nconf_empre  0.14  0.07  0.59 0.50 0.50 1.1\nconf_cong   0.12  0.53  0.23 0.55 0.45 1.5\nconf_pres   0.87  0.00 -0.02 0.74 0.26 1.0\n\n                       PA1  PA2  PA3\nSS loadings           1.84 1.08 0.87\nProportion Var        0.26 0.15 0.12\nCumulative Var        0.26 0.42 0.54\nProportion Explained  0.48 0.29 0.23\nCumulative Proportion 0.48 0.77 1.00\n\n With factor correlations of \n     PA1  PA2  PA3\nPA1 1.00 0.51 0.48\nPA2 0.51 1.00 0.44\nPA3 0.48 0.44 1.00\n\nMean item complexity =  1.4\nTest of the hypothesis that 3 factors are sufficient.\n\ndf null model =  21  with the objective function =  2.3 with Chi Square =  7858.1\ndf of  the model are 3  and the objective function was  0.01 \n\nThe root mean square of the residuals (RMSR) is  0.01 \nThe df corrected root mean square of the residuals is  0.03 \n\nThe harmonic n.obs is  3337 with the empirical chi square  12.76  with prob &lt;  0.0052 \nThe total n.obs was  3417  with Likelihood Chi Square =  39.13  with prob &lt;  0.000000016 \n\nTucker Lewis Index of factoring reliability =  0.968\nRMSEA index =  0.059  and the 90 % confidence intervals are  0.044 0.077\nBIC =  14.72\nFit based upon off diagonal values = 1\nMeasures of factor score adequacy             \n                                                   PA1  PA2  PA3\nCorrelation of (regression) scores with factors   0.93 0.84 0.79\nMultiple R square of scores with factors          0.86 0.71 0.62\nMinimum correlation of possible factor scores     0.72 0.43 0.25\n\n\n\nMaximum likelihood\n\nMaximiza la posibilidad de que los parámetros reproduzcan los datos observados\n\n\nCódigo\nfac_ml &lt;- data %&gt;% select(conf_gob:conf_pres) %&gt;% fa(nfactors = 3, fm= \"ml\")\nfac_ml\n\n\nFactor Analysis using method =  ml\nCall: fa(r = ., nfactors = 3, fm = \"ml\")\nStandardized loadings (pattern matrix) based upon correlation matrix\n             ML1   ML2   ML3   h2   u2 com\nconf_gob    0.77  0.13  0.02 0.72 0.28 1.1\nconf_part   0.05  0.78 -0.01 0.64 0.36 1.0\nconf_carab  0.51 -0.12  0.29 0.43 0.57 1.7\nconf_sind  -0.19  0.24  0.46 0.27 0.73 1.9\nconf_empre  0.11  0.00  0.66 0.53 0.47 1.1\nconf_cong   0.14  0.44  0.30 0.52 0.48 2.0\nconf_pres   0.88 -0.01 -0.03 0.75 0.25 1.0\n\n                       ML1  ML2  ML3\nSS loadings           1.83 1.02 1.00\nProportion Var        0.26 0.15 0.14\nCumulative Var        0.26 0.41 0.55\nProportion Explained  0.47 0.27 0.26\nCumulative Proportion 0.47 0.74 1.00\n\n With factor correlations of \n     ML1  ML2  ML3\nML1 1.00 0.48 0.52\nML2 0.48 1.00 0.45\nML3 0.52 0.45 1.00\n\nMean item complexity =  1.4\nTest of the hypothesis that 3 factors are sufficient.\n\ndf null model =  21  with the objective function =  2.3 with Chi Square =  7858.1\ndf of  the model are 3  and the objective function was  0.01 \n\nThe root mean square of the residuals (RMSR) is  0.01 \nThe df corrected root mean square of the residuals is  0.03 \n\nThe harmonic n.obs is  3337 with the empirical chi square  14.35  with prob &lt;  0.0025 \nThe total n.obs was  3417  with Likelihood Chi Square =  35.46  with prob &lt;  0.000000097 \n\nTucker Lewis Index of factoring reliability =  0.971\nRMSEA index =  0.056  and the 90 % confidence intervals are  0.041 0.074\nBIC =  11.05\nFit based upon off diagonal values = 1\nMeasures of factor score adequacy             \n                                                   ML1  ML2  ML3\nCorrelation of (regression) scores with factors   0.93 0.85 0.82\nMultiple R square of scores with factors          0.86 0.73 0.67\nMinimum correlation of possible factor scores     0.72 0.45 0.34\n\n\n\n\n\n\nVarimax (ortogonal)\n\n\n\nCódigo\nfac_ml_var &lt;- data %&gt;% select(conf_gob:conf_pres) %&gt;% fa(nfactors = 3, fm= \"ml\", rotate=\"varimax\") # ortogonal\nfac_ml_var\n\n\nFactor Analysis using method =  ml\nCall: fa(r = ., nfactors = 3, rotate = \"varimax\", fm = \"ml\")\nStandardized loadings (pattern matrix) based upon correlation matrix\n            ML1  ML2  ML3   h2   u2 com\nconf_gob   0.76 0.32 0.17 0.72 0.28 1.4\nconf_part  0.21 0.74 0.22 0.64 0.36 1.3\nconf_carab 0.57 0.05 0.31 0.43 0.57 1.6\nconf_sind  0.04 0.23 0.46 0.27 0.73 1.5\nconf_empre 0.35 0.11 0.63 0.53 0.47 1.6\nconf_cong  0.34 0.48 0.42 0.52 0.48 2.8\nconf_pres  0.83 0.22 0.10 0.75 0.25 1.2\n\n                       ML1  ML2  ML3\nSS loadings           1.89 1.00 0.97\nProportion Var        0.27 0.14 0.14\nCumulative Var        0.27 0.41 0.55\nProportion Explained  0.49 0.26 0.25\nCumulative Proportion 0.49 0.75 1.00\n\nMean item complexity =  1.6\nTest of the hypothesis that 3 factors are sufficient.\n\ndf null model =  21  with the objective function =  2.3 with Chi Square =  7858.1\ndf of  the model are 3  and the objective function was  0.01 \n\nThe root mean square of the residuals (RMSR) is  0.01 \nThe df corrected root mean square of the residuals is  0.03 \n\nThe harmonic n.obs is  3337 with the empirical chi square  14.35  with prob &lt;  0.0025 \nThe total n.obs was  3417  with Likelihood Chi Square =  35.46  with prob &lt;  0.000000097 \n\nTucker Lewis Index of factoring reliability =  0.971\nRMSEA index =  0.056  and the 90 % confidence intervals are  0.041 0.074\nBIC =  11.05\nFit based upon off diagonal values = 1\nMeasures of factor score adequacy             \n                                                   ML1  ML2  ML3\nCorrelation of (regression) scores with factors   0.89 0.78 0.73\nMultiple R square of scores with factors          0.79 0.61 0.54\nMinimum correlation of possible factor scores     0.59 0.21 0.07\n\n\n\nPromax (oblicua)\n\n\n\nCódigo\nfac_ml_pro &lt;- data %&gt;% select(conf_gob:conf_pres) %&gt;% fa(nfactors = 3, fm= \"ml\", rotate=\"promax\")\nfac_ml_pro\n\n\nFactor Analysis using method =  ml\nCall: fa(r = ., nfactors = 3, rotate = \"promax\", fm = \"ml\")\nStandardized loadings (pattern matrix) based upon correlation matrix\n             ML1   ML2   ML3   h2   u2 com\nconf_gob    0.80  0.19 -0.09 0.72 0.28 1.1\nconf_part   0.03  0.78  0.01 0.64 0.36 1.0\nconf_carab  0.57 -0.14  0.23 0.43 0.57 1.4\nconf_sind  -0.15  0.13  0.51 0.27 0.73 1.3\nconf_empre  0.19 -0.12  0.67 0.53 0.47 1.2\nconf_cong   0.17  0.39  0.30 0.52 0.48 2.3\nconf_pres   0.91  0.07 -0.16 0.75 0.25 1.1\n\n                       ML1  ML2  ML3\nSS loadings           1.98 0.96 0.92\nProportion Var        0.28 0.14 0.13\nCumulative Var        0.28 0.42 0.55\nProportion Explained  0.51 0.25 0.24\nCumulative Proportion 0.51 0.76 1.00\n\n With factor correlations of \n     ML1  ML2  ML3\nML1 1.00 0.48 0.57\nML2 0.48 1.00 0.56\nML3 0.57 0.56 1.00\n\nMean item complexity =  1.4\nTest of the hypothesis that 3 factors are sufficient.\n\ndf null model =  21  with the objective function =  2.3 with Chi Square =  7858.1\ndf of  the model are 3  and the objective function was  0.01 \n\nThe root mean square of the residuals (RMSR) is  0.01 \nThe df corrected root mean square of the residuals is  0.03 \n\nThe harmonic n.obs is  3337 with the empirical chi square  14.35  with prob &lt;  0.0025 \nThe total n.obs was  3417  with Likelihood Chi Square =  35.46  with prob &lt;  0.000000097 \n\nTucker Lewis Index of factoring reliability =  0.971\nRMSEA index =  0.056  and the 90 % confidence intervals are  0.041 0.074\nBIC =  11.05\nFit based upon off diagonal values = 1\nMeasures of factor score adequacy             \n                                                   ML1  ML2  ML3\nCorrelation of (regression) scores with factors   0.93 0.85 0.83\nMultiple R square of scores with factors          0.87 0.72 0.69\nMinimum correlation of possible factor scores     0.74 0.45 0.38\n\n\n\n\n\n\n\nCódigo\ndata %&gt;% select(conf_gob:conf_pres) %&gt;% sjPlot::tab_fa(method = \"ml\", rotation = \"promax\", show.comm = TRUE, title = \"Análisis factorial de confianza en instituciones\")\n\n\nParallel analysis suggests that the number of factors =  3  and the number of components =  NA \n\n\n\nAnálisis factorial de confianza en instituciones\n\n\n\n\n\n\n\n\n\n \nFactor 1\nFactor 2\nFactor 3\nCommunality\n\n\nGrado de confianza: El Gobierno\n0.80\n0.19\n-0.09\n0.72\n\n\nGrado de confianza: Los Partidos\nPoliticos\n0.03\n0.78\n0.01\n0.64\n\n\nGrado de confianza: Carabineros\n0.57\n-0.14\n0.23\n0.43\n\n\nGrado de confianza: Los Sindicatos\n-0.15\n0.13\n0.51\n0.27\n\n\nGrado de confianza: Las Empresas\nPrivadas\n0.19\n-0.12\n0.67\n0.53\n\n\nGrado de confianza: El Congreso Nacional\n0.17\n0.39\n0.30\n0.52\n\n\nGrado de confianza: El Presidente/a de\nla Republica\n0.91\n0.07\n-0.16\n0.75\n\n\nTotal Communalities\n\n3.85\n\n\nCronbach's α\n0.78\n0.67\n0.48\n\n\n\n\n\n\nLuego de realizar el Análisis factorial exploratorio existen varias alternativas sobre los pasos a seguir. Por ejemplo, es posible estimar un promedio simple entre cada una de las variables de los factores. Otra opción es estimar puntajes factoriales.\n\n\n\n\n\nCódigo\nfac_ml &lt;- data %&gt;% select(conf_gob:conf_pres) %&gt;% fa(nfactors = 3, fm= \"ml\", rotate = \"promax\", scores = \"regression\")\nfac_ml\n\n\nFactor Analysis using method =  ml\nCall: fa(r = ., nfactors = 3, rotate = \"promax\", scores = \"regression\", \n    fm = \"ml\")\nStandardized loadings (pattern matrix) based upon correlation matrix\n             ML1   ML2   ML3   h2   u2 com\nconf_gob    0.80  0.19 -0.09 0.72 0.28 1.1\nconf_part   0.03  0.78  0.01 0.64 0.36 1.0\nconf_carab  0.57 -0.14  0.23 0.43 0.57 1.4\nconf_sind  -0.15  0.13  0.51 0.27 0.73 1.3\nconf_empre  0.19 -0.12  0.67 0.53 0.47 1.2\nconf_cong   0.17  0.39  0.30 0.52 0.48 2.3\nconf_pres   0.91  0.07 -0.16 0.75 0.25 1.1\n\n                       ML1  ML2  ML3\nSS loadings           1.98 0.96 0.92\nProportion Var        0.28 0.14 0.13\nCumulative Var        0.28 0.42 0.55\nProportion Explained  0.51 0.25 0.24\nCumulative Proportion 0.51 0.76 1.00\n\n With factor correlations of \n     ML1  ML2  ML3\nML1 1.00 0.48 0.57\nML2 0.48 1.00 0.56\nML3 0.57 0.56 1.00\n\nMean item complexity =  1.4\nTest of the hypothesis that 3 factors are sufficient.\n\ndf null model =  21  with the objective function =  2.3 with Chi Square =  7858.1\ndf of  the model are 3  and the objective function was  0.01 \n\nThe root mean square of the residuals (RMSR) is  0.01 \nThe df corrected root mean square of the residuals is  0.03 \n\nThe harmonic n.obs is  3337 with the empirical chi square  14.35  with prob &lt;  0.0025 \nThe total n.obs was  3417  with Likelihood Chi Square =  35.46  with prob &lt;  0.000000097 \n\nTucker Lewis Index of factoring reliability =  0.971\nRMSEA index =  0.056  and the 90 % confidence intervals are  0.041 0.074\nBIC =  11.05\nFit based upon off diagonal values = 1\nMeasures of factor score adequacy             \n                                                   ML1  ML2  ML3\nCorrelation of (regression) scores with factors   0.93 0.85 0.83\nMultiple R square of scores with factors          0.87 0.72 0.69\nMinimum correlation of possible factor scores     0.74 0.45 0.38\n\n\n\n\nCódigo\ndata &lt;- cbind(data, fac_ml$scores)\n\n\n\n\nCódigo\ndata %&gt;% select(conf_inst, ML1, ML2, ML3) %&gt;% head(10)\n\n\n   conf_inst        ML1        ML2        ML3\n1   1.000000 -0.8382387 -0.4724225 -0.7851196\n2   1.333333 -0.5980196 -0.6372386 -0.7486267\n3   1.000000 -0.8356784 -0.5480919 -0.9833033\n4   2.833333  2.1363615  0.1859941  0.9509994\n5   1.166667 -0.7238739 -0.5542404 -0.5297908\n6   1.000000 -0.8356784 -0.5480919 -0.9833033\n7   1.000000 -0.8356784 -0.5480919 -0.9833033\n8   1.666667 -0.4275077  0.2577645  0.6781084\n9   1.000000 -0.8356784 -0.5480919 -0.9833033\n10  1.333333 -0.5980196 -0.6372386 -0.7486267\n\n\nFactor 1\n\n\nCódigo\nsummary(data$ML1)\n\n\n    Min.  1st Qu.   Median     Mean  3rd Qu.     Max.     NA's \n-0.84894 -0.72453 -0.38400 -0.01872  0.50205  3.94763      222 \n\n\nFactor 2\n\n\nCódigo\nsummary(data$ML2)\n\n\n    Min.  1st Qu.   Median     Mean  3rd Qu.     Max.     NA's \n-0.75098 -0.54809 -0.40290 -0.00971  0.16165  5.39270      222 \n\n\nFactor 3\n\n\nCódigo\nsummary(data$ML3)\n\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n-1.1852 -0.7486 -0.1423 -0.0131  0.5225  3.7504     222 \n\n\n\n\n\n\n\nCódigo\ndata&lt;- data %&gt;% rename(inst_ejecutivo=ML1,\n                inst_partidos=ML2,\n                inst_trabajo=ML3)\n\n\n\n\n\n\n\nCódigo\ndata&lt;-na.omit(data)\nreg1 &lt;- lm(satis_dem~conf_inst, data=data)\nreg2 &lt;- lm(satis_dem~inst_ejecutivo, data=data)\nreg3 &lt;- lm(satis_dem~inst_partidos, data=data)\nreg4 &lt;- lm(satis_dem~inst_trabajo, data=data)\nreg5 &lt;- lm(satis_dem~inst_ejecutivo+inst_partidos+inst_trabajo, data=data)\n\n\n\nCódigo\ntexreg::knitreg(list(reg1, reg2, reg3, reg4, reg5))\n\n\n\n\nStatistical models\n\n\n\n\n \n\n\nModel 1\n\n\nModel 2\n\n\nModel 3\n\n\nModel 4\n\n\nModel 5\n\n\n\n\n\n\n(Intercept)\n\n\n0.68***\n\n\n1.70***\n\n\n1.70***\n\n\n1.70***\n\n\n1.70***\n\n\n\n\n \n\n\n(0.04)\n\n\n(0.01)\n\n\n(0.02)\n\n\n(0.02)\n\n\n(0.01)\n\n\n\n\nconf_inst\n\n\n0.61***\n\n\n \n\n\n \n\n\n \n\n\n \n\n\n\n\n \n\n\n(0.02)\n\n\n \n\n\n \n\n\n \n\n\n \n\n\n\n\ninst_ejecutivo\n\n\n \n\n\n0.42***\n\n\n \n\n\n \n\n\n0.34***\n\n\n\n\n \n\n\n \n\n\n(0.02)\n\n\n \n\n\n \n\n\n(0.02)\n\n\n\n\ninst_partidos\n\n\n \n\n\n \n\n\n0.39***\n\n\n \n\n\n0.17***\n\n\n\n\n \n\n\n \n\n\n \n\n\n(0.02)\n\n\n \n\n\n(0.03)\n\n\n\n\ninst_trabajo\n\n\n \n\n\n \n\n\n \n\n\n0.37***\n\n\n-0.02\n\n\n\n\n \n\n\n \n\n\n \n\n\n \n\n\n(0.02)\n\n\n(0.03)\n\n\n\n\nR2\n\n\n0.18\n\n\n0.18\n\n\n0.13\n\n\n0.11\n\n\n0.20\n\n\n\n\nAdj. R2\n\n\n0.18\n\n\n0.18\n\n\n0.13\n\n\n0.11\n\n\n0.20\n\n\n\n\nNum. obs.\n\n\n3134\n\n\n3134\n\n\n3134\n\n\n3134\n\n\n3134\n\n\n\n\n\n\n***p &lt; 0.001; **p &lt; 0.01; *p &lt; 0.05"
  },
  {
    "objectID": "practicos/07-content.html#presentación",
    "href": "practicos/07-content.html#presentación",
    "title": "Práctico 7. AFE y puntajes factoriales",
    "section": "",
    "text": "Para el taller práctico de hoy utilizaremos la base de datos del Estudio Longitudinal Social de Chile, realizado por el Centro de estudios del conflicto y la cohesión social COES.\nEl Estudio Longitudinal Social del Chile ELSOC, único en Chile y América Latina, consiste en encuestar a casi 3.000 chilenos, anualmente, a lo largo de una década. ELSOC ha sido diseñado para evaluar la manera cómo piensan, sienten y se comportan los chilenos en torno a un conjunto de temas referidos al conflicto y la cohesión social en Chile. La población objetivo son hombres y mujeres entre 15 y 75 años de edad, tiene una representación de la población nacional urbana, donde se obtuvo una muestra original de 2927 casos en el año 2016 y mantiene 1728 en 2022, además de una muestra de refresco en 2018."
  },
  {
    "objectID": "practicos/07-content.html#objetivo-general",
    "href": "practicos/07-content.html#objetivo-general",
    "title": "Práctico 7. AFE y puntajes factoriales",
    "section": "",
    "text": "El objetivo de este ejercicio práctico es comprender y estimar un análisis factorial exploratorio con el fin de reducir la dimensionalidad de una batería de variables."
  },
  {
    "objectID": "practicos/07-content.html#cargar-paquetes",
    "href": "practicos/07-content.html#cargar-paquetes",
    "title": "Práctico 7. AFE y puntajes factoriales",
    "section": "",
    "text": "Código\npacman::p_load(tidyverse, #Conjunto de paquetes, sobre todo dplyr y ggplot2\n               car, #Para recodificar\n               haven,\n               summarytools, #Para descriptivos\n               sjmisc,\n               psych,     # para Alfa de Chronbach\n               sjPlot,\n               psy, # scree plot function\n               nFactors, # parallel\n               GPArotation, # Rotación\n               sjlabelled)\n\noptions(scipen = 999) # para desactivar notacion cientifica\nrm(list = ls()) # para limpiar el entorno de trabajo\n\n\n\n\n\n\nCódigo\nload(url(\"https://dataverse.harvard.edu/api/access/datafile/7245118\")) #Cargar base de datos\n\n\n\n\n\n\n\nCódigo\ndim(elsoc_long_2016_2022.2)\n\n\n[1] 18035   750\n\n\nDebido a la naturaleza longitudinal de ELSOC, la base de datos contiene 18035 casos (las mismas personas durante 6 años) y 750 variables (las mismas variables en 6 periodos distintos). Por lo tanto, para simplificar el proceso de análisis de este práctico trabajaremos solo con los casos y variables de quienes participaron en la cuarta ola (2019)"
  },
  {
    "objectID": "practicos/07-content.html#datos-y-variables",
    "href": "practicos/07-content.html#datos-y-variables",
    "title": "Práctico 7. AFE y puntajes factoriales",
    "section": "",
    "text": "Para estimar AFE, utilizaremos específicamente el módulo de Ciudadanía. De este módulo utilizaremos un concepto en particular llamado Confianza en instituciones con los ítems:\n\nGrado de confianza: El Gobierno\nGrado de confianza: Los Partidos políticos\nGrado de confianza: Carabineros\nGrado de confianza: Los sindicatos\nGrado de confianza: Las empresas privadas\nGrado de confianza: El congreso nacional\nGrado de confianza: El presidente de la república\n\nLa idea general es ver si esque todas estas variables miden algún tipo de confianza o si esque existen dimensiones subyacentes.\nAsimismo, vamos a utilizar los promedios y/o puntajes de estas variables para ver cómo influyen en la Satisfacción con la democracia en Chile"
  },
  {
    "objectID": "practicos/07-content.html#filtrar-base-de-datos",
    "href": "practicos/07-content.html#filtrar-base-de-datos",
    "title": "Práctico 7. AFE y puntajes factoriales",
    "section": "",
    "text": "Filtraremos la base de datos para quedarnos con las observaciones correspondientes solamente a la ola 4, y además seleccionaremos los ítems de interés.\n\n\nCódigo\ndata &lt;- elsoc_long_2016_2022.2 %&gt;% filter(ola==4) %&gt;%  # seleccionamos solo los casos de la ola 1\n  select(satis_dem = c01,\n         conf_gob = c05_01,\n         conf_part = c05_02,\n         conf_carab = c05_03,\n         conf_sind = c05_04,\n         conf_empre = c05_06,\n         conf_cong = c05_07,\n         conf_pres = c05_08,\n         )\n\n\nEstos ítems cuentan con las mismas categorías de respuesta: (1) Nada, a (5) Mucho. Además de los valores codificados como -888 y -999.\n\n\nRecodificamos los valores -888 y -999 en NA y eliminamos los NAs.\n\n\nCódigo\ndata$satis_dem &lt;- car::recode(data$satis_dem, \"c(-999,-888)=NA\")\ndata$conf_gob &lt;- car::recode(data$conf_gob, \"c(-999,-888)=NA\")\ndata$conf_part &lt;- car::recode(data$conf_part, \"c(-999,-888)=NA\")\ndata$conf_carab &lt;- car::recode(data$conf_carab, \"c(-999,-888)=NA\")\ndata$conf_sind &lt;- car::recode(data$conf_sind, \"c(-999,-888)=NA\")\ndata$conf_empre &lt;- car::recode(data$conf_empre, \"c(-999,-888)=NA\")\ndata$conf_cong &lt;- car::recode(data$conf_cong, \"c(-999,-888)=NA\")\ndata$conf_pres &lt;- car::recode(data$conf_pres, \"c(-999,-888)=NA\")\n\n\ndata$conf_gob &lt;- set_labels(data$conf_gob,\n            labels=c( \"Nada\"=1,\n                      \"Poca\"=2,\n                      \"Algo\"=3,\n                      \"Bastante\"=4,\n                      \"Mucha\"=5))\n\ndata$conf_part &lt;- set_labels(data$conf_part,\n            labels=c( \"Nada\"=1,\n                      \"Poca\"=2,\n                      \"Algo\"=3,\n                      \"Bastante\"=4,\n                      \"Mucha\"=5))\n\ndata$conf_carab &lt;- set_labels(data$conf_carab,\n            labels=c( \"Nada\"=1,\n                      \"Poca\"=2,\n                      \"Algo\"=3,\n                      \"Bastante\"=4,\n                      \"Mucha\"=5))\n\ndata$conf_sind &lt;- set_labels(data$conf_sind,\n            labels=c( \"Nada\"=1,\n                      \"Poca\"=2,\n                      \"Algo\"=3,\n                      \"Bastante\"=4,\n                      \"Mucha\"=5))\ndata$conf_empre &lt;- set_labels(data$conf_empre,\n            labels=c( \"Nada\"=1,\n                      \"Poca\"=2,\n                      \"Algo\"=3,\n                      \"Bastante\"=4,\n                      \"Mucha\"=5))\ndata$conf_cong &lt;- set_labels(data$conf_cong,\n            labels=c( \"Nada\"=1,\n                      \"Poca\"=2,\n                      \"Algo\"=3,\n                      \"Bastante\"=4,\n                      \"Mucha\"=5))\ndata$conf_pres &lt;- set_labels(data$conf_pres,\n            labels=c( \"Nada\"=1,\n                      \"Poca\"=2,\n                      \"Algo\"=3,\n                      \"Bastante\"=4,\n                      \"Mucha\"=5))"
  },
  {
    "objectID": "practicos/07-content.html#análisis",
    "href": "practicos/07-content.html#análisis",
    "title": "Práctico 7. AFE y puntajes factoriales",
    "section": "",
    "text": "Código\ndata %&gt;% select(conf_gob:conf_pres) %&gt;% \n  plot_stackfrq() + theme(legend.position=\"bottom\")\n\n\n\n\n\n\n\n\n\nCódigo\ndata %&gt;% select(conf_gob:conf_pres) %&gt;% tab_corr(triangle = \"lower\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n \nGrado de confianza: El Gobierno\nGrado de confianza: Los Partidos\nPoliticos\nGrado de confianza: Carabineros\nGrado de confianza: Los Sindicatos\nGrado de confianza: Las Empresas\nPrivadas\nGrado de confianza: El Congreso Nacional\nGrado de confianza: El Presidente/a de\nla Republica\n\n\nGrado de confianza: El Gobierno\n \n \n \n \n \n \n \n\n\nGrado de confianza: Los Partidos\nPoliticos\n0.451***\n \n \n \n \n \n \n\n\nGrado de confianza: Carabineros\n0.517***\n0.232***\n \n \n \n \n \n\n\nGrado de confianza: Los Sindicatos\n0.175***\n0.280***\n0.201***\n \n \n \n \n\n\nGrado de confianza: Las Empresas\nPrivadas\n0.417***\n0.291***\n0.409***\n0.317***\n \n \n \n\n\nGrado de confianza: El Congreso Nacional\n0.470***\n0.523***\n0.321***\n0.331***\n0.450***\n \n \n\n\nGrado de confianza: El Presidente/a de\nla Republica\n0.719***\n0.355***\n0.524***\n0.127***\n0.378***\n0.442***\n \n\n\nComputed correlation used pearson-method with listwise-deletion.\n\n\n\n\n\nPodemos observar que todas las correlaciones son positivas, por lo que no quedaron ítems invertidos.\n\n\nCódigo\ndata %&gt;% select(conf_gob:conf_pres) %&gt;% psych::alpha()\n\n\n\nReliability analysis   \nCall: psych::alpha(x = .)\n\n  raw_alpha std.alpha G6(smc) average_r S/N    ase mean   sd median_r\n      0.79      0.81    0.81      0.38 4.2 0.0055  1.8 0.63     0.37\n\n    95% confidence boundaries \n         lower alpha upper\nFeldt     0.78  0.79   0.8\nDuhachek  0.78  0.79   0.8\n\n Reliability if an item is dropped:\n           raw_alpha std.alpha G6(smc) average_r S/N alpha se var.r med.r\nconf_gob        0.73      0.76    0.75      0.34 3.1   0.0070 0.013  0.33\nconf_part       0.77      0.79    0.79      0.38 3.8   0.0060 0.023  0.41\nconf_carab      0.76      0.79    0.79      0.38 3.7   0.0064 0.021  0.37\nconf_sind       0.80      0.82    0.82      0.43 4.5   0.0049 0.014  0.44\nconf_empre      0.75      0.78    0.79      0.38 3.6   0.0064 0.026  0.35\nconf_cong       0.75      0.77    0.77      0.36 3.3   0.0064 0.024  0.35\nconf_pres       0.74      0.77    0.76      0.36 3.3   0.0068 0.012  0.33\n\n Item statistics \n              n raw.r std.r r.cor r.drop mean   sd\nconf_gob   3405  0.78  0.78  0.77   0.67  1.6 0.87\nconf_part  3394  0.58  0.65  0.57   0.48  1.3 0.57\nconf_carab 3409  0.73  0.67  0.59   0.54  2.4 1.25\nconf_sind  3253  0.53  0.51  0.37   0.31  2.1 1.09\nconf_empre 3339  0.69  0.68  0.59   0.55  1.9 0.97\nconf_cong  3382  0.70  0.74  0.69   0.59  1.4 0.71\nconf_pres  3399  0.75  0.74  0.72   0.62  1.6 0.92\n\nNon missing response frequency for each item\n              1    2    3    4    5 miss\nconf_gob   0.60 0.24 0.13 0.03 0.01 0.00\nconf_part  0.79 0.16 0.04 0.01 0.00 0.01\nconf_carab 0.32 0.23 0.23 0.15 0.07 0.00\nconf_sind  0.42 0.23 0.25 0.09 0.02 0.05\nconf_empre 0.45 0.28 0.21 0.05 0.01 0.02\nconf_cong  0.68 0.21 0.09 0.01 0.00 0.01\nconf_pres  0.65 0.18 0.12 0.03 0.01 0.01\n\n\nSi sacamos conf_sind el alpha sube a 0.8\n\n\nCódigo\ndata %&gt;% select(conf_gob:conf_carab, conf_empre:conf_pres) %&gt;% psych::alpha()\n\n\n\nReliability analysis   \nCall: psych::alpha(x = .)\n\n  raw_alpha std.alpha G6(smc) average_r S/N    ase mean   sd median_r\n       0.8      0.82    0.82      0.43 4.5 0.0049  1.7 0.65     0.44\n\n    95% confidence boundaries \n         lower alpha upper\nFeldt     0.79   0.8  0.81\nDuhachek  0.79   0.8  0.81\n\n Reliability if an item is dropped:\n           raw_alpha std.alpha G6(smc) average_r S/N alpha se  var.r med.r\nconf_gob        0.74      0.76    0.74      0.39 3.2   0.0066 0.0089  0.39\nconf_part       0.80      0.81    0.80      0.46 4.3   0.0053 0.0118  0.44\nconf_carab      0.79      0.80    0.79      0.45 4.0   0.0055 0.0136  0.44\nconf_empre      0.79      0.81    0.80      0.45 4.2   0.0054 0.0178  0.46\nconf_cong       0.78      0.79    0.77      0.43 3.7   0.0056 0.0187  0.41\nconf_pres       0.75      0.77    0.75      0.41 3.4   0.0065 0.0089  0.43\n\n Item statistics \n              n raw.r std.r r.cor r.drop mean   sd\nconf_gob   3405  0.82  0.82  0.80   0.71  1.6 0.87\nconf_part  3394  0.57  0.65  0.55   0.46  1.3 0.57\nconf_carab 3409  0.76  0.69  0.60   0.56  2.4 1.25\nconf_empre 3339  0.69  0.67  0.56   0.51  1.9 0.97\nconf_cong  3382  0.69  0.74  0.66   0.57  1.4 0.71\nconf_pres  3399  0.80  0.78  0.76   0.68  1.6 0.92\n\nNon missing response frequency for each item\n              1    2    3    4    5 miss\nconf_gob   0.60 0.24 0.13 0.03 0.01 0.00\nconf_part  0.79 0.16 0.04 0.01 0.00 0.01\nconf_carab 0.32 0.23 0.23 0.15 0.07 0.00\nconf_empre 0.45 0.28 0.21 0.05 0.01 0.02\nconf_cong  0.68 0.21 0.09 0.01 0.00 0.01\nconf_pres  0.65 0.18 0.12 0.03 0.01 0.01\n\n\n\n\nCódigo\ndata &lt;- cbind(data, \n              \"conf_inst\"=rowMeans(data %&gt;%\n              dplyr::select(conf_gob:conf_carab, conf_empre:conf_pres), \n              na.rm=TRUE))\n\nsummary(data$conf_inst)\n\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n  1.000   1.167   1.500   1.700   2.167   5.000       6"
  },
  {
    "objectID": "practicos/07-content.html#análisis-factorial-exploratorio",
    "href": "practicos/07-content.html#análisis-factorial-exploratorio",
    "title": "Práctico 7. AFE y puntajes factoriales",
    "section": "",
    "text": "¿Qué se puede deducir de la matriz de correlaciones en relación a la estructura subyacente en términos de variables latentes? No hay claridad de grupos de indicadores asociados entre sí.\n\n\nKMO (Kaiser, Meyer, Olkin Measure of Sampling Adequacy):\n\nVaría entre 0 y 1. Contrasta si las correlaciones parciales entre las variables son pequeñas\nValores pequeños (menores a 0.5) indican que los datos no serían adecuados para AFE, ya que las correlaciones entre pares de variables no pueden ser explicadas por otras variables.\n\n\n\nCódigo\ncorMat  &lt;- data %&gt;% select(conf_gob:conf_pres) %&gt;%\n  cor(use = \"complete.obs\")  # estimar matriz pearson\n\nKMO(corMat)\n\n\nKaiser-Meyer-Olkin factor adequacy\nCall: KMO(r = corMat)\nOverall MSA =  0.81\nMSA for each item = \n  conf_gob  conf_part conf_carab  conf_sind conf_empre  conf_cong  conf_pres \n      0.78       0.81       0.86       0.80       0.86       0.83       0.77 \n\n\nEn este caso las correlaciones son altas, por lo que los datos sí son adecuados para AFE.\n\n\n\nSe utiliza para evluar la hipótesis que la matriz de correlaciones es una matriz identidad (diagonal=1 y bajo la diagonal=0)\n\nSe busca significación (p &lt; 0.05) ya que se espera que las variables estén correlacionadas\n\n\n\nCódigo\ncortest.bartlett(corMat, n = 3417)\n\n\n$chisq\n[1] 7942.816\n\n$p.value\n[1] 0\n\n$df\n[1] 21\n\n\nEn este caso el valor p es 0, así que hay significación estadística\n\n\n\n\n\nCódigo\ndata %&gt;% select(conf_gob:conf_pres) %&gt;% scree.plot()\n\n\n\n\n\n\n\nCódigo\nfa.parallel(corMat, n.obs=3417)\n\n\n\n\n\nParallel analysis suggests that the number of factors =  3  and the number of components =  2 \n\n\n\n\n\n\nejes principales\n\n\n\nCódigo\nfac_pa &lt;- data %&gt;% select(conf_gob:conf_pres) %&gt;% fa(nfactors = 3, fm= \"pa\")\n#summary(fac_pa)\nfac_pa\n\n\nFactor Analysis using method =  pa\nCall: fa(r = ., nfactors = 3, fm = \"pa\")\nStandardized loadings (pattern matrix) based upon correlation matrix\n             PA1   PA2   PA3   h2   u2 com\nconf_gob    0.77  0.14  0.00 0.72 0.28 1.1\nconf_part   0.07  0.72 -0.04 0.55 0.45 1.0\nconf_carab  0.52 -0.13  0.32 0.45 0.55 1.8\nconf_sind  -0.19  0.29  0.42 0.27 0.73 2.2\nconf_empre  0.14  0.07  0.59 0.50 0.50 1.1\nconf_cong   0.12  0.53  0.23 0.55 0.45 1.5\nconf_pres   0.87  0.00 -0.02 0.74 0.26 1.0\n\n                       PA1  PA2  PA3\nSS loadings           1.84 1.08 0.87\nProportion Var        0.26 0.15 0.12\nCumulative Var        0.26 0.42 0.54\nProportion Explained  0.48 0.29 0.23\nCumulative Proportion 0.48 0.77 1.00\n\n With factor correlations of \n     PA1  PA2  PA3\nPA1 1.00 0.51 0.48\nPA2 0.51 1.00 0.44\nPA3 0.48 0.44 1.00\n\nMean item complexity =  1.4\nTest of the hypothesis that 3 factors are sufficient.\n\ndf null model =  21  with the objective function =  2.3 with Chi Square =  7858.1\ndf of  the model are 3  and the objective function was  0.01 \n\nThe root mean square of the residuals (RMSR) is  0.01 \nThe df corrected root mean square of the residuals is  0.03 \n\nThe harmonic n.obs is  3337 with the empirical chi square  12.76  with prob &lt;  0.0052 \nThe total n.obs was  3417  with Likelihood Chi Square =  39.13  with prob &lt;  0.000000016 \n\nTucker Lewis Index of factoring reliability =  0.968\nRMSEA index =  0.059  and the 90 % confidence intervals are  0.044 0.077\nBIC =  14.72\nFit based upon off diagonal values = 1\nMeasures of factor score adequacy             \n                                                   PA1  PA2  PA3\nCorrelation of (regression) scores with factors   0.93 0.84 0.79\nMultiple R square of scores with factors          0.86 0.71 0.62\nMinimum correlation of possible factor scores     0.72 0.43 0.25\n\n\n\nMaximum likelihood\n\nMaximiza la posibilidad de que los parámetros reproduzcan los datos observados\n\n\nCódigo\nfac_ml &lt;- data %&gt;% select(conf_gob:conf_pres) %&gt;% fa(nfactors = 3, fm= \"ml\")\nfac_ml\n\n\nFactor Analysis using method =  ml\nCall: fa(r = ., nfactors = 3, fm = \"ml\")\nStandardized loadings (pattern matrix) based upon correlation matrix\n             ML1   ML2   ML3   h2   u2 com\nconf_gob    0.77  0.13  0.02 0.72 0.28 1.1\nconf_part   0.05  0.78 -0.01 0.64 0.36 1.0\nconf_carab  0.51 -0.12  0.29 0.43 0.57 1.7\nconf_sind  -0.19  0.24  0.46 0.27 0.73 1.9\nconf_empre  0.11  0.00  0.66 0.53 0.47 1.1\nconf_cong   0.14  0.44  0.30 0.52 0.48 2.0\nconf_pres   0.88 -0.01 -0.03 0.75 0.25 1.0\n\n                       ML1  ML2  ML3\nSS loadings           1.83 1.02 1.00\nProportion Var        0.26 0.15 0.14\nCumulative Var        0.26 0.41 0.55\nProportion Explained  0.47 0.27 0.26\nCumulative Proportion 0.47 0.74 1.00\n\n With factor correlations of \n     ML1  ML2  ML3\nML1 1.00 0.48 0.52\nML2 0.48 1.00 0.45\nML3 0.52 0.45 1.00\n\nMean item complexity =  1.4\nTest of the hypothesis that 3 factors are sufficient.\n\ndf null model =  21  with the objective function =  2.3 with Chi Square =  7858.1\ndf of  the model are 3  and the objective function was  0.01 \n\nThe root mean square of the residuals (RMSR) is  0.01 \nThe df corrected root mean square of the residuals is  0.03 \n\nThe harmonic n.obs is  3337 with the empirical chi square  14.35  with prob &lt;  0.0025 \nThe total n.obs was  3417  with Likelihood Chi Square =  35.46  with prob &lt;  0.000000097 \n\nTucker Lewis Index of factoring reliability =  0.971\nRMSEA index =  0.056  and the 90 % confidence intervals are  0.041 0.074\nBIC =  11.05\nFit based upon off diagonal values = 1\nMeasures of factor score adequacy             \n                                                   ML1  ML2  ML3\nCorrelation of (regression) scores with factors   0.93 0.85 0.82\nMultiple R square of scores with factors          0.86 0.73 0.67\nMinimum correlation of possible factor scores     0.72 0.45 0.34\n\n\n\n\n\n\nVarimax (ortogonal)\n\n\n\nCódigo\nfac_ml_var &lt;- data %&gt;% select(conf_gob:conf_pres) %&gt;% fa(nfactors = 3, fm= \"ml\", rotate=\"varimax\") # ortogonal\nfac_ml_var\n\n\nFactor Analysis using method =  ml\nCall: fa(r = ., nfactors = 3, rotate = \"varimax\", fm = \"ml\")\nStandardized loadings (pattern matrix) based upon correlation matrix\n            ML1  ML2  ML3   h2   u2 com\nconf_gob   0.76 0.32 0.17 0.72 0.28 1.4\nconf_part  0.21 0.74 0.22 0.64 0.36 1.3\nconf_carab 0.57 0.05 0.31 0.43 0.57 1.6\nconf_sind  0.04 0.23 0.46 0.27 0.73 1.5\nconf_empre 0.35 0.11 0.63 0.53 0.47 1.6\nconf_cong  0.34 0.48 0.42 0.52 0.48 2.8\nconf_pres  0.83 0.22 0.10 0.75 0.25 1.2\n\n                       ML1  ML2  ML3\nSS loadings           1.89 1.00 0.97\nProportion Var        0.27 0.14 0.14\nCumulative Var        0.27 0.41 0.55\nProportion Explained  0.49 0.26 0.25\nCumulative Proportion 0.49 0.75 1.00\n\nMean item complexity =  1.6\nTest of the hypothesis that 3 factors are sufficient.\n\ndf null model =  21  with the objective function =  2.3 with Chi Square =  7858.1\ndf of  the model are 3  and the objective function was  0.01 \n\nThe root mean square of the residuals (RMSR) is  0.01 \nThe df corrected root mean square of the residuals is  0.03 \n\nThe harmonic n.obs is  3337 with the empirical chi square  14.35  with prob &lt;  0.0025 \nThe total n.obs was  3417  with Likelihood Chi Square =  35.46  with prob &lt;  0.000000097 \n\nTucker Lewis Index of factoring reliability =  0.971\nRMSEA index =  0.056  and the 90 % confidence intervals are  0.041 0.074\nBIC =  11.05\nFit based upon off diagonal values = 1\nMeasures of factor score adequacy             \n                                                   ML1  ML2  ML3\nCorrelation of (regression) scores with factors   0.89 0.78 0.73\nMultiple R square of scores with factors          0.79 0.61 0.54\nMinimum correlation of possible factor scores     0.59 0.21 0.07\n\n\n\nPromax (oblicua)\n\n\n\nCódigo\nfac_ml_pro &lt;- data %&gt;% select(conf_gob:conf_pres) %&gt;% fa(nfactors = 3, fm= \"ml\", rotate=\"promax\")\nfac_ml_pro\n\n\nFactor Analysis using method =  ml\nCall: fa(r = ., nfactors = 3, rotate = \"promax\", fm = \"ml\")\nStandardized loadings (pattern matrix) based upon correlation matrix\n             ML1   ML2   ML3   h2   u2 com\nconf_gob    0.80  0.19 -0.09 0.72 0.28 1.1\nconf_part   0.03  0.78  0.01 0.64 0.36 1.0\nconf_carab  0.57 -0.14  0.23 0.43 0.57 1.4\nconf_sind  -0.15  0.13  0.51 0.27 0.73 1.3\nconf_empre  0.19 -0.12  0.67 0.53 0.47 1.2\nconf_cong   0.17  0.39  0.30 0.52 0.48 2.3\nconf_pres   0.91  0.07 -0.16 0.75 0.25 1.1\n\n                       ML1  ML2  ML3\nSS loadings           1.98 0.96 0.92\nProportion Var        0.28 0.14 0.13\nCumulative Var        0.28 0.42 0.55\nProportion Explained  0.51 0.25 0.24\nCumulative Proportion 0.51 0.76 1.00\n\n With factor correlations of \n     ML1  ML2  ML3\nML1 1.00 0.48 0.57\nML2 0.48 1.00 0.56\nML3 0.57 0.56 1.00\n\nMean item complexity =  1.4\nTest of the hypothesis that 3 factors are sufficient.\n\ndf null model =  21  with the objective function =  2.3 with Chi Square =  7858.1\ndf of  the model are 3  and the objective function was  0.01 \n\nThe root mean square of the residuals (RMSR) is  0.01 \nThe df corrected root mean square of the residuals is  0.03 \n\nThe harmonic n.obs is  3337 with the empirical chi square  14.35  with prob &lt;  0.0025 \nThe total n.obs was  3417  with Likelihood Chi Square =  35.46  with prob &lt;  0.000000097 \n\nTucker Lewis Index of factoring reliability =  0.971\nRMSEA index =  0.056  and the 90 % confidence intervals are  0.041 0.074\nBIC =  11.05\nFit based upon off diagonal values = 1\nMeasures of factor score adequacy             \n                                                   ML1  ML2  ML3\nCorrelation of (regression) scores with factors   0.93 0.85 0.83\nMultiple R square of scores with factors          0.87 0.72 0.69\nMinimum correlation of possible factor scores     0.74 0.45 0.38\n\n\n\n\n\n\n\nCódigo\ndata %&gt;% select(conf_gob:conf_pres) %&gt;% sjPlot::tab_fa(method = \"ml\", rotation = \"promax\", show.comm = TRUE, title = \"Análisis factorial de confianza en instituciones\")\n\n\nParallel analysis suggests that the number of factors =  3  and the number of components =  NA \n\n\n\nAnálisis factorial de confianza en instituciones\n\n\n\n\n\n\n\n\n\n \nFactor 1\nFactor 2\nFactor 3\nCommunality\n\n\nGrado de confianza: El Gobierno\n0.80\n0.19\n-0.09\n0.72\n\n\nGrado de confianza: Los Partidos\nPoliticos\n0.03\n0.78\n0.01\n0.64\n\n\nGrado de confianza: Carabineros\n0.57\n-0.14\n0.23\n0.43\n\n\nGrado de confianza: Los Sindicatos\n-0.15\n0.13\n0.51\n0.27\n\n\nGrado de confianza: Las Empresas\nPrivadas\n0.19\n-0.12\n0.67\n0.53\n\n\nGrado de confianza: El Congreso Nacional\n0.17\n0.39\n0.30\n0.52\n\n\nGrado de confianza: El Presidente/a de\nla Republica\n0.91\n0.07\n-0.16\n0.75\n\n\nTotal Communalities\n\n3.85\n\n\nCronbach's α\n0.78\n0.67\n0.48\n\n\n\n\n\n\nLuego de realizar el Análisis factorial exploratorio existen varias alternativas sobre los pasos a seguir. Por ejemplo, es posible estimar un promedio simple entre cada una de las variables de los factores. Otra opción es estimar puntajes factoriales.\n\n\n\n\n\nCódigo\nfac_ml &lt;- data %&gt;% select(conf_gob:conf_pres) %&gt;% fa(nfactors = 3, fm= \"ml\", rotate = \"promax\", scores = \"regression\")\nfac_ml\n\n\nFactor Analysis using method =  ml\nCall: fa(r = ., nfactors = 3, rotate = \"promax\", scores = \"regression\", \n    fm = \"ml\")\nStandardized loadings (pattern matrix) based upon correlation matrix\n             ML1   ML2   ML3   h2   u2 com\nconf_gob    0.80  0.19 -0.09 0.72 0.28 1.1\nconf_part   0.03  0.78  0.01 0.64 0.36 1.0\nconf_carab  0.57 -0.14  0.23 0.43 0.57 1.4\nconf_sind  -0.15  0.13  0.51 0.27 0.73 1.3\nconf_empre  0.19 -0.12  0.67 0.53 0.47 1.2\nconf_cong   0.17  0.39  0.30 0.52 0.48 2.3\nconf_pres   0.91  0.07 -0.16 0.75 0.25 1.1\n\n                       ML1  ML2  ML3\nSS loadings           1.98 0.96 0.92\nProportion Var        0.28 0.14 0.13\nCumulative Var        0.28 0.42 0.55\nProportion Explained  0.51 0.25 0.24\nCumulative Proportion 0.51 0.76 1.00\n\n With factor correlations of \n     ML1  ML2  ML3\nML1 1.00 0.48 0.57\nML2 0.48 1.00 0.56\nML3 0.57 0.56 1.00\n\nMean item complexity =  1.4\nTest of the hypothesis that 3 factors are sufficient.\n\ndf null model =  21  with the objective function =  2.3 with Chi Square =  7858.1\ndf of  the model are 3  and the objective function was  0.01 \n\nThe root mean square of the residuals (RMSR) is  0.01 \nThe df corrected root mean square of the residuals is  0.03 \n\nThe harmonic n.obs is  3337 with the empirical chi square  14.35  with prob &lt;  0.0025 \nThe total n.obs was  3417  with Likelihood Chi Square =  35.46  with prob &lt;  0.000000097 \n\nTucker Lewis Index of factoring reliability =  0.971\nRMSEA index =  0.056  and the 90 % confidence intervals are  0.041 0.074\nBIC =  11.05\nFit based upon off diagonal values = 1\nMeasures of factor score adequacy             \n                                                   ML1  ML2  ML3\nCorrelation of (regression) scores with factors   0.93 0.85 0.83\nMultiple R square of scores with factors          0.87 0.72 0.69\nMinimum correlation of possible factor scores     0.74 0.45 0.38\n\n\n\n\nCódigo\ndata &lt;- cbind(data, fac_ml$scores)\n\n\n\n\nCódigo\ndata %&gt;% select(conf_inst, ML1, ML2, ML3) %&gt;% head(10)\n\n\n   conf_inst        ML1        ML2        ML3\n1   1.000000 -0.8382387 -0.4724225 -0.7851196\n2   1.333333 -0.5980196 -0.6372386 -0.7486267\n3   1.000000 -0.8356784 -0.5480919 -0.9833033\n4   2.833333  2.1363615  0.1859941  0.9509994\n5   1.166667 -0.7238739 -0.5542404 -0.5297908\n6   1.000000 -0.8356784 -0.5480919 -0.9833033\n7   1.000000 -0.8356784 -0.5480919 -0.9833033\n8   1.666667 -0.4275077  0.2577645  0.6781084\n9   1.000000 -0.8356784 -0.5480919 -0.9833033\n10  1.333333 -0.5980196 -0.6372386 -0.7486267\n\n\nFactor 1\n\n\nCódigo\nsummary(data$ML1)\n\n\n    Min.  1st Qu.   Median     Mean  3rd Qu.     Max.     NA's \n-0.84894 -0.72453 -0.38400 -0.01872  0.50205  3.94763      222 \n\n\nFactor 2\n\n\nCódigo\nsummary(data$ML2)\n\n\n    Min.  1st Qu.   Median     Mean  3rd Qu.     Max.     NA's \n-0.75098 -0.54809 -0.40290 -0.00971  0.16165  5.39270      222 \n\n\nFactor 3\n\n\nCódigo\nsummary(data$ML3)\n\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n-1.1852 -0.7486 -0.1423 -0.0131  0.5225  3.7504     222 \n\n\n\n\n\n\n\nCódigo\ndata&lt;- data %&gt;% rename(inst_ejecutivo=ML1,\n                inst_partidos=ML2,\n                inst_trabajo=ML3)\n\n\n\n\n\n\n\nCódigo\ndata&lt;-na.omit(data)\nreg1 &lt;- lm(satis_dem~conf_inst, data=data)\nreg2 &lt;- lm(satis_dem~inst_ejecutivo, data=data)\nreg3 &lt;- lm(satis_dem~inst_partidos, data=data)\nreg4 &lt;- lm(satis_dem~inst_trabajo, data=data)\nreg5 &lt;- lm(satis_dem~inst_ejecutivo+inst_partidos+inst_trabajo, data=data)\n\n\n\nCódigo\ntexreg::knitreg(list(reg1, reg2, reg3, reg4, reg5))\n\n\n\n\nStatistical models\n\n\n\n\n \n\n\nModel 1\n\n\nModel 2\n\n\nModel 3\n\n\nModel 4\n\n\nModel 5\n\n\n\n\n\n\n(Intercept)\n\n\n0.68***\n\n\n1.70***\n\n\n1.70***\n\n\n1.70***\n\n\n1.70***\n\n\n\n\n \n\n\n(0.04)\n\n\n(0.01)\n\n\n(0.02)\n\n\n(0.02)\n\n\n(0.01)\n\n\n\n\nconf_inst\n\n\n0.61***\n\n\n \n\n\n \n\n\n \n\n\n \n\n\n\n\n \n\n\n(0.02)\n\n\n \n\n\n \n\n\n \n\n\n \n\n\n\n\ninst_ejecutivo\n\n\n \n\n\n0.42***\n\n\n \n\n\n \n\n\n0.34***\n\n\n\n\n \n\n\n \n\n\n(0.02)\n\n\n \n\n\n \n\n\n(0.02)\n\n\n\n\ninst_partidos\n\n\n \n\n\n \n\n\n0.39***\n\n\n \n\n\n0.17***\n\n\n\n\n \n\n\n \n\n\n \n\n\n(0.02)\n\n\n \n\n\n(0.03)\n\n\n\n\ninst_trabajo\n\n\n \n\n\n \n\n\n \n\n\n0.37***\n\n\n-0.02\n\n\n\n\n \n\n\n \n\n\n \n\n\n \n\n\n(0.02)\n\n\n(0.03)\n\n\n\n\nR2\n\n\n0.18\n\n\n0.18\n\n\n0.13\n\n\n0.11\n\n\n0.20\n\n\n\n\nAdj. R2\n\n\n0.18\n\n\n0.18\n\n\n0.13\n\n\n0.11\n\n\n0.20\n\n\n\n\nNum. obs.\n\n\n3134\n\n\n3134\n\n\n3134\n\n\n3134\n\n\n3134\n\n\n\n\n\n\n***p &lt; 0.001; **p &lt; 0.01; *p &lt; 0.05"
  },
  {
    "objectID": "schedule.html",
    "href": "schedule.html",
    "title": "Planificación",
    "section": "",
    "text": "Los tres componentes centrales del curso son las clases teóricas, los prácticos en R y los trabajos. Las clases se realizarán los días Miércoles 08:30 a 09:50 en sala E67. Los prácticos en R se realizarán el mismo día en el horario de 10:00 a 11:20.\n\nClases ( ): Lecturas, documentos de presentación y sesiones teóricas\nTalleres y actividades en R (): Actividades prácticas a desarrollar en el segundo bloque de la clase, según programación al final de esta página.\nLecturas (): Llegar a la clase con los textos leídos.\n\n\n\n\n\n Clases\n Talleres y prácticos en R\n Lecturas y material adicional\n\n\n Agosto \n\n\n\n\n\nMiércoles 14\nIntroducción\n\nPresentación del curso\nRepaso de conceptos centrales para entender el análisis estadístico\n\nPráctico 1\n- Ritchey, F. 2002. Estadísticas para las Ciencias Sociales: El potencial de la imaginación estadística”. México: Mc Graw Hill. Capítulo. 13\n- Moore, D.S. (2005). Estadística básica aplicada. Capítulo 6 “Introducción a la inferencia estadística”.\n\n\nMiércoles 21\nUnidad 1\n\nChi-cuadrado\n\nPráctico 2\n- Moore, D.S. Estadística básica aplicada. Capítulo 9 “Inferencia para tablas de contingencia”. |\n\n\nMiércoles 28\nUnidad 1\n\nAnálisis de correspondencia simple\n\nPráctico 3\n- Capítulos 1-5: Greenacre, M. La práctica del análisis de correspondencias. |\n\n\n Septiembre \n\n\n\n\n\nMiércoles 04\nUnidad 1\n\nAnálisis de correspondencia múltiple\n\nTrabajo 1 (25%): se entrega pauta, UNA semana para entregar.\nPráctico 4\n- Capítulos 6-10: Greenacre, M. La práctica del análisis de correspondencias. |\n\n\nMiércoles 11\nUnidad 1\nClase resolución dudas / preparación trabajo 1.\nEstudiantes entregan trabajo 1 (25%).\nTrabajo 1\n\n\n\nMiércoles 25\nUnidad 2\n\nCorrelación y regresión lineal\n\nPráctico 5\n- Moore, D. Estadística básica aplicada. Capítulo 2 “Análisis de relaciones”.\n\n\n Octubre \n\n\n\n\n\nMiércoles 02\nUnidad 2\n\nAlfa de Cronbach\nAnálisis de Componentes Principales / Análisis Factorial (parte 1)\n\nPráctico 6\n- Ancona, M. A. Análisis multivariable. Capítulo 5 “Análisis factorial”. Cea D’.\n\n\nMiércoles 09\nUnidad 2\n\nAnálisis de Componentes Principales / Análisis Factorial (parte 2)\n\nPráctico 7\n- Lloret-Segura, et al. “El análisis factorial exploratorio de los ítems: una guía práctica, revisada y actualizada.”\n\n\nMiércoles 16\nUnidad 2\n\nAnálisis de Componentes Principales / Análisis Factorial (parte 3)\n\nTrabajo 2  (25%): se entrega pauta, UNA semana para entregar.\nPráctico 8\n- Capítulo 17 “Exploratory factor analysis”: Field. Discovering statistics using R.\n\n\nMiércoles 23\nUnidad 2\nClase resolución dudas / preparación trabajo 2.\nEstudiantes entregan trabajo 2 (25%).\nTrabajo 2\n\n\n\nMiércoles 30\nUnidad 3\n\nAnálisis de conglomerados (parte 1)\n\nPráctico 9\n- Cea D’ Ancona, M. A. Análisis multivariable. Capítulo 3 “Análisis de conglomerados”.\n\n\n Noviembre \n\n\n\n\n\nMiércoles 06\nUnidad 3\n\nAnálisis de conglomerados (parte 2)\n\nPráctico 10\n- Cea D’ Ancona, M. A. Análisis multivariable. Capítulo 3 “Análisis de conglomerados”.\n\n\nMiércoles 13\nUnidad 3\n\nAnálisis de conglomerados (parte 3)\n\nTrabajo 3  (25%): se entrega pauta, UNA semana para entregar.\nPráctico 11\n- Cea D’ Ancona, M. A. Análisis multivariable. Capítulo 3 “Análisis de conglomerados”.\n- Giordani et al. An Introduction to Clustering with R. Parte 2 “Standard Clustering”.\n\n\nMiércoles 20\nUnidad 3\nClase resolución dudas / preparación trabajo 3.\nEstudiantes entregan trabajo 3 (25%)\nTrabajo 3\n\n\n\nMiércoles 27\nClase resolución dudas\n\n\n\n\n Diciembre \n\n\n\n\n\nMiércoles 04\nEXAMEN (25%)\n\n\n\n\nMiércoles 11\nEXAMEN DE REPETICIÓN"
  },
  {
    "objectID": "slides/ayudantia1/presentacion_clase_repaso.html",
    "href": "slides/ayudantia1/presentacion_clase_repaso.html",
    "title": "Lenguaje de R:  nociones básicas de código",
    "section": "",
    "text": "Repaso Software R Studio\n\n\n\n\nUniversidad Alberto Hurtado\nProfesores: Kevin Carrasco y Daniela Olivares  Ayudante: María Fernanda Núñez"
  },
  {
    "objectID": "slides/ayudantia1/presentacion_clase_repaso.html#section",
    "href": "slides/ayudantia1/presentacion_clase_repaso.html#section",
    "title": "Lenguaje de R:  nociones básicas de código",
    "section": "",
    "text": "Repaso Software R Studio\n\n\n\n\nUniversidad Alberto Hurtado\nProfesores: Kevin Carrasco y Daniela Olivares  Ayudante: María Fernanda Núñez"
  },
  {
    "objectID": "slides/ayudantia1/presentacion_clase_repaso.html#primera-distinción-r-y-rstudio",
    "href": "slides/ayudantia1/presentacion_clase_repaso.html#primera-distinción-r-y-rstudio",
    "title": "Lenguaje de R:  nociones básicas de código",
    "section": "Primera distinción: R y RStudio",
    "text": "Primera distinción: R y RStudio\n\n\n \n\nR es un lenguaje de programación que permite la manipulación, almacenaje, cálculo y visualización de datos.\n\n\n \n\nRStudio es el ambiente que nos permite visulizar de forma más amigable R. Contiene 4 espacios"
  },
  {
    "objectID": "slides/ayudantia1/presentacion_clase_repaso.html#cuadrantes-de-rstudio",
    "href": "slides/ayudantia1/presentacion_clase_repaso.html#cuadrantes-de-rstudio",
    "title": "Lenguaje de R:  nociones básicas de código",
    "section": "4 cuadrantes de RStudio:",
    "text": "4 cuadrantes de RStudio:\n\n\n\nEditor de sintaxis : entorno donde se despliega la hoja de códigos (generalmente un R Script) que se utlizará para procesar la base de datos\n\n\n\n\nConsola: visualizador de resultados de los códigos desplegados en la sintaxis"
  },
  {
    "objectID": "slides/ayudantia1/presentacion_clase_repaso.html#cuadrantes-de-rstudio-1",
    "href": "slides/ayudantia1/presentacion_clase_repaso.html#cuadrantes-de-rstudio-1",
    "title": "Lenguaje de R:  nociones básicas de código",
    "section": "4 cuadrantes de RStudio:",
    "text": "4 cuadrantes de RStudio:\n\n\n\nEntorno de trabajo: espacio donde se alojan la base de datos, los objetos, las tablas, etc. que vamos creando en nuestra sesión de trabajo\n\n\n\n\nEspacio de archivos/carpetas, gráficos, paquetes y ayuda"
  },
  {
    "objectID": "slides/ayudantia1/presentacion_clase_repaso.html#flujo-de-trabajo-ipo",
    "href": "slides/ayudantia1/presentacion_clase_repaso.html#flujo-de-trabajo-ipo",
    "title": "Lenguaje de R:  nociones básicas de código",
    "section": "Flujo de trabajo: IPO",
    "text": "Flujo de trabajo: IPO"
  },
  {
    "objectID": "slides/ayudantia1/presentacion_clase_repaso.html#crear-un-proyecto",
    "href": "slides/ayudantia1/presentacion_clase_repaso.html#crear-un-proyecto",
    "title": "Lenguaje de R:  nociones básicas de código",
    "section": "Crear un proyecto",
    "text": "Crear un proyecto\n\nAbrir RStudio\nHacer click en el siguiente simbólo que aparece en el esquina superior derecha:\n\nSeleccionar “New Project”\nSeleccionar “New directory”\nDefinir un nombre al proyecto\nDefinir ubicación del proyecto con la opción “Browse”"
  },
  {
    "objectID": "slides/ayudantia1/presentacion_clase_repaso.html#crear-un-script-o-documento-de-r",
    "href": "slides/ayudantia1/presentacion_clase_repaso.html#crear-un-script-o-documento-de-r",
    "title": "Lenguaje de R:  nociones básicas de código",
    "section": "Crear un script (o documento de R)",
    "text": "Crear un script (o documento de R)\nUn R Script es una hoja de código donde se escriben las instrucciones y los códigos para el tratamiento de datos. Para crear un R Script hay dos formas:\n\n\n\n\nEn la esquina superior izquierda hay un icono de una hoja con un signo “+” verde, hay que clikearlo y seleccionar R Script.\n\n\n\n\n\n\n\ncon las teclas Ctrl+Shift+N\n\n\n\n\nPara guardarlo, hay que (a) hacer click en el signo de documento en la parte superior del Script, o (b) con las teclas Crtl + S"
  },
  {
    "objectID": "slides/ayudantia1/presentacion_clase_repaso.html#r-como-calculadora",
    "href": "slides/ayudantia1/presentacion_clase_repaso.html#r-como-calculadora",
    "title": "Lenguaje de R:  nociones básicas de código",
    "section": "R como calculadora",
    "text": "R como calculadora\nPara sumar:\n\n1+2\n\n[1] 3"
  },
  {
    "objectID": "slides/ayudantia1/presentacion_clase_repaso.html#r-como-calculadora-1",
    "href": "slides/ayudantia1/presentacion_clase_repaso.html#r-como-calculadora-1",
    "title": "Lenguaje de R:  nociones básicas de código",
    "section": "R como calculadora",
    "text": "R como calculadora\nPara sumar:\n\n1+2\n\n[1] 3\n\n\nPara restar:\n\n3-1\n\n[1] 2"
  },
  {
    "objectID": "slides/ayudantia1/presentacion_clase_repaso.html#r-como-calculadora-2",
    "href": "slides/ayudantia1/presentacion_clase_repaso.html#r-como-calculadora-2",
    "title": "Lenguaje de R:  nociones básicas de código",
    "section": "R como calculadora",
    "text": "R como calculadora\nPara sumar:\n\n1+2\n\n[1] 3\n\n\nPara restar:\n\n3-1\n\n[1] 2\n\n\nPara multiplicar:\n\n3*5\n\n[1] 15"
  },
  {
    "objectID": "slides/ayudantia1/presentacion_clase_repaso.html#r-como-calculadora-3",
    "href": "slides/ayudantia1/presentacion_clase_repaso.html#r-como-calculadora-3",
    "title": "Lenguaje de R:  nociones básicas de código",
    "section": "R como calculadora",
    "text": "R como calculadora\nPara sumar:\n\n1+2\n\n[1] 3\n\n\nPara restar:\n\n3-1\n\n[1] 2\n\n\nPara multiplicar:\n\n3*5\n\n[1] 15\n\n\nPara dividir:\n\n4/2\n\n[1] 2"
  },
  {
    "objectID": "slides/ayudantia1/presentacion_clase_repaso.html#r-como-calculadora-4",
    "href": "slides/ayudantia1/presentacion_clase_repaso.html#r-como-calculadora-4",
    "title": "Lenguaje de R:  nociones básicas de código",
    "section": "R como calculadora",
    "text": "R como calculadora\nPara sumar:\n\n1+2\n\n[1] 3\n\n\nPara restar:\n\n3-1\n\n[1] 2\n\n\nPara multiplicar:\n\n3*5\n\n[1] 15\n\n\nPara dividir:\n\n4/2\n\n[1] 2\n\n\nPara elevar al cuadrado:\n\n2^2\n\n[1] 4"
  },
  {
    "objectID": "slides/ayudantia1/presentacion_clase_repaso.html#objetosvectoresvariables",
    "href": "slides/ayudantia1/presentacion_clase_repaso.html#objetosvectoresvariables",
    "title": "Lenguaje de R:  nociones básicas de código",
    "section": "Objetos/vectores/variables",
    "text": "Objetos/vectores/variables\n\n\nSe trata de: asignar un valor a un objeto o asignar a un objeto un valor, donde &lt; - es nuestro “asignador” que nos sirve para crear objetos\nSe pueden asignar números o nombres\n\n\n\nx &lt;- 2 #asignamos el valor\nx #ejecutamos\n\n[1] 2\n\ny &lt;- \"hola\"\n\ny\n\n[1] \"hola\""
  },
  {
    "objectID": "slides/ayudantia1/presentacion_clase_repaso.html#variable-conjunto-de-datos",
    "href": "slides/ayudantia1/presentacion_clase_repaso.html#variable-conjunto-de-datos",
    "title": "Lenguaje de R:  nociones básicas de código",
    "section": "Variable (conjunto de datos)",
    "text": "Variable (conjunto de datos)\n\nPodemos crear un vector, conjunto de datos o una variable con el siguiente comando:\n\n\ngenero &lt;- c(1,1,2,1,2,2,2,1,2)\n\n\nDonde: masculino=1; femenino =2"
  },
  {
    "objectID": "slides/ayudantia1/presentacion_clase_repaso.html#tipos-de-datos",
    "href": "slides/ayudantia1/presentacion_clase_repaso.html#tipos-de-datos",
    "title": "Lenguaje de R:  nociones básicas de código",
    "section": "Tipos de datos",
    "text": "Tipos de datos\n\n\nCharacter: valores alfanuméricos, es decir, letras, números y signos mezclados.\n\n\n\na &lt;- \"totalmente de acuerdo\"\na\n\n[1] \"totalmente de acuerdo\"\n\nclass(a) #para observar la clase (o tipo de vector) del objeto \n\n[1] \"character\""
  },
  {
    "objectID": "slides/ayudantia1/presentacion_clase_repaso.html#tipos-de-datos-1",
    "href": "slides/ayudantia1/presentacion_clase_repaso.html#tipos-de-datos-1",
    "title": "Lenguaje de R:  nociones básicas de código",
    "section": "Tipos de datos",
    "text": "Tipos de datos\n\n\nNumeric: valores numéricos, incluye decimales.\n\n\n\nb &lt;- 1\nb\n\n[1] 1\n\nclass(b)\n\n[1] \"numeric\""
  },
  {
    "objectID": "slides/ayudantia1/presentacion_clase_repaso.html#tipos-de-datos-2",
    "href": "slides/ayudantia1/presentacion_clase_repaso.html#tipos-de-datos-2",
    "title": "Lenguaje de R:  nociones básicas de código",
    "section": "Tipos de datos",
    "text": "Tipos de datos\n\n\nlogical: valores lógicos, TRUE (T) o FALSE (F).\n\n\n\ni &lt;- FALSE \ni\n\n[1] FALSE\n\nclass(i)\n\n[1] \"logical\""
  },
  {
    "objectID": "slides/ayudantia1/presentacion_clase_repaso.html#data-frame-o-base-de-datos",
    "href": "slides/ayudantia1/presentacion_clase_repaso.html#data-frame-o-base-de-datos",
    "title": "Lenguaje de R:  nociones básicas de código",
    "section": "Data Frame (o base de datos)",
    "text": "Data Frame (o base de datos)\n\n\nUn data frame es una base de datos que contiene dos dimensiones (columnas y filas) donde podemos agrupar variables\n\n\nSiguiendo con el caso anterior:\n\ngenero &lt;- c(1,1,2,1,2,2,2,1,2)\n\ningreso &lt;- c(100000,300000,500000,340000,300000,500000,650000,410000,750000)\n\nacuerdo &lt;- c(1,1,3,2,4,1,5,3,2)\n\nOJO: todas las variables deben tener la misma cantidad de casos"
  },
  {
    "objectID": "slides/ayudantia1/presentacion_clase_repaso.html#data-frame-o-base-de-datos-1",
    "href": "slides/ayudantia1/presentacion_clase_repaso.html#data-frame-o-base-de-datos-1",
    "title": "Lenguaje de R:  nociones básicas de código",
    "section": "Data Frame (o base de datos)",
    "text": "Data Frame (o base de datos)\nCreamos el data frame:\n\ndatos_ficticios &lt;- data.frame(genero, ingreso, acuerdo)\n\nVerificamos:\n\nnames(datos_ficticios)# nos muestra los nombres de nuestras variables\n\n[1] \"genero\"  \"ingreso\" \"acuerdo\"\n\ndim(datos_ficticios) #nos muestra la cantidad de casos (9) y de variables (3)\n\n[1] 9 3"
  },
  {
    "objectID": "slides/ayudantia1/presentacion_clase_repaso.html#librerias",
    "href": "slides/ayudantia1/presentacion_clase_repaso.html#librerias",
    "title": "Lenguaje de R:  nociones básicas de código",
    "section": "Librerias ",
    "text": "Librerias \n\nLas librerias corresponden al conjunto de paquetes que utlizaremos para trabajar en nuestra sesión de R\nEstas deben ser siempre cargadas antes de comenzar a trabajar en nuestra hoja de códigos. En cada sesión de trabajo\nSin embargo, esta deben ser instaladas solo una vez\n\nPara instalar librerías se utiliza el siguiente código:\n\ninstall.packages(“paquete_a_utilizar”)\n\nPara cargar librerias se utiliza el siguiente código:\n\nlibrary (paquete_A_utilizar)"
  },
  {
    "objectID": "slides/ayudantia1/presentacion_clase_repaso.html#paquetes",
    "href": "slides/ayudantia1/presentacion_clase_repaso.html#paquetes",
    "title": "Lenguaje de R:  nociones básicas de código",
    "section": "Paquetes ",
    "text": "Paquetes \n\nLos paquetes corresponden al conjunto de funciones específicas que usaremos en nuestra sesión de R.\nLos principales son dos:\n\n\npacman: este facilita y agiliza la lectura de los paquetes a utilizar en R\n\n\ntidyverse: es nuestro entorno de trabajo o colección de paquetes que utlizaremos para el procesamiento de nuestros datos, de los cuales destacan los paquetes dplyr y haven"
  },
  {
    "objectID": "slides/ayudantia1/presentacion_clase_repaso.html#paquetes-tidyverse",
    "href": "slides/ayudantia1/presentacion_clase_repaso.html#paquetes-tidyverse",
    "title": "Lenguaje de R:  nociones básicas de código",
    "section": "Paquetes: tidyverse ",
    "text": "Paquetes: tidyverse \n\ndplyr: nos permite seleccionar variables de un set de datos"
  },
  {
    "objectID": "slides/ayudantia1/presentacion_clase_repaso.html#paquetes-tidyverse-1",
    "href": "slides/ayudantia1/presentacion_clase_repaso.html#paquetes-tidyverse-1",
    "title": "Lenguaje de R:  nociones básicas de código",
    "section": "Paquetes: tidyverse",
    "text": "Paquetes: tidyverse\n\ndplyr: nos permite seleccionar variables de un set de datos\nhaven: cargar y exportar bases de datos en formatos .sav y .dta"
  },
  {
    "objectID": "slides/ayudantia1/presentacion_clase_repaso.html#paquetes-tidyverse-2",
    "href": "slides/ayudantia1/presentacion_clase_repaso.html#paquetes-tidyverse-2",
    "title": "Lenguaje de R:  nociones básicas de código",
    "section": "Paquetes: tidyverse",
    "text": "Paquetes: tidyverse\n\ndplyr: nos permite seleccionar variables de un set de datos\nhaven: cargar y exportar bases de datos en formatos .sav y .dta\ncar: para recodificar/agrupar valores de variables"
  },
  {
    "objectID": "slides/ayudantia1/presentacion_clase_repaso.html#paquetes-tidyverse-3",
    "href": "slides/ayudantia1/presentacion_clase_repaso.html#paquetes-tidyverse-3",
    "title": "Lenguaje de R:  nociones básicas de código",
    "section": "Paquetes: tidyverse",
    "text": "Paquetes: tidyverse\n\ndplyr: nos permite seleccionar variables de un set de datos\nhaven: cargar y exportar bases de datos en formatos .sav y .dta\ncar: para recodificar/agrupar valores de variables"
  },
  {
    "objectID": "slides/ayudantia1/presentacion_clase_repaso.html#importar-base-de-datos",
    "href": "slides/ayudantia1/presentacion_clase_repaso.html#importar-base-de-datos",
    "title": "Lenguaje de R:  nociones básicas de código",
    "section": "Importar base de datos ",
    "text": "Importar base de datos \nA continuación se presentan funciones para importar diferentes formatos de base de datos:\n\nbase_sav &lt;- read_sav(“input/data/nombre_de_la_base.sav”)\n\n\nbase.dta &lt;- haven::read_dta(file = “input/data/nombre_de_la_base.dta”, encoding = “UTF-8”)\n\n\nbase.csv &lt;- readr::read_csv(file =“input/data/nombre_de_la_base.csv”)"
  },
  {
    "objectID": "slides/ayudantia1/presentacion_clase_repaso.html#importar-base-de-datos-1",
    "href": "slides/ayudantia1/presentacion_clase_repaso.html#importar-base-de-datos-1",
    "title": "Lenguaje de R:  nociones básicas de código",
    "section": "Importar base de datos ",
    "text": "Importar base de datos \n\nbase.xlxx &lt;- readxl::read_excel(“input/data/nombre_de_la_base.xlsx”)\n\n\nbase.RData &lt;- base::load(file = “input/data/nombre_de_la_base.RData”)"
  },
  {
    "objectID": "slides/ayudantia1/presentacion_clase_repaso.html#seleccionar",
    "href": "slides/ayudantia1/presentacion_clase_repaso.html#seleccionar",
    "title": "Lenguaje de R:  nociones básicas de código",
    "section": "Seleccionar ",
    "text": "Seleccionar \n\nPara seleccionar:\n\n\ndim(datos_ficticios)\n\n[1] 9 3\n\nnames(datos_ficticios)\n\n[1] \"genero\"  \"ingreso\" \"acuerdo\"\n\n\ndplyr::select(datos_ficticios, genero, ingreso)\n\n\n  genero ingreso\n1      1  100000\n2      1  300000\n3      2  500000\n4      1  340000\n5      2  300000\n6      2  500000\n7      2  650000\n8      1  410000\n9      2  750000"
  },
  {
    "objectID": "slides/ayudantia1/presentacion_clase_repaso.html#filtrar",
    "href": "slides/ayudantia1/presentacion_clase_repaso.html#filtrar",
    "title": "Lenguaje de R:  nociones básicas de código",
    "section": "Filtrar ",
    "text": "Filtrar \n\nPara filtrar:\n\n\ndplyr::filter(datos_ficticios, genero == 1)\n\n  genero ingreso acuerdo\n1      1  100000       1\n2      1  300000       1\n3      1  340000       2\n4      1  410000       3"
  },
  {
    "objectID": "slides/ayudantia1/presentacion_clase_repaso.html#recodificar",
    "href": "slides/ayudantia1/presentacion_clase_repaso.html#recodificar",
    "title": "Lenguaje de R:  nociones básicas de código",
    "section": "Recodificar ",
    "text": "Recodificar \n\nEjemplo: para recodificar el grado de acuerdo de 1 a 5 a 3 valores.\n\n\ntable(datos_ficticios$acuerdo)\n\n\n1 2 3 4 5 \n3 2 2 1 1 \n\nlibrary(car)\n\nWarning: package 'car' was built under R version 4.3.3\n\n\nLoading required package: carData\n\n\nWarning: package 'carData' was built under R version 4.3.3\n\ndatos_ficticios$acuerdo &lt;- car::recode(datos_ficticios$acuerdo, c(\"1=1\", \"2=1\",\"3=2\", \"4=3,5=3\"))"
  },
  {
    "objectID": "slides/ayudantia1/presentacion_clase_repaso.html#transformar-variables-creación-o-derivación",
    "href": "slides/ayudantia1/presentacion_clase_repaso.html#transformar-variables-creación-o-derivación",
    "title": "Lenguaje de R:  nociones básicas de código",
    "section": "Transformar variables: creación o derivación ",
    "text": "Transformar variables: creación o derivación \n\nmutate() de dplyr\nCase_when(): cuando el valor sea X, asignar un nombre Y.\nif_else: para crear una variable a partir de una condición."
  },
  {
    "objectID": "slides/ayudantia1/presentacion_clase_repaso.html#guardar-procesamiento-de-los-datos",
    "href": "slides/ayudantia1/presentacion_clase_repaso.html#guardar-procesamiento-de-los-datos",
    "title": "Lenguaje de R:  nociones básicas de código",
    "section": "Guardar procesamiento de los datos ",
    "text": "Guardar procesamiento de los datos \n\nSolo utilizamos la siguiente línea de código:\n\n\n#saveRDS(datos_ficticios, file = \"input/data/proc/datos_proc.Rdata\")"
  },
  {
    "objectID": "slides/ayudantia1/presentacion_clase_repaso.html#ahora-con-datos-reales",
    "href": "slides/ayudantia1/presentacion_clase_repaso.html#ahora-con-datos-reales",
    "title": "Lenguaje de R:  nociones básicas de código",
    "section": "Ahora con datos reales",
    "text": "Ahora con datos reales"
  },
  {
    "objectID": "syllabus.html",
    "href": "syllabus.html",
    "title": "Programa",
    "section": "",
    "text": "Daniela Olivares\n danielaolivarescollio@gmail.com\n\n\n\n   Kevin Carrasco\n kevin.carrasco@ug.uchile.cl\n\n\n\n\n\n   Miércoles\n   Agosto 14 - Diciembre 11 2024\n   08:30 a 09:50 y 10:00 a 11:20\n   Sala Lab. E67"
  },
  {
    "objectID": "syllabus.html#propósitos-de-aprendizaje",
    "href": "syllabus.html#propósitos-de-aprendizaje",
    "title": "Programa",
    "section": "Propósitos de aprendizaje",
    "text": "Propósitos de aprendizaje\nAl término de esta actividad curricular los estudiantes serán capaces de:\n\nIdentificar las diferencias claves entre las técnicas de análisis exploratorio.\nInterpretar la información derivada de software estadísticos de cada técnica. software estadísticos de cada técnica.\nAplicar las diferentes técnicas de análisis exploratorio a problemas de investigación social."
  },
  {
    "objectID": "syllabus.html#contenidos",
    "href": "syllabus.html#contenidos",
    "title": "Programa",
    "section": "Contenidos",
    "text": "Contenidos\n\nUnidad 1: Análisis de variables observadas categóricas: Análisis de Correspondencias simple y múltiple\n\nAspectos previos al Análisis de Correspondencias: la prueba Chi-cuadrado.\nObjetivos del Análisis de Correspondencias.\nConstrucción de mapas perceptuales: conceptos de media ponderada, masa, perfiles, vértices, distancias Chi-cuadrado e inercia.\nReducción de dimensionalidad y escalamiento óptimo: cómo construir mapas perceptuales bidimensionales.\nTransformación de mapas simétricos en mapas asimétricos.\nImplementación de la técnica y análisis de resultados en software estadísticos.\n\n\n\nUnidad 2: Análisis exploratorio de variables latentes: Análisis Factorial y Análisis de Componentes Principales\n\nAspectos previos: correlación y regresión lineal de mínimos cuadrados ordinarios (MCO).\nAproximaciones a la técnica: diferencias entre análisis de variables reflectivas y de variables formativas; diferencias entre Análisis de Componentes Principales y Análisis de Factor Común (o “Análisis Factorial”); diferencias entre análisis exploratorio y análisis confirmatorio.\nForma de operación del análisis de componentes principales (ACP): procedimiento de extracción componentes; criterios para escoger el número de componentes adecuado; análisis de la matriz factorial; rotación de componentes y tipos de rotación disponibles; interpretación y evaluación del modelo final; cálculo de puntuaciones factoriales.\nImplementación de la técnica e interpretación de resultados en software estadísticos.\nAplicación práctica (construcción de escalas): el ACP como técnica para chequear la dimensionalidad de una escala; chequeo de la validez de una escala (Alfa de Cronbach).\n\n\n\nUnidad 3: Análisis exploratorio de variables observadas: Análisis de conglomerados\n\nObjetivo de la técnica: clasificación en ciencias sociales.\nEl análisis de conglomerado como técnica de clasificación, reducción de datos e identificación de relaciones.\nFuncionamiento de la técnica: definición de supuestos; elección de variables, de la medición de similitud entre objetos y del método de conglomeración; definición del número adecuado de grupos, caracterización y validación de dichos grupos.\nImplementación de la técnica e interpretación de resultados en software estadísticos."
  },
  {
    "objectID": "syllabus.html#metodología",
    "href": "syllabus.html#metodología",
    "title": "Programa",
    "section": "Metodología",
    "text": "Metodología\nEl curso se realizará de una manera presencial y consistirá en clases expositivas y prácticas en donde se revisarán los elementos teóricos básicos de cada técnica estadística, así como su aplicación en la investigación empírica y la interpretación de sus resultados. La participación activa de los/as estudiantes en clases formará parte de la nota final.\nEl curso cuenta también con sesiones de ayudantía en donde los/las estudiantes reforzarán los contenidos aprendidos en la cátedra, aprenderán el uso de comandos de software estadísticos y se prepararán para los trabajos. La definición del horario se realizará la primera semana de clases."
  },
  {
    "objectID": "syllabus.html#evaluación-de-aprendizajes",
    "href": "syllabus.html#evaluación-de-aprendizajes",
    "title": "Programa",
    "section": "Evaluación de aprendizajes",
    "text": "Evaluación de aprendizajes\nDurante el semestre se realizarán distintas actividades evaluadas, que incluyen instancias individuales y en pareja:\nTrabajos aplicados: durante el semestre los/as estudiantes deberán realizar tres trabajos en pareja, en donde los/as estudiantes deberán aplicar los contenidos del curso a una pregunta de investigación relevante sociológicamente que pueda ser respondida por medio de las técnicas vistas en el curso. Los/as estudiantes deberán utilizar el software R. Cada trabajo equivale a un 25% de la nota final.\nExamen: Se realizará un examen oral individual para quienes tengan una nota menor a 5,5. Se evaluará todo el contenido del curso. Este examen tiene una ponderación del 25%.\nPodrán rendir un examen de repetición los/as estudiantes que terminaron con una nota final, ya rendido el primer examen, entre 3,5 a 3,9. Considerando que se trata de un examen de última oportunidad, a quienes aprueban el examen de repetición (esto es, obtengan la nota que respectivamente necesitan según sus notas de presentación), se les ingresará al sistema una nota final de 4,0 que permita aprobar la asignatura.\nTendrán derecho a rendir los exámenes todos los/as estudiantes que hayan cumplido con la exigencia de asistencia mínima al curso, correspondiente al 70% de las clases efectivamente realizadas, y cuyo promedio de notas sea igual o superior a 3,5.\n\n\n\nEvaluación\nPonderación\n\n\n\n\nTrabajo 1\n25%\n\n\nTrabajo 2\n25%\n\n\nTrabajo 3\n25%\n\n\nExamen\n25%\n\n\nExamen de repetición\n\n\n\n\nLas evaluaciones se corregirán en un plazo máximo de 15 días hábiles transcurrida la fecha de su entrega y proporcionará retroalimentación en el formato que la profesora y ayudantes estimen conveniente. Se autoriza el uso de un lenguaje inclusivo en las evaluaciones del curso a quienes deseen emplearlo, respetando un vocabulario formal y académico. Las peticiones de recorrección deberán hacerse por correo electrónico a l-s profesores (daolivares@uahurtado.cl; kcarrasco@uahurtado.cl ) en un plazo máximo de 5 días hábiles desde la entrega de las correcciones. Las solicitudes tendrán que estar debidamente fundamentadas y no se aceptarán recorrecciones de pruebas redactadas con lápiz grafito o de texto escrito en lugares previamente no autorizados en la evaluación."
  },
  {
    "objectID": "syllabus.html#información-general",
    "href": "syllabus.html#información-general",
    "title": "Programa",
    "section": "Información general",
    "text": "Información general\nLos/as alumnas/os que no se presenten o entreguen una evaluación por enfermedad deben hacer llegar el certificado médico a coordinación en el plazo establecido por el reglamento. Quienes no lo hagan serán evaluados con nota 1,0.\nPara presentarse a examen se requiere nota promedio 3,5 y una asistencia mínima del 70% a las clases. En caso de eximición, la nota mínima es igual o superior a 5,5, el docente es quien decidirá si el curso tendrá alumnos que se eximen o no y si los tuviera deberá repetir la nota promedio del curso en el examen."
  },
  {
    "objectID": "syllabus.html#reglamento-académico-del-estudiante-de-pregrado.",
    "href": "syllabus.html#reglamento-académico-del-estudiante-de-pregrado.",
    "title": "Programa",
    "section": "Reglamento Académico del Estudiante de Pregrado.",
    "text": "Reglamento Académico del Estudiante de Pregrado.\nArt. 23.- Cualquier conducta de un estudiante que tienda a viciar la evaluación de actividades académicas o que constituya fraude académico, figura que contempla irregularidades tales como copia, suplantación o alteración de evaluaciones, plagio, faltas a la ética profesional, sin que esta enumeración sea taxativa, dará origen a las siguientes sanciones, según la gravedad de la falta cometida: (i) nota mínima 1,0 (uno) en la respectiva evaluación; (ii) reprobación del curso respectivo; (iii) amonestación; (iv) permanencia condicional; (v) suspensión de actividades académicas por un período académico; (vi) expulsión de la Universidad.\nAsimismo, toda actividad de un estudiante que entorpezca gravemente y/o dificulte el normal desarrollo académico, podrá ser sancionada de conformidad a las disposiciones establecidas en el Reglamento de Conducta y Convivencia de la Universidad Alberto Hurtado.\nArt. 24.- Las dos primeras sanciones previstas en el artículo anterior, a saber (i) Nota mínima 1,0; y (ii) Reprobación del Curso respectivo, son prerrogativa del docente a cargo de la asignatura, quien deberá informarlas a la Dirección de la Carrera.\n***Para evitar el plagio todo trabajo, composición o material documental que los estudiantes realicen debe citar adecuadamente las fuentes utilizadas, ya sea a través del sistema APA (American Psychological Association) http://www.apastyle.org o MLA (Modern Language Association) http://www.mla.org/."
  }
]