[
  {
    "objectID": "trabajos.html",
    "href": "trabajos.html",
    "title": "Trabajos",
    "section": "",
    "text": "Proximamente…"
  },
  {
    "objectID": "schedule.html",
    "href": "schedule.html",
    "title": "Planificación",
    "section": "",
    "text": "Los tres componentes centrales del curso son las clases teóricas, los prácticos en R y los trabajos. Las clases se realizarán los días Martes 16:00 a 17:20 en sala E67. Los prácticos en R se realizarán el mismo día en el horario de 17:30 a 18:50.\n\nClases ( ): Lecturas, documentos de presentación y sesiones teóricas\nTalleres y actividades en R (): Actividades prácticas a desarrollar en el segundo bloque de la clase, según programación al final de esta página.\nLecturas (): Llegar a la clase con los textos leídos.\n\n\n\n\n\n Clases\n Talleres y prácticos en R\n Lecturas y material adicional\n\n\n\n\n Marzo \n\n\n\n\n\nMartes 12\nUnidad 1: Elementos y herramientas de R\nPráctico 1\n- Leer detalladamente programa del curso\n\n\nMartes 19\nUnidad 1: Elementos y herramientas de R\nPráctico 2\n\n\n\nMartes 26\nUnidad 2: Operacionalización y análisis descriptivo de datos\nPráctico 3\n\n\n\n Abril \n\n\n\n\n\nMartes 02\nUnidad 2: Operacionalización y análisis descriptivo de datos\nPráctico 4\n\n\n\nMartes 09\nUnidad 2: Operacionalización y análisis descriptivo de datos\nPráctico 5\n\n\n\nMartes 16\nSesión de apoyo Trabajo N°2\nTrabajo 2 (18/04)\n\n\n\nMartes 23\nUnidad 3: Asociación de variables en R\nPráctico 6\n\n\n\nMartes 30\nUnidad 3: Indices y escalas\nPráctico 7\n\n\n\n Mayo \n\n\n\n\n\nMartes 07\nSesión de apoyo Trabajo N°3\nTrabajo 3\n\n\n\nMartes 14\nUnidad 4: Regresión lineal y regresión logística\nPráctico 8\n\n\n\nMartes 21\nFeriado\n\n\n\n\nMartes 28\nUnidad 4: Regresión lineal y regresión logística\nPráctico 9\n\n\n\n Junio \n\n\n\n\n\nMartes 04\nSesión de apoyo Trabajo N°4\nTrabajo N°4\n\n\n\nMartes 11\nTrabajo de investigación\nPráctico 10\n\n\n\nMartes 18\nTrabajo de investigación\nPresentaciones\n\n\n\nMartes 25\nSesión de apoyo evaluación final.\n\n\n\n\n Julio \n\n\n\n\n\nMartes 02\nExamen final"
  },
  {
    "objectID": "practicos/practico5.html",
    "href": "practicos/practico5.html",
    "title": "Práctico 5",
    "section": "",
    "text": "Code\npacman::p_load(sjlabelled,\n               dplyr, #Manipulacion de datos\n              stargazer, #Tablas\n              sjmisc, # Tablas\n              summarytools, # Tablas\n              kableExtra, #Tablas\n              sjPlot, #Tablas y gráficos\n              corrplot, # Correlaciones\n              sessioninfo, # Información de la sesión de trabajo\n              ggplot2) # Para la mayoría de los gráficos"
  },
  {
    "objectID": "practicos/practico5.html#descriptivos",
    "href": "practicos/practico5.html#descriptivos",
    "title": "Práctico 5",
    "section": "4.1 Descriptivos",
    "text": "4.1 Descriptivos\n\n\nCode\nsjmisc::descr(data,\n      show = c(\"label\",\"range\", \"mean\", \"sd\", \"NA.prc\", \"n\"))%&gt;% # Selecciona estadísticos\n      kable(.,\"markdown\") # Esto es para que se vea bien en quarto\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nvar\nlabel\nn\nNA.prc\nmean\nsd\nrange\n\n\n\n\n4\npromedio\npromedio\n11\n0\n3.40077\n1.016976\n3.59 (2.3-5.9)\n\n\n1\ngdp\ngdp\n11\n0\n15528.18364\n6480.045512\n19523.79 (5631.2-25154.99)\n\n\n3\nlife_exp\nlife_exp\n11\n0\n75.90909\n2.286593\n8.8 (71.24-80.04)\n\n\n2\ngini\ngini\n11\n0\n45.46364\n4.156266\n14.2 (39.7-53.9)"
  },
  {
    "objectID": "practicos/practico5.html#otra-opción",
    "href": "practicos/practico5.html#otra-opción",
    "title": "Práctico 5",
    "section": "4.2 otra opción",
    "text": "4.2 otra opción\n\n\nCode\nview(dfSummary(data, headings=FALSE))\n\n\nSwitching method to 'browser'\n\n\nOutput file written: C:\\Users\\kevin\\AppData\\Local\\Temp\\RtmpU7Tojn\\file536c8da31ac.html"
  },
  {
    "objectID": "practicos/08-content.html",
    "href": "practicos/08-content.html",
    "title": "08: Regresión lineal múltiple",
    "section": "",
    "text": "El desarrollo de esta guía tiene por objetivo revisar algunos procedimientos para la estimación de regresiones lineales y múltiples en R.\nPor temas de orden y reproducibilidad, en este curso hemos separado en dos momentos el trabajo con datos, y dos archivos de código correspondientes.\n\n\n\nCohesión barrial con elsoc 2016. Código de preparación disponible en: https://r-data-analisis.netlify.app/practicos/resumen-content#preparaci%C3%B3n",
    "crumbs": [
      "Prácticos",
      "Talleres",
      "09: Práctico 8"
    ]
  },
  {
    "objectID": "practicos/08-content.html#objetivo-de-la-práctica",
    "href": "practicos/08-content.html#objetivo-de-la-práctica",
    "title": "08: Regresión lineal múltiple",
    "section": "",
    "text": "El desarrollo de esta guía tiene por objetivo revisar algunos procedimientos para la estimación de regresiones lineales y múltiples en R.\nPor temas de orden y reproducibilidad, en este curso hemos separado en dos momentos el trabajo con datos, y dos archivos de código correspondientes.",
    "crumbs": [
      "Prácticos",
      "Talleres",
      "09: Práctico 8"
    ]
  },
  {
    "objectID": "practicos/08-content.html#antecedentes-de-los-datos-a-utilizar",
    "href": "practicos/08-content.html#antecedentes-de-los-datos-a-utilizar",
    "title": "08: Regresión lineal múltiple",
    "section": "",
    "text": "Cohesión barrial con elsoc 2016. Código de preparación disponible en: https://r-data-analisis.netlify.app/practicos/resumen-content#preparaci%C3%B3n",
    "crumbs": [
      "Prácticos",
      "Talleres",
      "09: Práctico 8"
    ]
  },
  {
    "objectID": "practicos/08-content.html#librerias",
    "href": "practicos/08-content.html#librerias",
    "title": "08: Regresión lineal múltiple",
    "section": "1. Librerías principales (de R) a utilizar en el análisis",
    "text": "1. Librerías principales (de R) a utilizar en el análisis\n\n\nCódigo\npacman::p_load(dplyr, car, sjmisc, sjPlot, sjlabelled, stargazer, kableExtra, corrplot, texreg, ggplot2, ggpubr)\n\n\no desde internet:\n\n\nCódigo\nload(url(\"https://github.com/Kevin-carrasco/R-data-analisis/raw/main/practicos/files/elsoc2016_proc.RData\"))",
    "crumbs": [
      "Prácticos",
      "Talleres",
      "09: Práctico 8"
    ]
  },
  {
    "objectID": "practicos/08-content.html#análisis-descriptivo",
    "href": "practicos/08-content.html#análisis-descriptivo",
    "title": "08: Regresión lineal múltiple",
    "section": "Análisis descriptivo",
    "text": "Análisis descriptivo\n\n\nCódigo\nsjmisc::descr(proc_data,\n      show = c(\"label\",\"range\", \"mean\", \"sd\", \"NA.prc\", \"n\"))%&gt;% # Selecciona estadísticos\n      kable(.,\"markdown\") # Esto es para que se vea bien en quarto\n\n\n\n\nTabla 1: Descriptivos\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nvar\nlabel\nn\nNA.prc\nmean\nsd\nrange\n\n\n\n\n2\nideal\nEste barrio es ideal para mi\n2926\n0.0341647\n2.615174\n1.0202541\n4 (0-4)\n\n\n4\nintegracion\nMe siento integrado en este barrio\n2923\n0.1366587\n2.565515\n0.9993502\n4 (0-4)\n\n\n3\nidentificacion\nMe identifico con la gente de este barrio\n2923\n0.1366587\n2.523777\n0.9884856\n4 (0-4)\n\n\n8\npertenencia\nMe siento parte de este barrio\n2925\n0.0683293\n2.627692\n0.9878809\n4 (0-4)\n\n\n5\nm01\nNivel educacional\n2925\n0.0683293\n5.260513\n2.2015019\n9 (1-10)\n\n\n7\nm0_sexo\nSexo del entrevistado\n2927\n0.0000000\n1.602665\n0.4894300\n1 (1-2)\n\n\n6\nm0_edad\nEdad del entrevistado\n2927\n0.0000000\n46.090878\n15.2867983\n70 (18-88)\n\n\n1\ncohesion_barrial\ncohesion_barrial\n2917\n0.3416467\n10.333562\n3.3978552\n16 (0-16)\n\n\n\n\n\n\n\n\nEn la Tabla 1 podemos observar los descriptivos generales de la base de datos procesada que utilizamos en el práctico anterior. Contiene ya creado el índice de cohesión barrial cuya media es de 10,33",
    "crumbs": [
      "Prácticos",
      "Talleres",
      "09: Práctico 8"
    ]
  },
  {
    "objectID": "practicos/08-content.html#asociación-de-variables",
    "href": "practicos/08-content.html#asociación-de-variables",
    "title": "08: Regresión lineal múltiple",
    "section": "Asociación de variables",
    "text": "Asociación de variables\nSeleccionamos las principales variables y cambiamos su nombre. No seleccionaremos las variables originales que construyeron el índice.\n\n\nCódigo\nproc_data &lt;- proc_data %&gt;% select(cohesion_barrial, edad=m0_edad, educacion=m01, sexo=m0_sexo)\n\n\nPodemos ver la asociación de todas las variables, como lo muestra la ?@cor-complete\n\n\nCódigo\nM &lt;- cor(proc_data, use = \"complete.obs\") # Usar solo casos con observaciones completas\ndiag(M) = NA # Elimina la diagonal (correlaciones absolutas de cada variable consigmo misma)\nrownames(M) &lt;- c(\"A. Cohesión barrial\",\n                         \"B. Edad\",\n                         \"C. Educación\",\n                         \"D. Sexo\")\ncolnames(M) &lt;-c(\"(A)\", \"(B)\",\"(C)\", \"(D)\")\n\n\n\n\nCódigo\ncorrplot::corrplot(M,\n  method = \"color\", # Cambia los círculos por color completo de cada cuadrante\n  addCoef.col = \"#000390\", # Color de los coeficientes\n  type = \"upper\", # Deja solo las correlaciones de arriba\n  tl.col = \"black\", # COlor letras, rojo por defecto\n  na.label = \"-\")\n\n\n\n\n\nCorrelación variables elsoc 2016",
    "crumbs": [
      "Prácticos",
      "Talleres",
      "09: Práctico 8"
    ]
  },
  {
    "objectID": "practicos/08-content.html#medias-condicionales",
    "href": "practicos/08-content.html#medias-condicionales",
    "title": "08: Regresión lineal múltiple",
    "section": "Medias condicionales",
    "text": "Medias condicionales\nAntes de avanzar desde la correlación al método de regresión es importante conocer el concepto de media condicional.\nImaginemos un juego de tacataca con dos variables: cantidad de juegos previos y puntos obtenidos en un partido. En estas variables, el promedio de puntos es 4. Es decir, si conocemos a algún individuo que pertence al grupo de “datos”, sabemos que su puntaje se encuentra probablemente cercano a 4. ¿Podemos mejorar nuestra estimación utilizando el puntaje de X? Si el sujeto nos dice que ha jugado antes 6 veces, probablemente vamos a estimar un puntaje superior de puntos, tal vez más cercano a 6.\nLo que estamos haciendo es utilizar la información que conocemos de X para dar una estimación de Y, que sea más precisa que el promedio bruto.\n\nMirando el gráfico de nube de puntos, sabemos que tres personas han jugado antes una vez, pero una de ellas tuvo 2 puntos, otra 3 y otra 4. Con estos datos podemos calcular la media de Y para X=1, que sería igual a 3. En otras palabras, la media condicional de Y cuando X=1 es 3. Con esto, uno podría calcular la media condicional para cada punto de X y hacer una estimación más precisa de Y. Sin embargo, este proceso todavía no nos permite generalizar más eficientemte la relación entre X e Y.\n¿Cuántos puntos (Y) se obtienen según la experiencia previa de juego (X)? Esta pregunta nos conduce al cálculo de una recta que atraviese los puntos y que generalice la relación entre X e Y.",
    "crumbs": [
      "Prácticos",
      "Talleres",
      "09: Práctico 8"
    ]
  },
  {
    "objectID": "practicos/08-content.html#residuos",
    "href": "practicos/08-content.html#residuos",
    "title": "08: Regresión lineal múltiple",
    "section": "Residuos",
    "text": "Residuos\nEn el gráfico anterior vemos que la línea resume la relación entre X e Y, pero claramente es una simplificación que no abarca toda la variabilidad de los datos.\nPor ejemplo, para el sujeto cuya experiencia es haber jugado 1 vez y luego gana 3 puntos, esta línea predice exáctamente su puntaje basada en su experiencia. Sin embargo, el sujeto que ha jugado 3 veces y saca 6 puntos se encuentra más lejos de la línea y por lo tanto esta línea o “modelo predictivo” no representa tan bien su puntaje. A esto se refieren los residuos, que es la diferencia entre el valor predicho (o \\(\\widehat{Y}\\)) y el observado \\(Y\\), siendo los valores predichos de Y los que pasan por la recta a la altura de cada valor de X. Por lo tanto, la mejor recta será aquella que minimice al máximo los residuos.\n\nEl sentido de la recta que resume de mejor manera la relación entre dos variables es que minimice la suma de todos los residuos. ¿Cómo realizar este procedimiento?\n\nPara realizar la suma de los residuos estos se elevan al cuadrado, lo que se denomina Suma de residuos al cuadrado o \\(SS_{residual}\\). Se eleva al cuadrado ya que como hay residuos positivos y negativos, unos cancelarían a otros y la suma seía 0, tal como sucede en la formula de la varianza.\nDe la infinita cantidad de rectas que se pueden trazar, siempre hay una que tiene un valor menor de \\(SS_{residual}\\). Este procedimiento es el que da nombre al proceso de estimación: mínimos (residuos) cuadrados ordinarios, o OLS (Ordinary Least Squares).\n\n¿Cómo funciona esto con nuestro ejemplo?\n\n\nCódigo\n#Grafico x1 = ACT\ngraph1 &lt;- ggplot(proc_data, aes(x = edad, y = cohesion_barrial)) +\n  geom_point(size = 1) +  # Puntos\n  geom_smooth(method = \"lm\", se = FALSE) +  # Recta de regresión\n  labs(x = \"Edad\", y = \"Cohesión Barrial\")  # Etiquetas de ejes\n\n# Gráfico 2\ngraph2 &lt;- ggplot(proc_data, aes(x = educacion, y = cohesion_barrial)) +\n  geom_point(size = 1) +\n  geom_smooth(method = \"lm\", se = FALSE) +\n  labs(x = \"Educación\", y = \"Cohesión Barrial\")\nggarrange(graph1, graph2, nrow = 1) # Unir graficos\n\n\n\n\n\n\n\n\n\nCon el gráfico anterior podemos notar que, si bien ambas variables tienen una asociación distinta con la cohesión barrial, el tamaño efecto de esta relación es distinto. Edad tiene una asociación positiva, mientras que educación tiene una asociación negativa. El tamaño de efecto de edad es ‘grande’, mientras que el tamaño de educación es casi nulo.",
    "crumbs": [
      "Prácticos",
      "Talleres",
      "09: Práctico 8"
    ]
  },
  {
    "objectID": "practicos/08-content.html#regresiones",
    "href": "practicos/08-content.html#regresiones",
    "title": "08: Regresión lineal múltiple",
    "section": "Regresiones",
    "text": "Regresiones\nPara facilitar la interpretación de los coeficientes de regresión vamos a recodificar la variable de educación (10 categorías) en tres categorías (básica, media y universitaria).\nAdemás, nos aseguramos que las variables categóricas estén como variables categóricas con as_factor. De esta forma nos aseguramos que la estimación de los modelos sea correcta ya que no se úede interpretar educación como si fuera una variable numérica.\n\n\nCódigo\nproc_data$educacion &lt;- car::recode(proc_data$educacion, \"c(1,2,3)=1; c(4,5)=2; c(6,7,8,9,10)=3\")\n\nproc_data$educacion &lt;- set_labels(proc_data$educacion,\n            labels=c( \"Educacion básica\"=1,\n                      \"Educación media\"=2,\n                      \"Educación superior\"=3))\n\nfrq(proc_data$educacion)\n\n\nNivel educacional (x) &lt;numeric&gt; \n# total N=2927 valid N=2925 mean=2.12 sd=0.75\n\nValue |              Label |    N | Raw % | Valid % | Cum. %\n------------------------------------------------------------\n    1 |   Educacion básica |  656 | 22.41 |   22.43 |  22.43\n    2 |    Educación media | 1251 | 42.74 |   42.77 |  65.20\n    3 | Educación superior | 1018 | 34.78 |   34.80 | 100.00\n &lt;NA&gt; |               &lt;NA&gt; |    2 |  0.07 |    &lt;NA&gt; |   &lt;NA&gt;\n\n\nCódigo\nproc_data$educacion &lt;- as_factor(proc_data$educacion)\nproc_data$sexo &lt;- as_factor(proc_data$sexo)\n\nproc_data &lt;- na.omit(proc_data)\n\nreg1 &lt;- lm(cohesion_barrial ~ 1, data=proc_data)\n\nstargazer(reg1, type=\"text\")\n\n\n\n===============================================\n                        Dependent variable:    \n                    ---------------------------\n                         cohesion_barrial      \n-----------------------------------------------\nConstant                     10.336***         \n                              (0.063)          \n                                               \n-----------------------------------------------\nObservations                   2,915           \nR2                             0.000           \nAdjusted R2                    0.000           \nResidual Std. Error      3.397 (df = 2914)     \n===============================================\nNote:               *p&lt;0.1; **p&lt;0.05; ***p&lt;0.01\n\n\n¿Qué valor toma una regresión lineal cuando no incluímos predictores en nuestro modelo?\nEn este caso, lo que nos interesa observar es el intercepto. Un intercepto de 10.336 nos indica la media de la cohesión barrial.\n\nRegresión lineal simple\nUna regresión lineal simple es aquel modelo que incluye solo un predictor. En este caso construiremos tres modelos distintos con tres variables independientes, es decir, reg2 que incluye como predictor ‘edad’, reg3 incluye educación y reg4 incluye sexo.\n\nCódigo\nreg2 &lt;- lm(cohesion_barrial ~ edad, data=proc_data)\nreg3 &lt;- lm(cohesion_barrial ~ educacion, data=proc_data)\nreg4 &lt;- lm(cohesion_barrial ~ sexo, data=proc_data)\n\nknitreg(list(reg2, reg3, reg4), \n        custom.model.names = c(\"Modelo 1\",\n                               \"Modelo 2\",\n                               \"Modelo 3\"),\n        custom.note = \"*** p &lt; 0.001; ** p &lt; 0.01; * p &lt; 0.05\",\n        custom.coef.names = c(\"Intercepto\", \n                              \"Edad\",\n                              \"Educación media &lt;br&gt; &lt;i&gt;(Ref. Ed. básica)&lt;/i&gt;\", \n                              \"Educación superior\", \n                              \"Mujer &lt;br&gt; &lt;i&gt;(Ref. Hombre)&lt;/i&gt;\"),\n        caption = \"Cohesión barrial\",\n        caption.above = TRUE)\n\n\n\nCohesión barrial\n\n\n\n\n \n\n\nModelo 1\n\n\nModelo 2\n\n\nModelo 3\n\n\n\n\n\n\nIntercepto\n\n\n8.42***\n\n\n10.51***\n\n\n10.49***\n\n\n\n\n \n\n\n(0.20)\n\n\n(0.13)\n\n\n(0.10)\n\n\n\n\nEdad\n\n\n0.04***\n\n\n \n\n\n \n\n\n\n\n \n\n\n(0.00)\n\n\n \n\n\n \n\n\n\n\nEducación media  (Ref. Ed. básica)\n\n\n \n\n\n-0.13\n\n\n \n\n\n\n\n \n\n\n \n\n\n(0.16)\n\n\n \n\n\n\n\nEducación superior\n\n\n \n\n\n-0.35*\n\n\n \n\n\n\n\n \n\n\n \n\n\n(0.17)\n\n\n \n\n\n\n\nMujer  (Ref. Hombre)\n\n\n \n\n\n \n\n\n-0.26*\n\n\n\n\n \n\n\n \n\n\n \n\n\n(0.13)\n\n\n\n\nR2\n\n\n0.03\n\n\n0.00\n\n\n0.00\n\n\n\n\nAdj. R2\n\n\n0.03\n\n\n0.00\n\n\n0.00\n\n\n\n\nNum. obs.\n\n\n2915\n\n\n2915\n\n\n2915\n\n\n\n\n\n\n*** p &lt; 0.001; ** p &lt; 0.01; * p &lt; 0.05\n\n\n\n\nLa interpretación de una tabla de regresión debe seguir el orden de presentación de los modelos y el orden de los coeficientes de regresión. En este ejemplo se dará el paso a paso de cómo interpretar las tablas:\nEn el Modelo 1 se incluye edad como predictor, que tiene un coeficiente de regresión de 0,04. Esto indica que por cada unidad que aumenta edad, la cohesión barrial aumenta en promedio 0,04 unidades, efecto que podemos extrapolar a la población con un 99,9% de confianza (p&lt;0,001). El intercepto es de 8,42, lo que indica que (teóricamente) una persona con edad 0 tendría un promedio de cohesión barrial de 8,42. Finalmente, el modelo 1 logra explicar el 3% de la varianza de la variable dependiente (R2=0,03).\nEl Modelo 2 incluye la edad de los/as encuestados como variable independiente, teniendo la categoría de ‘educación básica’ como categoría de referencia. Este Modelo indica que las personas con educación media tienen en promedio -0,13 unidades en el índice de cohesión barrial que las personas con educación básica, sin embargo, este coeficiente no es estadísticamente significativo. En cuanto a las personas con educación superior, estas tendrían en promedio -0,35 unidades en la escala de cohesión barrial en comparación con las personas con educación básica, efecto que es estadísticamente significativo (p&lt;0,05). Si observamos el intercepto, este nos indica que el promedio de cohesión barrial para las personas con educación básica es de 10,51, por lo que el promedio de cohesión barrial para las personas con educación media sería de 10,38 y para las personas con educación superior sería 10,16.\nEl modelo 3 indica que las mujeres tendrían -0,26 unidades en la escala de cohesión barrial que los hombres, efecto que podemos extrapolar a la población con un 95% de confianza. El intercepto indica que el promedio de cohesión barrial de los hombres es 10,49, por lo que el promedio para las mujeres sería de 10,23.\n\n\nRegresión lineal múltiple\nUna regresión lineal múltiple es aquel modelo que incluye más de un predictor en las estimaciones. Idealmente, la inclusión de nuevas variables independientes, así como el orden de presentación de los modelos debe seguir un sentido teórico y/o acorde a las hipótesis de investigación. En este caso, y solo como ejemplo, construiremos cuatro modelos distintos que incluyen todas las combinaciones de variables posibles para ver cómo cambian los efectos según el control estadístico (parcialización)\n\nCódigo\nreg5 &lt;- lm(cohesion_barrial ~ edad + educacion, data=proc_data)\nreg6 &lt;- lm(cohesion_barrial ~ edad + sexo, data=proc_data)\nreg7 &lt;- lm(cohesion_barrial ~ educacion + sexo, data=proc_data)\nreg8 &lt;- lm(cohesion_barrial ~ edad + educacion + sexo, data=proc_data)\n\nknitreg(list(reg5, reg6, reg7, reg8), \n        custom.model.names = c(\"Modelo 1\",\n                               \"Modelo 2\",\n                               \"Modelo 3\",\n                               \"Modelo 4\"),\n        custom.note = \"*** p &lt; 0.001; ** p &lt; 0.01; * p &lt; 0.05\",\n        custom.coef.names = c(\"Intercepto\", \n                              \"Edad\",\n                              \"Educación media &lt;br&gt; &lt;i&gt;(Ref. Ed. básica)&lt;/i&gt;\", \n                              \"Educación superior\", \n                              \"Mujer &lt;br&gt; &lt;i&gt;(Ref. Hombre)&lt;/i&gt;\"),\n        caption = \"Cohesión barrial\",\n        caption.above = TRUE)\n\n\n\nCohesión barrial\n\n\n\n\n \n\n\nModelo 1\n\n\nModelo 2\n\n\nModelo 3\n\n\nModelo 4\n\n\n\n\n\n\nIntercepto\n\n\n7.99***\n\n\n8.60***\n\n\n10.71***\n\n\n8.19***\n\n\n\n\n \n\n\n(0.28)\n\n\n(0.21)\n\n\n(0.16)\n\n\n(0.29)\n\n\n\n\nEdad\n\n\n0.04***\n\n\n0.04***\n\n\n \n\n\n0.05***\n\n\n\n\n \n\n\n(0.00)\n\n\n(0.00)\n\n\n \n\n\n(0.00)\n\n\n\n\nEducación media  (Ref. Ed. básica)\n\n\n0.35*\n\n\n \n\n\n-0.16\n\n\n0.33\n\n\n\n\n \n\n\n(0.17)\n\n\n \n\n\n(0.16)\n\n\n(0.17)\n\n\n\n\nEducación superior\n\n\n0.36*\n\n\n \n\n\n-0.38*\n\n\n0.33\n\n\n\n\n \n\n\n(0.18)\n\n\n \n\n\n(0.17)\n\n\n(0.18)\n\n\n\n\nMujer  (Ref. Hombre)\n\n\n \n\n\n-0.34**\n\n\n-0.28*\n\n\n-0.33**\n\n\n\n\n \n\n\n \n\n\n(0.13)\n\n\n(0.13)\n\n\n(0.13)\n\n\n\n\nR2\n\n\n0.04\n\n\n0.04\n\n\n0.00\n\n\n0.04\n\n\n\n\nAdj. R2\n\n\n0.04\n\n\n0.04\n\n\n0.00\n\n\n0.04\n\n\n\n\nNum. obs.\n\n\n2915\n\n\n2915\n\n\n2915\n\n\n2915\n\n\n\n\n\n\n*** p &lt; 0.001; ** p &lt; 0.01; * p &lt; 0.05\n\n\n\n\nEl Modelo 1 incluye edad y educación como variables independientes. Este modelo indica que por cada unidad que aumenta la edad, la cohesión barrial aumenta en 0,04 unidades, manteniendo la educación constante, efecto que es estadísticamente significativo (p&lt;0,001). En cuanto a la educación, tener educación media (b=0,35) y tener educación superior (b=0,36) tienen un efecto positivo sobre la cohesión barrial en comparación con quienes tienen educación básica, menteniendo la edad constante, efecto que es estadísticamente significativo (p&lt;0,05).\nEn el Modelo 2 el efecto de edad se mantiene igual que en el modelo 1. Al incluir edad (y no educación) este modelo indica que las mujeres tendrían -0,34 unidades en la escala de cohesión barrial que los hombres, manteniendo la edad constante, efecto que podemos extrapolar a la población con un 99% de confianza.\nEl Modelo 3 incluye las variables educación y sexo, por lo que es interesante notar que al no controlar por edad, el efecto de la educación cambia de positivo a negativo y solo encontramos diferencias estadísticamente significativas al tener educación superior. El efecto del sexo disminuye, pero mantiene su sentido y significancia.\nEl Modelo 4 incluye todas las variables independientes. Este modelo indica que por cada unidad que aumenta la edad, la cohesión barrial aumenta en 0,05 unidades, manteniendo el resto de las variables constantes, efecto que es estadísticamente significativo (p&lt;0,001). En cuanto a la educación, tener educación media (b=0,33) y tener educación superior (b=0,33) tienen un efecto positivo sobre la cohesión barrial en comparación con quienes tienen educación básica, menteniendo el resto de las variables constantes, sin embargo, estas diferencias no son estadísticamente significativas. Finalmente, las mujeres tendrían -0,33 unidades en la escala de cohesión barrial que los hombres, manteniendo el resto de variables constantes, efecto que podemos extrapolar a la población con un 99% de confianza.\nLos modelos 1, 2 y 4 logran explicar el 4% de la varianza de la variable dependiente (R2=0,04).\n\n\nGraficar\n\n\nCódigo\nplot_model(reg8, \n            title = \"\", #quitar titulo\n            show.values = TRUE, #mostrar valor de efectos\n            dot.size = 3, #tamaño circulos\n            line.size = 1, #tamaño CI\n            value.size = 4, #tamaño valor efectoss\n            spacing = 1, #espacio entre efectos\n            vline.color = \"red\", # linea roja en punto neutro (0)\n            axis.labels = rev(c(\"Edad\",\n                              \"Educación media\", \n                              \"Educación superior\", \n                              \"Mujer\")), #con rev porque automatico los tira en otro orden\n            show.legend = FALSE) + # variables dependientes\n  theme_bw()",
    "crumbs": [
      "Prácticos",
      "Talleres",
      "09: Práctico 8"
    ]
  },
  {
    "objectID": "practicos/06-content.html#recursos-de-la-práctica",
    "href": "practicos/06-content.html#recursos-de-la-práctica",
    "title": "Práctico 6. Asociación de variables",
    "section": "Recursos de la práctica",
    "text": "Recursos de la práctica\nEn esta práctica trabajaremos con la ola 2021 Estudio Longitudinal Social de Chile (ELSOC), elaborado por COES. Para este ejercicio, obtendremos directamente esta base desde internet.\n\n\nCódigo\nload(url((\"https://github.com/cursos-metodos-facso/metod1-MCS/raw/main/resource/files/ELSOC_W05_v1.0_R.RData\")))\n\n\n\n\n\n\n\n\nNota\n\n\n\nPara importar los datos en R debemos tener en consideración tres cosas:\n\nCómo se llaman los datos (en nuestro caso ELSOC_W05_v1.0_SPSS)\nEl formato de nuestros datos (en nuestro caso .sav)\nEl lugar de donde están alojados nuestros datos",
    "crumbs": [
      "Prácticos",
      "Talleres",
      "06: Práctico 6"
    ]
  },
  {
    "objectID": "practicos/06-content.html#preparación-datos",
    "href": "practicos/06-content.html#preparación-datos",
    "title": "Práctico 6. Asociación de variables",
    "section": "Preparación datos",
    "text": "Preparación datos\nComencemos por preparar nuestros datos. Iniciamos cargando las librerías necesarias.\n\n\nCódigo\npacman::p_load(dplyr, # Manipulacion datos\n               sjmisc, # Descriptivos\n               sjPlot, # Tablas\n               sjlabelled, #etiquetas\n               kableExtra, #Tablas\n               GGally, # Correlaciones\n               corrplot) # Correlaciones\n## package 'labelled' successfully unpacked and MD5 sums checked\n## package 'broom.helpers' successfully unpacked and MD5 sums checked\n## package 'patchwork' successfully unpacked and MD5 sums checked\n## package 'ggstats' successfully unpacked and MD5 sums checked\n## package 'GGally' successfully unpacked and MD5 sums checked\n## \n## The downloaded binary packages are in\n##  C:\\Users\\kevin\\AppData\\Local\\Temp\\RtmpeWHYME\\downloaded_packages\n\noptions(scipen = 999) # para desactivar notacion cientifica\n\n\nA continuación, exploramos la base de datos elsoc_2021.\n\n\nCódigo\ndim(elsoc_2021) # Dimensiones\n\n\n[1] 2740  311\n\n\nContamos con 311 variables (columnas) y 2740 observaciones (filas).\nPara este ejemplo, vamos a utilizar dos variables numéricas (ingresos y edad) y cuatro variables categóricas (Educación, percepción de desigualdad y 2 de percepción de meritocracia).\n\n\nCódigo\nproc_elsoc &lt;- elsoc_2021 %&gt;% select(edad=m0_edad, ingreso=m13, educacion=m01, desigualdad=c18_11, esfuerzo=c18_09, inteligencia=c18_10)\n\n\nAhora, profundicemos un poco más y observemos algunos estadísticos descriptivos de resumen de nuestra base de datos. Utilizaremos la función descr del paquete sjmisc.\n\n\nCódigo\nsjmisc::descr(proc_elsoc,\n      show = c(\"label\",\"range\", \"mean\", \"sd\", \"NA.prc\", \"n\")) %&gt;%\n      kable(.,\"markdown\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nvar\nlabel\nn\nNA.prc\nmean\nsd\nrange\n\n\n\n\n2\nedad\nEdad del entrevistado\n2740\n0.00000\n49.411314\n15.12879\n66 (20-86)\n\n\n5\ningreso\nIngreso mensual entrevistado (monto)\n1641\n40.10949\n579621.962827\n616203.06223\n9000999 (-999-9000000)\n\n\n3\neducacion\nNivel educacional\n2740\n0.00000\n5.455109\n2.22973\n9 (1-10)\n\n\n1\ndesigualdad\nGrado de acuerdo: Las diferencias de ingreso son demasiado grandes\n2740\n0.00000\n-1.036496\n64.56727\n1004 (-999-5)\n\n\n4\nesfuerzo\nGrado de acuerdo: Las personas son recompensadas por sus esfuerzos\n2740\n0.00000\n-5.887591\n84.14409\n1004 (-999-5)\n\n\n6\ninteligencia\nGrado de acuerdo: Las personas son recompensada por su inteligencia\n2740\n0.00000\n-5.097810\n80.70845\n1004 (-999-5)\n\n\n\n\n\n¡ALTO! Tenemos algunos valores o casos perdidos en ciertas variables. ¿Cómo lidiar con los casos perdidos?",
    "crumbs": [
      "Prácticos",
      "Talleres",
      "06: Práctico 6"
    ]
  },
  {
    "objectID": "practicos/06-content.html#tratamiento-de-casos-perdidos",
    "href": "practicos/06-content.html#tratamiento-de-casos-perdidos",
    "title": "Práctico 6. Asociación de variables",
    "section": "Tratamiento de casos perdidos",
    "text": "Tratamiento de casos perdidos\nTrabajar con datos a menudo implica enfrentar valores perdidos (NA), lo que puede ser un gran desafío. Estos valores indican la ausencia de un valor en una base de datos. Los valores perdidos pueden originarse por diversas razones, como el sesgo de no respuesta en encuestas, errores en la entrada de datos o simplemente la falta de información para ciertas variables.\n\n\nCódigo\nfrq(proc_elsoc$esfuerzo)\n\n\nGrado de acuerdo: Las personas son recompensadas por sus esfuerzos (x) &lt;numeric&gt; \n# total N=2740 valid N=2740 mean=-5.89 sd=84.14\n\nValue |                                 Label |    N | Raw % | Valid % | Cum. %\n-------------------------------------------------------------------------------\n -999 |                 No Responde (no leer) |    4 |  0.15 |    0.15 |   0.15\n -888 |                     No Sabe (no leer) |   14 |  0.51 |    0.51 |   0.66\n -777 |       Valor perdido por error tecnico |    0 |  0.00 |    0.00 |   0.66\n -666 | Valor perdido por encuesta incompleta |   10 |  0.36 |    0.36 |   1.02\n    1 |              Totalmente en desacuerdo |  237 |  8.65 |    8.65 |   9.67\n    2 |                         En desacuerdo | 1415 | 51.64 |   51.64 |  61.31\n    3 |        Ni en desacuerdo ni de acuerdo |  422 | 15.40 |   15.40 |  76.72\n    4 |                            De acuerdo |  567 | 20.69 |   20.69 |  97.41\n    5 |                 Totalmente de acuerdo |   71 |  2.59 |    2.59 | 100.00\n &lt;NA&gt; |                                  &lt;NA&gt; |    0 |  0.00 |    &lt;NA&gt; |   &lt;NA&gt;\n\n\nCódigo\nproc_elsoc &lt;- proc_elsoc %&gt;% set_na(., na = c(-999, -888, -777, -666))\n\nfrq(proc_elsoc$esfuerzo)\n\n\nGrado de acuerdo: Las personas son recompensadas por sus esfuerzos (x) &lt;numeric&gt; \n# total N=2740 valid N=2712 mean=2.56 sd=1.00\n\nValue |                          Label |    N | Raw % | Valid % | Cum. %\n------------------------------------------------------------------------\n    1 |       Totalmente en desacuerdo |  237 |  8.65 |    8.74 |   8.74\n    2 |                  En desacuerdo | 1415 | 51.64 |   52.18 |  60.91\n    3 | Ni en desacuerdo ni de acuerdo |  422 | 15.40 |   15.56 |  76.47\n    4 |                     De acuerdo |  567 | 20.69 |   20.91 |  97.38\n    5 |          Totalmente de acuerdo |   71 |  2.59 |    2.62 | 100.00\n &lt;NA&gt; |                           &lt;NA&gt; |   28 |  1.02 |    &lt;NA&gt; |   &lt;NA&gt;\n\n\n\n\nCódigo\nfrq(proc_elsoc$educacion)\n\n\nNivel educacional (x) &lt;numeric&gt; \n# total N=2740 valid N=2740 mean=5.46 sd=2.23\n\nValue |                                       Label |   N | Raw % | Valid % | Cum. %\n------------------------------------------------------------------------------------\n    1 |                                Sin estudios |  18 |  0.66 |    0.66 |   0.66\n    2 |  Educacion Basica o Preparatoria incompleta | 280 | 10.22 |   10.22 |  10.88\n    3 |    Educacion Basica o Preparatoria completa | 243 |  8.87 |    8.87 |  19.74\n    4 |    Educacion Media o Humanidades incompleta | 354 | 12.92 |   12.92 |  32.66\n    5 |      Educacion Media o Humanidades completa | 819 | 29.89 |   29.89 |  62.55\n    6 |                 Tecnica Superior incompleta |  93 |  3.39 |    3.39 |  65.95\n    7 |                   Tecnica Superior completa | 355 | 12.96 |   12.96 |  78.91\n    8 |                    Universitaria incompleta | 167 |  6.09 |    6.09 |  85.00\n    9 |                      Universitaria completa | 360 | 13.14 |   13.14 |  98.14\n   10 | Estudios de posgrado (magister o doctorado) |  51 |  1.86 |    1.86 | 100.00\n &lt;NA&gt; |                                        &lt;NA&gt; |   0 |  0.00 |    &lt;NA&gt; |   &lt;NA&gt;\n\n\nLa presencia de valores perdidos puede tener un impacto considerable en la precisión y confiabilidad de los análisis estadísticos, lo que a su vez puede conducir a resultados sesgados y conclusiones incorrectas.\nExisten varias formas de tratar valores perdidos, que van desde enfoques simples hasta métodos más complejos, como la imputación. En esta ocasión, nos centraremos en las dos estrategias más comunes:\n\ntrabajar exclusivamente con casos completos (listwise) o\nretener los casos con valores perdidos, pero excluyéndolos al calcular estadísticas (pairwise).\n\n\na) Analísis con casos completos: listwise deletion\nEste enfoque es uno de los más conocidos: implica remover completamente las observaciones que tienen valores perdidos en cualquier variable de interés. En otras palabras, si una fila/caso en un conjunto de datos tiene al menos un valor faltante en alguna de las variables que estás considerando, se eliminará por completo.\nEn R, esto podemos hacerlo con la función na.omit. Para hacer esto, sigamos estos pasos:\n\nrespaldar la base de datos original en el espacio de trabajo (por si queremos en adelante realizar algún análisis referido a casos perdidos)-\ncontamos el número de casos con el comando dim.\ncontamos cuántos y en dónde tenemos casos perdidos.\nborramos los casos perdidos con na.omit.\ncontamos nuevamente con dim para asegurarnos que se borraron.\n\n\n\nCódigo\nproc_elsoc_original &lt;- proc_elsoc\ndim(proc_elsoc)\n\n\n[1] 2740    6\n\n\n\n\nCódigo\nsum(is.na(proc_elsoc))\n\n\n[1] 1251\n\n\n\n\nCódigo\ncolSums(is.na(proc_elsoc))\n\n\n        edad      ingreso    educacion  desigualdad     esfuerzo inteligencia \n           0         1179            0           18           28           26 \n\n\n\n\nCódigo\nproc_elsoc &lt;- na.omit(proc_elsoc)\ndim(proc_elsoc)\n\n\n[1] 1545    6\n\n\nAhora nos quedamos con 1545 observaciones sin casos perdidos.\nAunque es simple de implementar, con este enfoque podemos perder información importante, especialmente si los valores perdidos no se distribuyen aleatoriamente.\n\nSiempre hay que intentar rescatar la mayor cantidad de casos posibles. Por lo tanto, si un listwise genera más de un 10% de casos perdidos se debe detectar qué variables esta produciendo esta pérdida e intentar recuperar datos.\n\n\n\nb) Retener pero excluir: pairwise deletion\nA diferencia del anterior, este es un enfoque en el que las observaciones se utilizan para el análisis siempre que tengan datos disponibles para las variables específicas que se están analizando. En lugar de eliminar toda una fila si falta un valor, se eliminan solo los valores faltantes en las variables que se están analizando en ese momento.\nPara hacer esto en R debemos siempre verificar e indicar en nuestro código si queremos (o no) remover los NA para realizar los análisis.\n\n\nCódigo\nmean(proc_elsoc_original$esfuerzo); mean(proc_elsoc_original$edad); mean(proc_elsoc$desigualdad)\n\n\n[1] NA\n\n\n[1] 49.41131\n\n\n[1] 4.180583\n\n\nCódigo\nmean(proc_elsoc_original$esfuerzo, na.rm = TRUE); mean(proc_elsoc$edad, na.rm = TRUE); mean(proc_elsoc_original$desigualdad, na.rm = TRUE)\n\n\n[1] 2.564897\n\n\n[1] 45.09644\n\n\n[1] 4.135562\n\n\nCon ambas opciones tenemos resultados diferentes, ya que cambia la cantidad de casos analizados. La decisión final de qué método usar dependerá siempre del equipo de investigación.",
    "crumbs": [
      "Prácticos",
      "Talleres",
      "06: Práctico 6"
    ]
  },
  {
    "objectID": "practicos/04-content.html#librerías",
    "href": "practicos/04-content.html#librerías",
    "title": "Práctico 4. Visualización de variables",
    "section": "1. Librerías",
    "text": "1. Librerías\n\n\nCódigo\npacman::p_load(sjlabelled,\n               dplyr, #Manipulacion de datos\n              stargazer, #Tablas\n              sjmisc, # Tablas\n              summarytools, # Tablas\n              kableExtra, #Tablas\n              sjPlot, #Tablas y gráficos\n              corrplot, # Correlaciones\n              sessioninfo, # Información de la sesión de trabajo\n              ggplot2) # Para la mayoría de los gráficos\n\n\npackage 'svglite' successfully unpacked and MD5 sums checked\npackage 'kableExtra' successfully unpacked and MD5 sums checked\n\nThe downloaded binary packages are in\n    C:\\Users\\kevin\\AppData\\Local\\Temp\\RtmpCAvcli\\downloaded_packages\npackage 'corrplot' successfully unpacked and MD5 sums checked\n\nThe downloaded binary packages are in\n    C:\\Users\\kevin\\AppData\\Local\\Temp\\RtmpCAvcli\\downloaded_packages\npackage 'sessioninfo' successfully unpacked and MD5 sums checked\n\nThe downloaded binary packages are in\n    C:\\Users\\kevin\\AppData\\Local\\Temp\\RtmpCAvcli\\downloaded_packages",
    "crumbs": [
      "Prácticos",
      "Talleres",
      "04: Práctico 4"
    ]
  },
  {
    "objectID": "practicos/04-content.html#cargar-base-de-datos",
    "href": "practicos/04-content.html#cargar-base-de-datos",
    "title": "Práctico 4. Visualización de variables",
    "section": "2. Cargar base de datos",
    "text": "2. Cargar base de datos\nVamos a cargar la base de datos latinobarometro_proc.Rdata, que generamos durante la práctica anterior. Se puede llamar desde el directorio en que se guardó anteriormente dando la ruta completa:\n\n\nCódigo\nload(\"ruta-hacia-carpeta-local/latinobarometro_proc.RData\") #Cargar base de datos\n\n\nO también para esta práctica la podemos llamar directamente desde nuestro sitio web:\n\n\nCódigo\nload(url(\"https://github.com/Kevin-carrasco/R-data-analisis/raw/main/files/data/latinobarometro_total.RData\")) #Cargar base de datos\n\n\n\nExploración inicial general de la base de datos\n\n\n\nCódigo\nnames(proc_data) # Muestra los nombres de las variables de la base de datos\n\n\n[1] \"conf_gob\"     \"conf_cong\"    \"conf_jud\"     \"conf_partpol\" \"educacion\"   \n[6] \"sexo\"         \"edad\"         \"idenpa\"       \"conf_inst\"   \n\n\nCódigo\ndim(proc_data) # Dimensiones\n\n\n[1] 20204     9\n\n\nEn el caso de esta base, 20204 casos y 9 variables\nRecordando el contenido de cada variable preparada en la práctica anterior:\n\n[conf_gob] = Confianza en el gobierno.\n[conf_cong] = Confianza en el congreso.\n[conf_jud] = Confianza en el poder judicial.\n[conf_partpol] = Confianza en los partidos políticos.\n[conf_inst] = Indice sumativo de confianza en instituciones políticas.\n[educacion] = Nivel educacional(1 = Educacion básica, 2 = Educacion media, 3 = superior)\n[sexo] = Sexo (O = Hombre; 1 = Mujer)\n[edad] = ¿Cuáles su edad?",
    "crumbs": [
      "Prácticos",
      "Talleres",
      "04: Práctico 4"
    ]
  },
  {
    "objectID": "practicos/04-content.html#descripción-de-variables",
    "href": "practicos/04-content.html#descripción-de-variables",
    "title": "Práctico 4. Visualización de variables",
    "section": "3. Descripción de variables",
    "text": "3. Descripción de variables\nLos resultados referidos a descripción de variables se presentan en dos momentos del reporte de investigación:\n\nen la sección de metodología, cuando se presentan las variables del estudio en una tabla descriptiva de variables.\nen la sección de análisis, que en general comienza con una exploración de asociaciones entre variables, también conocido como análisis descriptivo.\n\n\n3.1 Tabla descriptiva de variables para sección metodológica\nA continuación se presentan dos opciones de generar esta tabla descriptiva de variables con distintas librerías de R.\na. Tabla descriptiva con stargazerstargazer\nLa función stargazer (de la librería del mismo nombre) permitirá mostrar los principales estadísticos descriptivos univariados de las variables: medidas de tendencia central (media), de dispersión (desviación estándar) y posición (mínimo, máximo, percentiles).\n\n\nCódigo\nstargazer(proc_data,type = \"text\")\n\n\n\n============================================\nStatistic      N     Mean   St. Dev. Min Max\n--------------------------------------------\nconf_gob     19,748  0.967   1.001    0   3 \nconf_cong    19,382  0.819   0.876    0   3 \nconf_jud     19,467  0.940   0.923    0   3 \nconf_partpol 19,653  0.603   0.798    0   3 \nedad         20,204 40.999   16.538  16  100\nidenpa       20,204 365.378 260.493  32  862\nconf_inst    18,768  3.303   2.851    0  12 \n--------------------------------------------\n\n\nAlgunas observaciones sobre esta tabla:\n\nLa opción type=\"text\" permite que podamos ver los resultados directamente en la consola, de manera bastante rudimentaria. Con otras opciones que veremos más adelante se puede estilizar para su publicación.\nUna distinción relevante a considerar cuando se describen variables es si estas son categóricas o continuas. La definición de si una variables es tratada como categórica o continua es algo que hace el/la autor/a del reporte, sin embargo hay variables nominales como sexo que claramente corresponden a categóricas, y por lo tanto no corresponde hacer un promedio entre ambas. Sin embargo, como esta variable está codificada 0 (hombre) y 1 (mujer), en este caso lo que indica el valor de la columna promedio (Mean=0.537) es la proporción de mujeres vs hombres. En otras palabras, hay un 54% de mujeres y 46% de hombres en la muestra.\n\nb. Tablas descriptivas con descr, librería sjmiscsjmisc::descr\nLa opción básica de descr es la siguiente:\n\n\nCódigo\nsjmisc::descr(proc_data)\n\n\n\n## Basic descriptive statistics\n\n          var        type                         label     n NA.prc   mean\n     conf_gob     numeric           Confianza: Gobierno 19748   2.26   0.97\n    conf_cong     numeric           Confianza: Congreso 19382   4.07   0.82\n     conf_jud     numeric     Confianza: Poder judicial 19467   3.65   0.94\n conf_partpol     numeric Confianza: Partidos politicos 19653   2.73   0.60\n    educacion categorical                     Educación 20201   0.01   1.88\n         sexo categorical                          Sexo 20204   0.00   1.52\n         edad     numeric                          Edad 20204   0.00  41.00\n       idenpa     numeric                        idenpa 20204   0.00 365.38\n    conf_inst     numeric    Confianza en instituciones 18768   7.11   3.30\n     sd   se  md trimmed        range iqr  skew\n   1.00 0.01   1    0.83      3 (0-3)   2  0.70\n   0.88 0.01   1    0.71      3 (0-3)   1  0.82\n   0.92 0.01   1    0.84      3 (0-3)   2  0.65\n   0.80 0.01   0    0.47      3 (0-3)   1  1.19\n   0.76 0.01   2    1.85      2 (1-3)   1  0.20\n   0.50 0.00   2    1.53      1 (1-2)   1 -0.09\n  16.54 0.12  39   39.90  84 (16-100)  28  0.49\n 260.49 1.83 222  343.35 830 (32-862) 421  0.56\n   2.85 0.02   3    2.99    12 (0-12)   4  0.75\n\n\nEn este caso utilizamos la forma librería::función (sjmisc::descr), ya que la función descr también existe en otras librerías y así nos aseguramos que la función utilizada es de esa librería específica.\nSeleccionamos algunas columnas específicas con información más relevante con la opción show. Además, agregamos la función kable para obtener una tabla que luego sea fácilmente publicable en distintos formatos (a profundizar en ejercicios posteriores):\n\n\nCódigo\nsjmisc::descr(proc_data,\n      show = c(\"label\",\"range\", \"mean\", \"sd\", \"NA.prc\", \"n\"))%&gt;%\n      kable(.,\"markdown\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nvar\nlabel\nn\nNA.prc\nmean\nsd\nrange\n\n\n\n\n2\nconf_gob\nConfianza: Gobierno\n19748\n2.2569788\n0.9668321\n1.0013733\n3 (0-3)\n\n\n1\nconf_cong\nConfianza: Congreso\n19382\n4.0685013\n0.8193169\n0.8761394\n3 (0-3)\n\n\n4\nconf_jud\nConfianza: Poder judicial\n19467\n3.6477925\n0.9404633\n0.9232323\n3 (0-3)\n\n\n5\nconf_partpol\nConfianza: Partidos politicos\n19653\n2.7271827\n0.6032158\n0.7975983\n3 (0-3)\n\n\n7\neducacion\nEducación\n20201\n0.0148485\n1.8826296\n0.7588656\n2 (1-3)\n\n\n9\nsexo\nSexo\n20204\n0.0000000\n1.5215304\n0.4995486\n1 (1-2)\n\n\n6\nedad\nEdad\n20204\n0.0000000\n40.9985151\n16.5383434\n84 (16-100)\n\n\n8\nidenpa\nidenpa\n20204\n0.0000000\n365.3783409\n260.4932509\n830 (32-862)\n\n\n3\nconf_inst\nConfianza en instituciones\n18768\n7.1075035\n3.3030158\n2.8506243\n12 (0-12)\n\n\n\n\n\nc. Tabla descriptiva con summarytools::dfSummarysummarytools::dfSummary\nEsta tercera opción nos ofrece una tabla aún más detallada, con gráficos para cada variable, las frecuencias para cada valor, y las etiquetas de las variables, por lo que es muy recomendable.\nSe específica de la siguiente manera:\n\n\nCódigo\nsummarytools::dfSummary(proc_data, plain.ascii = FALSE)\n\n\n### Data Frame Summary  \n#### proc_data  \n**Dimensions:** 20204 x 9  \n**Duplicates:** 2673  \n\n----------------------------------------------------------------------------------------------------------------------------------------------------------\nNo   Variable        Label                           Stats / Values               Freqs (% of Valid)   Graph                          Valid      Missing  \n---- --------------- ------------------------------- ---------------------------- -------------------- ------------------------------ ---------- ---------\n1    conf_gob\\       Confianza: Gobierno             Mean (sd) : 1 (1)\\           0 : 8138 (41.2%)\\    IIIIIIII \\                     19748\\     456\\     \n     [numeric]                                       min &lt; med &lt; max:\\            1 : 6228 (31.5%)\\    IIIIII \\                       (97.7%)    (2.3%)   \n                                                     0 &lt; 1 &lt; 3\\                   2 : 3281 (16.6%)\\    III \\                                              \n                                                     IQR (CV) : 2 (1)             3 : 2101 (10.6%)     II                                                 \n\n2    conf_cong\\      Confianza: Congreso             Mean (sd) : 0.8 (0.9)\\       0 : 8495 (43.8%)\\    IIIIIIII \\                     19382\\     822\\     \n     [numeric]                                       min &lt; med &lt; max:\\            1 : 6905 (35.6%)\\    IIIIIII \\                      (95.9%)    (4.1%)   \n                                                     0 &lt; 1 &lt; 3\\                   2 : 2971 (15.3%)\\    III \\                                              \n                                                     IQR (CV) : 1 (1.1)           3 : 1011 ( 5.2%)     I                                                  \n\n3    conf_jud\\       Confianza: Poder judicial       Mean (sd) : 0.9 (0.9)\\       0 : 7550 (38.8%)\\    IIIIIII \\                      19467\\     737\\     \n     [numeric]                                       min &lt; med &lt; max:\\            1 : 6886 (35.4%)\\    IIIIIII \\                      (96.4%)    (3.6%)   \n                                                     0 &lt; 1 &lt; 3\\                   2 : 3671 (18.9%)\\    III \\                                              \n                                                     IQR (CV) : 2 (1)             3 : 1360 ( 7.0%)     I                                                  \n\n4    conf_partpol\\   Confianza: Partidos politicos   Mean (sd) : 0.6 (0.8)\\       0 : 11097 (56.5%)\\   IIIIIIIIIII \\                  19653\\     551\\     \n     [numeric]                                       min &lt; med &lt; max:\\            1 :  5857 (29.8%)\\   IIIII \\                        (97.3%)    (2.7%)   \n                                                     0 &lt; 0 &lt; 3\\                   2 :  2099 (10.7%)\\   II \\                                               \n                                                     IQR (CV) : 1 (1.3)           3 :   600 ( 3.1%)                                                       \n\n5    educacion\\      Educación                       1\\. Educacion basica\\        7141 (35.3%)\\        IIIIIII \\                      20201\\     3\\       \n     [factor]                                        2\\. Educacion media\\         8290 (41.0%)\\        IIIIIIII \\                     (100.0%)   (0.0%)   \n                                                     3\\. Educacion superior       4770 (23.6%)         IIII                                               \n\n6    sexo\\           Sexo                            1\\. Hombre\\                  9667 (47.8%)\\        IIIIIIIII \\                    20204\\     0\\       \n     [factor]                                        2\\. Mujer                    10537 (52.2%)        IIIIIIIIII                     (100.0%)   (0.0%)   \n\n7    edad\\           Edad                            Mean (sd) : 41 (16.5)\\       81 distinct values   : : :\\                         20204\\     0\\       \n     [numeric]                                       min &lt; med &lt; max:\\                                 : : : \\ \\ .\\                   (100.0%)   (0.0%)   \n                                                     16 &lt; 39 &lt; 100\\                                    : : : : : :\\                                       \n                                                     IQR (CV) : 28 (0.4)                               : : : : : : .\\                                     \n                                                                                                       : : : : : : : .                                    \n\n8    idenpa\\                                         Mean (sd) : 365.4 (260.5)\\   18 distinct values   \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ :\\     20204\\     0\\       \n     [numeric]                                       min &lt; med &lt; max:\\                                 : : . \\ \\ \\ \\ \\ \\ :\\           (100.0%)   (0.0%)   \n                                                     32 &lt; 222 &lt; 862\\                                   : : : . \\ \\ \\ \\ : \\ \\ \\ \\ .\\                       \n                                                     IQR (CV) : 421 (0.7)                              : : : : \\ \\ . : \\ \\ \\ \\ :\\                         \n                                                                                                       : : : : \\ \\ : : \\ \\ \\ \\ :                          \n\n9    conf_inst\\      Confianza en instituciones      Mean (sd) : 3.3 (2.9)\\       13 distinct values   :\\                             18768\\     1436\\    \n     [numeric]                                       min &lt; med &lt; max:\\                                 :\\                             (92.9%)    (7.1%)   \n                                                     0 &lt; 3 &lt; 12\\                                       : \\ \\ \\ \\ .\\                                       \n                                                     IQR (CV) : 4 (0.9)                                : . : : :\\                                         \n                                                                                                       : : : : : . . . \\ \\ .                              \n----------------------------------------------------------------------------------------------------------------------------------------------------------\n\n\nEs muy ancha para visualizar bien en la consola de R, pero en su versión más definitiva de publicación se verá así:\n\n\nCódigo\nview(dfSummary(proc_data, headings=FALSE))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNo\nVariable\nLabel\nStats / Values\nFreqs (% of Valid)\nGraph\nValid\nMissing\n\n\n\n\n1\nconf_gob [numeric]\nConfianza: Gobierno\n\n\n\nMean (sd) : 1 (1)\n\n\nmin ≤ med ≤ max:\n\n\n0 ≤ 1 ≤ 3\n\n\nIQR (CV) : 2 (1)\n\n\n\n\n\n\n0\n:\n8138\n(\n41.2%\n)\n\n\n1\n:\n6228\n(\n31.5%\n)\n\n\n2\n:\n3281\n(\n16.6%\n)\n\n\n3\n:\n2101\n(\n10.6%\n)\n\n\n\n\n19748 (97.7%)\n456 (2.3%)\n\n\n2\nconf_cong [numeric]\nConfianza: Congreso\n\n\n\nMean (sd) : 0.8 (0.9)\n\n\nmin ≤ med ≤ max:\n\n\n0 ≤ 1 ≤ 3\n\n\nIQR (CV) : 1 (1.1)\n\n\n\n\n\n\n0\n:\n8495\n(\n43.8%\n)\n\n\n1\n:\n6905\n(\n35.6%\n)\n\n\n2\n:\n2971\n(\n15.3%\n)\n\n\n3\n:\n1011\n(\n5.2%\n)\n\n\n\n\n19382 (95.9%)\n822 (4.1%)\n\n\n3\nconf_jud [numeric]\nConfianza: Poder judicial\n\n\n\nMean (sd) : 0.9 (0.9)\n\n\nmin ≤ med ≤ max:\n\n\n0 ≤ 1 ≤ 3\n\n\nIQR (CV) : 2 (1)\n\n\n\n\n\n\n0\n:\n7550\n(\n38.8%\n)\n\n\n1\n:\n6886\n(\n35.4%\n)\n\n\n2\n:\n3671\n(\n18.9%\n)\n\n\n3\n:\n1360\n(\n7.0%\n)\n\n\n\n\n19467 (96.4%)\n737 (3.6%)\n\n\n4\nconf_partpol [numeric]\nConfianza: Partidos politicos\n\n\n\nMean (sd) : 0.6 (0.8)\n\n\nmin ≤ med ≤ max:\n\n\n0 ≤ 0 ≤ 3\n\n\nIQR (CV) : 1 (1.3)\n\n\n\n\n\n\n0\n:\n11097\n(\n56.5%\n)\n\n\n1\n:\n5857\n(\n29.8%\n)\n\n\n2\n:\n2099\n(\n10.7%\n)\n\n\n3\n:\n600\n(\n3.1%\n)\n\n\n\n\n19653 (97.3%)\n551 (2.7%)\n\n\n5\neducacion [factor]\nEducación\n\n\n\n1. Educacion basica\n\n\n2. Educacion media\n\n\n3. Educacion superior\n\n\n\n\n\n\n7141\n(\n35.3%\n)\n\n\n8290\n(\n41.0%\n)\n\n\n4770\n(\n23.6%\n)\n\n\n\n\n20201 (100.0%)\n3 (0.0%)\n\n\n6\nsexo [factor]\nSexo\n\n\n\n1. Hombre\n\n\n2. Mujer\n\n\n\n\n\n\n9667\n(\n47.8%\n)\n\n\n10537\n(\n52.2%\n)\n\n\n\n\n20204 (100.0%)\n0 (0.0%)\n\n\n7\nedad [numeric]\nEdad\n\n\n\nMean (sd) : 41 (16.5)\n\n\nmin ≤ med ≤ max:\n\n\n16 ≤ 39 ≤ 100\n\n\nIQR (CV) : 28 (0.4)\n\n\n\n81 distinct values\n\n20204 (100.0%)\n0 (0.0%)\n\n\n8\nidenpa [numeric]\n\n\n\n\nMean (sd) : 365.4 (260.5)\n\n\nmin ≤ med ≤ max:\n\n\n32 ≤ 222 ≤ 862\n\n\nIQR (CV) : 421 (0.7)\n\n\n\n18 distinct values\n\n20204 (100.0%)\n0 (0.0%)\n\n\n9\nconf_inst [numeric]\nConfianza en instituciones\n\n\n\nMean (sd) : 3.3 (2.9)\n\n\nmin ≤ med ≤ max:\n\n\n0 ≤ 3 ≤ 12\n\n\nIQR (CV) : 4 (0.9)\n\n\n\n13 distinct values\n\n18768 (92.9%)\n1436 (7.1%)\n\n\n\n\nGenerated by summarytools 1.0.1 (R version 4.4.0)2024-05-15\n\n\n\n\n\nNota sobre casos perdidos (NAs) na.omit(data)\nHasta ahora hemos mantenido los casos perdidos en la base de datos, ya que son importantes de reportar en la tabla general de variables. Sin embargo, de aquí en adelante se recomienda trabajar solo con casos completos, es decir, sacar los casos perdidos. El quitar los casos perdidos de una base de datos es muy simple con la función na.omit, pero para tomar precauciones y asegurarse que funciona se recomienda el siguiente procedimiento:\n\nrespaldar la base de datos original en el espacio de trabajo (por si queremos en adelante realizar algún análisis referido a casos perdidos), la dejaremos con el nombre proc_data_original.\ncontamos el número de casos con el comando dim\ncontamos el número de casos perdidos con sum(is.na(proc_data))\nborramos los casos perdidos con proc_data &lt;-na.omit(proc_data)\ncontamos nuevamente con dim para asegurarnos que se borraron\ny por temas de funcionamiento de R, al realizar la operación de sacar casos perdidos, se borra toda la información de las etiquetas (labels), así que las recuperamos de la base original con el comando copy_labels, de la librería sjlabelled.\n\n\n\nCódigo\nproc_data_original &lt;-proc_data\ndim(proc_data)\n\n\n[1] 20204     9\n\n\nCódigo\nsum(is.na(proc_data))\n\n\n[1] 4005\n\n\nCódigo\nproc_data &lt;-na.omit(proc_data)\ndim(proc_data)\n\n\n[1] 18765     9\n\n\nCódigo\nproc_data &lt;-sjlabelled::copy_labels(proc_data,proc_data_original)\n\n\n\n\n\n3.2 Visualización de variables\nPara visualizar variables mediante gráficos, en R el paquete más comúnmente usado es ggplot2. La lógica detrás de este paquete es que funciona por capas.\n\n\nCódigo\nggplot()\n\n\n\n\n\n\n\n\n\n\n\nCódigo\nggplot(proc_data, aes(x = conf_inst))\n\n\n\n\n\n\n\n\n\n\n\nCódigo\nproc_data %&gt;% ggplot(aes(x = conf_inst)) + \n  geom_bar()\n\n\n\n\n\n\n\n\n\n\n\nCódigo\nproc_data %&gt;% ggplot(aes(x = conf_inst)) + \n  geom_bar(fill = \"coral\")\n\n\n\n\n\n\n\n\n\n\n\nCódigo\nproc_data %&gt;% ggplot(aes(x = conf_inst)) + \n  geom_bar(fill = \"coral\")+\n  labs(title = \"Confianza en instituciones\",\n       x = \"Confianza en instituciones\",\n       y = \"Frecuencia\")\n\n\n\n\n\n\n\n\n\n\n\nCódigo\n# Crear el gráfico usando ggplot2\ngraph1 &lt;- proc_data %&gt;% ggplot(aes(x = conf_inst)) + \n  geom_bar(fill = \"coral\")+\n  labs(title = \"Confianza en instituciones\",\n       x = \"Confianza en instituciones\",\n       y = \"Frecuencia\") +\n  theme_bw()\n\ngraph1\n\n\n\n\n\n\n\n\n\nCódigo\n# y lo podemos guardar:\n\nggsave(graph1, file=\"files/img/graph1.png\")\n\n\nSaving 7 x 5 in image\n\n\n\n\n3.3 Exploración de asociación entre variables\nDado que las hipótesis de investigación corresponden a asociación entre variables, antes de realizar el contraste de hipótesis se suele presentar un análisis descriptivo que explora las asociaciones entre variables.\nLa forma de explorar las asociaciones entre variables dependen de la naturaleza de las variables que se asocian:\n\nVariables categóricas: tabla de contingencia\nVariable categórica y continua: tabla de promedios por cada categoría\n\nEn esta sección también es muy relevante la visualización de datos mediante gráficos, por lo que incluiremos algunos.\nEl uso tanto de tablas como de gráficos en el reporte queda a discreción del/a autor/a. La pregunta que orienta esta decisión es: ¿Me permite enriquecer la discusión de los resultados en relación a las hipótesis planteadas?\n\nTablas de contingencia para variables categóricas\nPara tablas de contingencia categóricas utilizaremos la función sjt.xtab, de la librería sjPlot. Veamos primero una especificación simple: sjPlot::sjt.xtab\n\n\nCódigo\nsjt.xtab(proc_data$educacion, proc_data$sexo)\n\n\n\n \n Educación\n Sexo\n Total\n \n \n\n Hombre\n Mujer\n \n \n \nEducacion basica\n3027\n3216\n6243 \n\n \n \nEducacion media\n3845\n4041\n7886 \n\n \n \nEducacion superior\n2252\n2384\n4636 \n\n \n \nTotal\n9124\n9641\n18765 \n\nχ2=0.108 · df=2 · Cramer's V=0.002 · p=0.948 \n\n \n\n\n\nAl ejecutar el comando, el resultado aparece automáticamente en el visor de RStudio. A esta tabla podemos también agregar porcentajes de filas y/o columnas, según sea lo más relevante analizar. En general se recomienda agregar solo un porcentaje, de otra manera la tabla se satura de información. Además, vamos a quitar el pie de la tabla (conviene dejarlo solo si hay hipótesis asociadas al cruce simple entre las dos variables).\n\n\nCódigo\nsjt.xtab(proc_data$educacion, proc_data$sexo,\n        show.col.prc=TRUE,\n        show.summary=FALSE,\n        encoding = \"UTF-8\"\n)\n\n\n\n\n\n\n\n\n\n\n\n\nEducación\nSexo\nTotal\n\n\nHombre\nMujer\n\n\nEducacion basica\n3027\n33.2 %\n3216\n33.4 %\n6243\n33.3 %\n\n\nEducacion media\n3845\n42.1 %\n4041\n41.9 %\n7886\n42 %\n\n\nEducacion superior\n2252\n24.7 %\n2384\n24.7 %\n4636\n24.7 %\n\n\nTotal\n9124\n100 %\n9641\n100 %\n18765\n100 %\n\n\n\n\n\n\n\n\nTablas de promedio de variable continua por una categóricas\nEn ejemplo vamos a explorar datos de nuestra variable de confianza en instituciones conf_inst por los niveles educacionales educacion.\nUna forma rápida de explorar esto es mediante la función tapply, que nos entrega de manera simple el promedio de una variable por otra:\n\n\nCódigo\ntapply(proc_data$conf_inst, proc_data$educacion, mean)\n\n\n  Educacion basica    Educacion media Educacion superior \n          3.396604           3.229647           3.303063 \n\n\nAquí vemos en promedio de conf_inst para cada uno de los 3 niveles de la variable educación educacion. Si se estima conveniente este tipo de cruces se puede representar también en una tabla con más opciones de información y también de publicación. Para esto utilizaremos una función algo más compleja de la librería dplyr.dplyr Esta librería permite aplicar una serie de funciones concatenadas y enlazadas mediante el operador %&gt;%. El sentido de cada función aparece comentado abajo:\n\n\nCódigo\nproc_data %&gt;% # se especifica la base de datos\n  select(conf_inst,educacion) %&gt;% # se seleccionan las variables\n  dplyr::group_by(Educación=sjlabelled::as_label(educacion)) %&gt;% # se agrupan por la variable categórica y se usan sus etiquetas con as_label\n  dplyr::summarise(Obs.=n(),Promedio=mean(conf_inst),SD=sd(conf_inst)) %&gt;% # se agregan las operaciones a presentar en la tabla\n  kable(., format = \"markdown\") # se genera la tabla\n\n\n\n\n\nEducación\nObs.\nPromedio\nSD\n\n\n\n\nEducacion basica\n6243\n3.396604\n3.038681\n\n\nEducacion media\n7886\n3.229648\n2.751494\n\n\nEducacion superior\n4636\n3.303063\n2.749961\n\n\n\n\n\nEsta asociación también se puede representar de manera más simple con un gráfico, en este caso de cajas o boxplot mediante la función geom_boxplot de gplot2:\n\n\nCódigo\ngraph &lt;- ggplot(proc_data, aes(x =educacion, y = conf_inst)) +\n  geom_boxplot() +\n  labs(x = \"Educación\", y = \"Confianza en instituciones\") +\n  theme_minimal()\n\ngraph\n\n\n\n\n\n\n\n\n\nCódigo\n# y lo podemos guardar:\n\nggsave(graph, file=\"files/img/graph.png\")\n\n\nSaving 7 x 5 in image\n\n\nSin embargo, al ser los promedios similares no permite ver demasiadas diferencias… Probemos otro\n\n\nCódigo\nggplot(proc_data, aes(x =educacion, y = conf_inst)) +\n  geom_point() +\n  labs(x = \"Educación\", y = \"Confianza en instituciones\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\nEn este gráfico cada punto representa una observación para cada categoría. Por lo tanto, al existir tantos valores difernetes en cada categoría, el gráfico tampoco nos presenta información sustantiva ¿Qué necesitamos hacer? Necesitamos obtener exactamente los datos que queremos graficar, esto es, el promedio por cada categoría. Volvamos a group_by\n\n\nCódigo\ndatos &lt;- proc_data %&gt;% group_by(educacion) %&gt;% \n  summarise(promedio = mean(conf_inst))\n\nggplot(datos, aes(x =educacion, y = promedio)) +\n  geom_point() +\n  labs(x = \"Educación\", y = \"Confianza en instituciones\") +\n  theme_minimal()+\n  ylim(0, 12)\n\n\n\n\n\n\n\n\n\nEste gráfico entrega un poco más de información, pero al ver pocas diferencias en el promedio de cada categoría no se logran evidenciar\n\n\nCódigo\nproc_data$idenpa &lt;- factor(proc_data$idenpa,\n            labels=c(\"Argentina\",\n         \"Bolivia\",\n         \"Brasil\",\n         \"Chile\",\n         \"Colombia\",\n         \"Costa Rica\",\n         \"Cuba\",\n         \"República Dominicana\",\n         \"Ecuador\",\n         \"El Salvador\",\n         \"Guatemala\",\n         \"Honduras\",\n         \"México\",\n         \"Nicaragua\",\n         \"Panamá\",\n         \"Paraguay\",\n         \"Uruguay\",\n         \"Venezuela\"),\n            levels=c(\"32\",\n         \"68\",\n         \"76\",\n         \"152\",\n         \"170\",\n         \"188\",\n         \"214\",\n         \"218\",\n         \"222\",\n         \"320\",\n         \"340\",\n         \"484\",\n         \"558\",\n         \"591\",\n         \"600\",\n         \"604\",\n         \"858\",\n         \"862\"))\n\n\ngraph_box &lt;- ggplot(proc_data, aes(x = idenpa, y = conf_inst)) +\n  geom_boxplot() +\n  labs(x = \"País\", y = \"Confianza en instituciones\") +\n  theme_minimal()+\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))  # Rotar las etiquetas del eje x\n\ngraph_box\n\n\n\n\n\n\n\n\n\nCódigo\n# y lo podemos guardar:\n\nggsave(graph_box, file=\"files/img/graph.png\")\n\n\nSaving 7 x 5 in image\n\n\nDe manera alternativa, podemos seguir explorando nuestros datos con otros gráficos\nPara varias variables univariadas, tipo escala likert, una buena alternativa es el paquete sjPlot, en este caso la función plot_stackfrq:\n\n\nCódigo\ngraph2 &lt;- sjPlot::plot_stackfrq(dplyr::select(proc_data, conf_gob,\n                                 conf_cong,\n                                 conf_jud,\n                                 conf_partpol),\n                                 title = \"Confianza en instituciones políticas\") +\n  theme(legend.position=\"bottom\")\n\ngraph2\n\n\n\n\n\n\n\n\n\nCódigo\n# Guardamos\n\nggsave(graph2, file=\"files/img/graph2.png\")\n\n\nSaving 7 x 5 in image\n\n\nPara asociación de dos variables, retomemos el primer gráfico:\n\n\nCódigo\ngraph3 &lt;- proc_data %&gt;% ggplot(aes(x = conf_inst, fill = sexo)) + \n  geom_bar() +\n  xlab(\"Confianza en instituciones\") +\n  ylab(\"Cantidad\") + \n  labs(fill=\"Sexo\")+\n  scale_fill_discrete(labels = c('Hombre','Mujer'))\n\ngraph3\n\n\n\n\n\n\n\n\n\nCódigo\n# Guardamos\n\nggsave(graph3, file=\"files/img/graph3.png\")\n\n\nSaving 7 x 5 in image\n\n\nuna forma alternativa:\n\n\nCódigo\nproc_data %&gt;% ggplot(aes(x = conf_inst)) + \n  geom_bar() +\n  xlab(\"Confianza en instituciones\") +\n  ylab(\"Cantidad\")+\n  facet_wrap(~sexo)\n\n\n\n\n\n\n\n\n\nPara variables continuas\n\n\nCódigo\ngraph4 &lt;- ggplot(proc_data, aes(x = as.numeric(edad))) +\n  geom_histogram(binwidth=0.6, colour=\"black\", fill=\"yellow\") +\n  theme_bw() +\n  xlab(\"Edad\") +\n  ylab(\"Cantidad\")\n\ngraph4 \n\n\n\n\n\n\n\n\n\nCódigo\n# Guardamos\n\nggsave(graph4, file=\"files/img/graph4.png\")\n\n\nSaving 7 x 5 in image\n\n\ny lo podemos complicar un poco más…\n\n\n\nAsociación entre tres variables\ncon facet_wrap dividimos el gráfico en distintos paneles, según la cantidad de categorías que tenga una variable\n\n\nCódigo\ndatos &lt;- proc_data %&gt;% group_by(educacion, sexo) %&gt;% \n  summarise(promedio = mean(conf_inst))\n\n\n`summarise()` has grouped output by 'educacion'. You can override using the\n`.groups` argument.\n\n\nCódigo\nggplot(datos, aes(x =educacion, y = promedio)) +\n  geom_point() +\n  labs(x = \"Educación\", y = \"Confianza en instituciones\") +\n  theme_bw()+\n  ylim(0, 12)+\n  facet_wrap(~sexo)\n\n\n\n\n\n\n\n\n\no alternativamente…\n\n\nCódigo\nggplot(datos, aes(x =sexo, y = promedio)) +\n  geom_point() +\n  labs(x = \"Sexo\", y = \"Confianza en instituciones\") +\n  theme_bw()+\n  ylim(0, 12)+\n  facet_wrap(~educacion)\n\n\n\n\n\n\n\n\n\nProbemos otras agrupaciones. Por ejemplo, categorizar edad en grupos para estimar promedios grupales. Una función clave para lograr esto puede ser case_when de dplyr, combinándolo con mutate. Es decir, crear una nueva variable a partir de un condicional\n\n\nCódigo\nsummary(proc_data$edad)\n\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  16.00   26.00   38.00   40.53   53.00  100.00 \n\n\nCódigo\nproc_data &lt;- proc_data %&gt;% \n  mutate(edad_groups = case_when(edad &gt;=16 & edad&lt;=25 ~ \"Entre 16 y 25 años\",\n                                 edad &gt;=26 & edad&lt;=39 ~ \"Entre 26 y 39 años\",\n                                 edad &gt;=40 & edad&lt;=65 ~ \"Entre 40 y 65 años\",\n                                 edad &gt;65 ~ \"Más de 65 años\"))\n\ntable(proc_data$edad_groups)\n\n\n\nEntre 16 y 25 años Entre 26 y 39 años Entre 40 y 65 años     Más de 65 años \n              4304               5487               7390               1584 \n\n\nAhora creamos este gráfico\n\n\nCódigo\ndatos &lt;- proc_data %&gt;% group_by(educacion, edad_groups) %&gt;% \n  summarise(promedio = mean(conf_inst))\n\n\n`summarise()` has grouped output by 'educacion'. You can override using the\n`.groups` argument.\n\n\nCódigo\nggplot(datos, aes(x =educacion, y = promedio)) +\n  geom_point() +\n  labs(x = \"Educación\", y = \"Confianza en instituciones\") +\n  theme_bw()+\n  ylim(0, 7)+\n  facet_wrap(~edad_groups)\n\n\n\n\n\n\n\n\n\ny lo podemos seguir complicando, por ejemplo, agregando otra variable en el gráfico\n\n\nCódigo\ndatos &lt;- proc_data %&gt;% group_by(educacion, sexo, edad_groups) %&gt;% \n  summarise(promedio = mean(conf_inst))\n\n\n`summarise()` has grouped output by 'educacion', 'sexo'. You can override using\nthe `.groups` argument.\n\n\nCódigo\nggplot(datos, aes(x =educacion, y = promedio, color=sexo)) +\n  geom_point() +\n  labs(x = \"Educación\", y = \"Confianza en instituciones\") +\n  theme_bw()+\n  ylim(0, 7)+\n  facet_wrap(~edad_groups)\n\n\n\n\n\n\n\n\n\nCon ‘color’ (gráfico anterior) solo se diferencia la variable según color. Con ‘shape’ (gráfico siguiente) también se diferencia según la forma de la representación\n\n\nCódigo\nggplot(datos, aes(x =educacion, y = promedio, color=sexo, shape=sexo)) +\n  geom_point() +\n  labs(x = \"Educación\", y = \"Confianza en instituciones\") +\n  theme_bw()+\n  ylim(0, 7)+\n  facet_wrap(~edad_groups)\n\n\n\n\n\n\n\n\n\nY tenemos aún un problema… las categorías del eje x se están solapando. Eso lo podemos corregir modificando el ángulo del eje x.\n\n\nCódigo\nggplot(datos, aes(x = educacion, y = promedio, color = sexo, shape = sexo)) +\n  geom_point() +\n  labs(x = \"Educación\", y = \"Confianza en instituciones\") +\n  theme_bw() +\n  ylim(0, 7) +\n  facet_wrap(~edad_groups) +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))",
    "crumbs": [
      "Prácticos",
      "Talleres",
      "04: Práctico 4"
    ]
  },
  {
    "objectID": "practicos/04-content.html#unir-bases-de-datos",
    "href": "practicos/04-content.html#unir-bases-de-datos",
    "title": "Práctico 4. Visualización de variables",
    "section": "Unir bases de datos",
    "text": "Unir bases de datos\nUna de las grandes ventajas del uso de sofwares para el análisis de datos es poder utilizar distintas fuentes de datos y combinarlas en una sola base de datos que nos permita potenciar y profundizar nuestros análisis. Por ejemplo, si utilizamos la base de datos del Latinobarómetro, que incluye datos de 18 países de latinoamérica, podemos combinar esta base enfocada en preguntas de percepciones, creencias y actitudes sociopolíticas con datos administrativos de cada país.\nEn este ejemplo, vincularemos la base del Latinobarómetro con la World Values Survey, una encuesta internacional que incluye datos para 86 países de todo el mundo. Sin embargo, debido a la gran envergadura de esta base de datos, no contamos con datos para los 18 países del latinobarómetro. Vamos verificando paso a paso lo que podemos hacer.\n\nRetomando desde el comienzo\nCargamos ambas bases de datos desde internet\n\n\nCódigo\nload(url(\"https://github.com/Kevin-carrasco/R-data-analisis/raw/main/files/data/latinobarometro_total.RData\")) #Cargar base de datos\nload(url(\"https://github.com/Kevin-carrasco/R-data-analisis/raw/main/files/data/data_wvs.RData\")) #Cargar base de datos\n\n\nPara trabajar con ambas bases, agruparemos las variables de interés por país, por lo que ya no trabajaremos directamente con individuos.\n\n\nCódigo\ncontext_data &lt;- wvs %&gt;% group_by(B_COUNTRY) %&gt;% # Agrupar por país\n  summarise(gdp = mean(GDPpercap1, na.rm = TRUE), # Promedio de GDP per capita\n         life_exp = mean(lifeexpect, na.rm = TRUE), # Promedio esperanza de vida\n         gini = mean(giniWB, na.rm = TRUE)) %&gt;%  # Promedio gini\n  rename(idenpa=B_COUNTRY) # Para poder vincular ambas bases, es necesario que la variable de identificación se llamen igual\ncontext_data$idenpa &lt;- as.numeric(context_data$idenpa) # Como era categórica, la dejamos numérica\n\nproc_data &lt;- proc_data %&gt;% group_by(idenpa) %&gt;%  # agrupamos por país\n  summarise(promedio = mean(conf_inst, na.rm = TRUE)) # promedio de confianza en instituciones por país\n\n\nPara vincular nuestras bases de datos existen múltiples opciones, la primera es ‘merge’ de R base y las siguinetes tres vienen desde dplyr: ‘right_join’, ‘full_join’ y ‘left_join’. Cada una tiene sus propias potencialidades y limitaciones y dependerá de cada caso cuál usemos\n\n\nProbemos merge\n\n\nCódigo\ndata &lt;- merge(proc_data, context_data, by=\"idenpa\")\n\n\ndata tiene 12 observaciones y 5 variables. En el fondo lo que hace es vincular solo aquellos casos que tienen datos disponibles para ambas bases originales\n\n\nCódigo\ndata1 &lt;- right_join(proc_data, context_data, by=\"idenpa\")\n\n\ndata1 tiene 64 observaciones y 5 variables. Esta función lo que hace es mantener todos los valores de la base de la ‘derecha’ (los 64 originales) y añadir los de la ‘izquierda’ con la identificación que corresponde. Para el resto de países que no tienen valores en la base del latinobarómetro, los agrega como NA\n\n\nCódigo\ndata2 &lt;- left_join(proc_data, context_data, by=\"idenpa\")\n\n\ndata2 tiene 18 observaciones y 5 variables. Esta función es el proceso inverso de right_join. Mantiene todos los valores de la base de la ‘izquierda’ y los vincula con los de la ‘derecha’ cuando corresponde. Para el resto de países de latinobarómetro que no tienen casos en WVS, los deja como NA en las nuevas varaibles\n\n\nCódigo\ndata3 &lt;- full_join(proc_data, context_data, by=\"idenpa\")\n\n\nFinalmente data3 tiene 70 observaciones y 5 variables. Esta función junta todo lo que pueda, es decir, mantiene todos los casos de latinobarómetro y de WVS, por eso si nos fijamos en el país que tiene por código 909, esta función lo mantiene aunque no tenga valores en latinobarómetro ni en WVS.\n¿Cuál es la mejor opción para este caso?\nVamos a quedarnos con la función original de R base ‘merge’ ya que para poder visualizar y representar resultados en un gráfico, en este ejemplo solo nos interesa mostrar aquellos casos completos.\n\n\nCódigo\ndata &lt;- data %&gt;%\n  mutate(idenpa = as.character(idenpa)) %&gt;%\n  mutate(idenpa = case_when(\n    idenpa == \"32\" ~ \"Argentina\",\n    idenpa == \"68\" ~ \"Bolivia\",\n    idenpa == \"76\" ~ \"Brasil\",\n    idenpa == \"152\" ~ \"Chile\",\n    idenpa == \"170\" ~ \"Colombia\",\n    idenpa == \"188\" ~ \"Costa Rica\",\n    idenpa == \"214\" ~ \"Cuba\",\n    idenpa == \"218\" ~ \"República Dominicana\",\n    idenpa == \"222\" ~ \"Ecuador\",\n    idenpa == \"320\" ~ \"El Salvador\",\n    idenpa == \"340\" ~ \"Guatemala\",\n    idenpa == \"484\" ~ \"Honduras\",\n    idenpa == \"558\" ~ \"México\",\n    idenpa == \"591\" ~ \"Nicaragua\",\n    idenpa == \"600\" ~ \"Panamá\",\n    idenpa == \"604\" ~ \"Paraguay\",\n    idenpa == \"858\" ~ \"Uruguay\",\n    idenpa == \"862\" ~ \"Venezuela\"))\ndata$gdp &lt;- as.numeric(data$gdp)\ndata$gdp[data$gdp==0] &lt;- NA\ndata &lt;- na.omit(data)\n\n\n\n\nCódigo\ndata %&gt;%\n  ggplot(aes(x = gdp, y = promedio, label = idenpa)) +\n  geom_point() +\n  geom_text(vjust = -0.5) +\n  labs(x = \"GDP\", y = \"Promedio\") +\n  theme_bw()",
    "crumbs": [
      "Prácticos",
      "Talleres",
      "04: Práctico 4"
    ]
  },
  {
    "objectID": "practicos/02-content.html",
    "href": "practicos/02-content.html",
    "title": "Práctico R 2. Vinculación R y Zotero",
    "section": "",
    "text": "Acceder a la página de zotero\n\nVamos a Log in\n\n\nY creamos una cuenta gratis\n\n\n\nFinalmente volvemos al inicio y descargamos el programa:\n\n\n\n\n\nZotero es un gestor bibliográfico que nos permite almacenar referencias bibliográficas.\n\nEs posible crear distintas bibliotecas personales (esquina superior izquierda) o grupales (abajo). Se recomienda separar las bibliotecas por temas o proyectos\nAl visualizar una referencia bibliográfica nos muestra todos los metadatos: Título, autores, nombre de la revista, año de publicación, DOI, ISBN de la revista, número de páginas, etc.\nEl dato central que nos va a servir en esta parte del proceso es el DOI\n\n\n\n\n\n\n\nNota\n\n\n\nDOI: Digital Object Identifier (Identificador de objetos digitales)\nEl DOI consiste en un código alfanumérico que identifica en la web un artículo y que lo recupera incluso si éste se ubica en un servidor distinto al que fue alojado en un principio. Se evita así el típico problema de los enlaces rotos, muy habitual en macrowebs como las universitarias.\n\n\n\n\nPara crear una biblioteca en zotero vamos a Archivo -&gt; Nueva colección y le ponemos un nombre que no tenga tíldes, ñ o espacios\n\n\nEn este caso mi biblioteca se llama “percepcion-desigualdad”.\n\nZotero tiene dos funciones para agregar referencias botón verde “Nuevo elemento” o varita mágica “añadir elemento por identificador”. Esta vez vamos por la segunda opción\nBuscamos un paper que nos interese: en este caso busqué el paper The paradox of inequality: income inequality and belief in meritocracy go hand in hand de Jonathan Mijs (2021). Su DOI es https://doi.org/10.1093/ser/mwy051\nUsamos la función Añadir elemento por identificador para agregar nuestra referencia a zotero\n\n\n¿Cuál es la forma más eficiente de buscar bibliografía sobre un mismo tema?\n\n\n\n\nResearch Rabbit es una plataforma que a partir de un paper busca otros similares, cruzando referencias y autores. Además, tiene una ventaja: Se vincula con Zotero\n\nIngresar a la página https://researchrabbitapp.com/.\nCrear cuenta\n\n\n\nUna vez dentro apretamos “Import Zotero Collection” y seleccionamos nuestra biblioteca\n\n\n\nAsí se ve research rabbit\n\n\n\nPodemos revisar el abstract de algún paper y, si nos interesa, lo agregamos a nuestra biblioteca\n\n\n\nDespués volvemos a Zotero, actualizamos y aparece nuestro nuevo paper\n\n\nAhora solo nos interesa lograr una cosa más: vincular nuestra biblioteca de Zotero con R\n\nVamos a este link y descargamos zotero-better-bibtex-6.7.169.xpi\nVolvemos a Zotero –&gt; Herramientas –&gt; Complementos –&gt; La tuerca en la esquina superior derecha –&gt; Instalar Add-on desde archivo –&gt; Seleccionamos el archivo que acabamos de descargar\n\n\n\nPaso final: exportamos nuestra biblioteca. Click derecho en nuestra biblioteca –&gt; Exportar colección\n\n\n\nSeleccionamos formato: Better BibTeX y marcamos la casilla “Keep updated”. Esto último actualizará el archivo automáticamente cuando agreguemos nueva bibliografía\n\n\n\nGuardamos nuestro archivo .bib en la misma carpeta de nuestro proyecto de trabajo\n\n\n\n\nLa escritura en Quarto tiene algunos códigos o funciones, aquí un resumen de su mayoría:\n\n\n\nCódigo\nAsí se ve\n\n\n\n\nAlgo de texto en el párrafo.\n\nMás texto\nespacio entre lineas.\nAlgo de texto.\nAlgo de texto en el párrafo. Siempre utilizando espacios para dividir párrafos\n\n\n`*Cursivas*`\nCursivas\n\n\n`**Negrita**`\nNegrita\n\n\n# Título 1\n\n\n\n## Título 2\n\n\n\n### Título 3\n\n\n\n(puedes llegar hasta un título N° 6 con ######)\n\n\n\n`[Texto enlace](https://quarto.org/)`\nTexto enlace\n\n\n`![Texto imagen](/path/to/image.png)`\n\n\n\nTexto imagen\n\n\n\n\n&gt; Citas\n\nCitas\n\n\n\n1. Una\n2. lista\n3 ordenada\n\nUna\nlista\nordenada\n\n\n\n- Otro\n- tipo\n- de lista\n\nOtro\ntipo\nde lista\n\n\n\n\n\nAbrimos nuestro Rproject y creamos un nuevo documento de Quarto file –&gt; new file –&gt; Quarto document\nEditamos el yaml, agregando bibliography: percepcion-desigualdad.bib y link-citations: yes\n\n\n\n\n\n\n\nNota\n\n\n\nYAML: Lenguaje de programación. Es un formato de serialización de datos que proporcionan un mecanismo de intercambio de datos legible por humanos. Dan formato a los datos de manera estandarizada para su intercambio entre aplicaciones de software.\n\n\n\n\nComenzamos a escribir la introducción de nuestra investigación\nPara insertar referencias:\n\nSe pueden insertar citas usando el comando Insert -&gt; Citation o usando la sintaxis directamente (por ejemplo, (cita?) o (cita?)).\nLas citas van entre corchetes y están separadas por punto y coma. Cada cita debe tener una clave, compuesta por ‘@’ + el identificador de la cita en zotero.\n\nEn este caso, [@mijsParadoxInequalityIncome2021a]\nAquí hay otros ejemplos:\nLa investigación sobre percepción de desigualdad económica ha tenido un auge durante los últimos años [ver @mijsParadoxInequalityIncome2021a; también @crucesBiasedPerceptionsIncome2013].\nEspecíficamente, se ha encontrado evidencia sobre que… [@mijsParadoxInequalityIncome2021a]. De todas formas, @crucesBiasedPerceptionsIncome2013 plantea que…\nAsí mismo, Mijs señala que… [-@mijsParadoxInequalityIncome2021a]\nAunque ambos concluyen que… [@mijsParadoxInequalityIncome2021a; @crucesBiasedPerceptionsIncome2013]\n\n\nLuego renderizamos y se debería ver así:\n\n\nCon referencias automáticas!\n\nAhora que tenemos la introducción de nuestra investigación podemos subirla a Github Pages a través de Github Desktop.",
    "crumbs": [
      "Prácticos",
      "Talleres",
      "02: Práctico 2"
    ]
  },
  {
    "objectID": "practicos/02-content.html#zotero",
    "href": "practicos/02-content.html#zotero",
    "title": "Práctico R 2. Vinculación R y Zotero",
    "section": "",
    "text": "Acceder a la página de zotero\n\nVamos a Log in\n\n\nY creamos una cuenta gratis\n\n\n\nFinalmente volvemos al inicio y descargamos el programa:\n\n\n\n\n\nZotero es un gestor bibliográfico que nos permite almacenar referencias bibliográficas.\n\nEs posible crear distintas bibliotecas personales (esquina superior izquierda) o grupales (abajo). Se recomienda separar las bibliotecas por temas o proyectos\nAl visualizar una referencia bibliográfica nos muestra todos los metadatos: Título, autores, nombre de la revista, año de publicación, DOI, ISBN de la revista, número de páginas, etc.\nEl dato central que nos va a servir en esta parte del proceso es el DOI\n\n\n\n\n\n\n\nNota\n\n\n\nDOI: Digital Object Identifier (Identificador de objetos digitales)\nEl DOI consiste en un código alfanumérico que identifica en la web un artículo y que lo recupera incluso si éste se ubica en un servidor distinto al que fue alojado en un principio. Se evita así el típico problema de los enlaces rotos, muy habitual en macrowebs como las universitarias.\n\n\n\n\nPara crear una biblioteca en zotero vamos a Archivo -&gt; Nueva colección y le ponemos un nombre que no tenga tíldes, ñ o espacios\n\n\nEn este caso mi biblioteca se llama “percepcion-desigualdad”.\n\nZotero tiene dos funciones para agregar referencias botón verde “Nuevo elemento” o varita mágica “añadir elemento por identificador”. Esta vez vamos por la segunda opción\nBuscamos un paper que nos interese: en este caso busqué el paper The paradox of inequality: income inequality and belief in meritocracy go hand in hand de Jonathan Mijs (2021). Su DOI es https://doi.org/10.1093/ser/mwy051\nUsamos la función Añadir elemento por identificador para agregar nuestra referencia a zotero\n\n\n¿Cuál es la forma más eficiente de buscar bibliografía sobre un mismo tema?",
    "crumbs": [
      "Prácticos",
      "Talleres",
      "02: Práctico 2"
    ]
  },
  {
    "objectID": "practicos/02-content.html#researchrabbit",
    "href": "practicos/02-content.html#researchrabbit",
    "title": "Práctico R 2. Vinculación R y Zotero",
    "section": "",
    "text": "Research Rabbit es una plataforma que a partir de un paper busca otros similares, cruzando referencias y autores. Además, tiene una ventaja: Se vincula con Zotero\n\nIngresar a la página https://researchrabbitapp.com/.\nCrear cuenta\n\n\n\nUna vez dentro apretamos “Import Zotero Collection” y seleccionamos nuestra biblioteca\n\n\n\nAsí se ve research rabbit\n\n\n\nPodemos revisar el abstract de algún paper y, si nos interesa, lo agregamos a nuestra biblioteca\n\n\n\nDespués volvemos a Zotero, actualizamos y aparece nuestro nuevo paper\n\n\nAhora solo nos interesa lograr una cosa más: vincular nuestra biblioteca de Zotero con R\n\nVamos a este link y descargamos zotero-better-bibtex-6.7.169.xpi\nVolvemos a Zotero –&gt; Herramientas –&gt; Complementos –&gt; La tuerca en la esquina superior derecha –&gt; Instalar Add-on desde archivo –&gt; Seleccionamos el archivo que acabamos de descargar\n\n\n\nPaso final: exportamos nuestra biblioteca. Click derecho en nuestra biblioteca –&gt; Exportar colección\n\n\n\nSeleccionamos formato: Better BibTeX y marcamos la casilla “Keep updated”. Esto último actualizará el archivo automáticamente cuando agreguemos nueva bibliografía\n\n\n\nGuardamos nuestro archivo .bib en la misma carpeta de nuestro proyecto de trabajo",
    "crumbs": [
      "Prácticos",
      "Talleres",
      "02: Práctico 2"
    ]
  },
  {
    "objectID": "practicos/02-content.html#quarto",
    "href": "practicos/02-content.html#quarto",
    "title": "Práctico R 2. Vinculación R y Zotero",
    "section": "",
    "text": "La escritura en Quarto tiene algunos códigos o funciones, aquí un resumen de su mayoría:\n\n\n\nCódigo\nAsí se ve\n\n\n\n\nAlgo de texto en el párrafo.\n\nMás texto\nespacio entre lineas.\nAlgo de texto.\nAlgo de texto en el párrafo. Siempre utilizando espacios para dividir párrafos\n\n\n`*Cursivas*`\nCursivas\n\n\n`**Negrita**`\nNegrita\n\n\n# Título 1\n\n\n\n## Título 2\n\n\n\n### Título 3\n\n\n\n(puedes llegar hasta un título N° 6 con ######)\n\n\n\n`[Texto enlace](https://quarto.org/)`\nTexto enlace\n\n\n`![Texto imagen](/path/to/image.png)`\n\n\n\nTexto imagen\n\n\n\n\n&gt; Citas\n\nCitas\n\n\n\n1. Una\n2. lista\n3 ordenada\n\nUna\nlista\nordenada\n\n\n\n- Otro\n- tipo\n- de lista\n\nOtro\ntipo\nde lista\n\n\n\n\n\nAbrimos nuestro Rproject y creamos un nuevo documento de Quarto file –&gt; new file –&gt; Quarto document\nEditamos el yaml, agregando bibliography: percepcion-desigualdad.bib y link-citations: yes\n\n\n\n\n\n\n\nNota\n\n\n\nYAML: Lenguaje de programación. Es un formato de serialización de datos que proporcionan un mecanismo de intercambio de datos legible por humanos. Dan formato a los datos de manera estandarizada para su intercambio entre aplicaciones de software.\n\n\n\n\nComenzamos a escribir la introducción de nuestra investigación\nPara insertar referencias:\n\nSe pueden insertar citas usando el comando Insert -&gt; Citation o usando la sintaxis directamente (por ejemplo, (cita?) o (cita?)).\nLas citas van entre corchetes y están separadas por punto y coma. Cada cita debe tener una clave, compuesta por ‘@’ + el identificador de la cita en zotero.\n\nEn este caso, [@mijsParadoxInequalityIncome2021a]\nAquí hay otros ejemplos:\nLa investigación sobre percepción de desigualdad económica ha tenido un auge durante los últimos años [ver @mijsParadoxInequalityIncome2021a; también @crucesBiasedPerceptionsIncome2013].\nEspecíficamente, se ha encontrado evidencia sobre que… [@mijsParadoxInequalityIncome2021a]. De todas formas, @crucesBiasedPerceptionsIncome2013 plantea que…\nAsí mismo, Mijs señala que… [-@mijsParadoxInequalityIncome2021a]\nAunque ambos concluyen que… [@mijsParadoxInequalityIncome2021a; @crucesBiasedPerceptionsIncome2013]\n\n\nLuego renderizamos y se debería ver así:\n\n\nCon referencias automáticas!\n\nAhora que tenemos la introducción de nuestra investigación podemos subirla a Github Pages a través de Github Desktop.",
    "crumbs": [
      "Prácticos",
      "Talleres",
      "02: Práctico 2"
    ]
  },
  {
    "objectID": "news/index.html",
    "href": "news/index.html",
    "title": "Noticias",
    "section": "",
    "text": "Ordenar por\n       Por defecto\n         \n          Fecha - Menos reciente\n        \n         \n          Fecha - Más reciente\n        \n         \n          Título\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\nFecha\n\n\nTítulo\n\n\nCategorías\n\n\n\n\n\n\nlunes agosto 7, 2023 at 12:00 AM\n\n\nBienvenid_s a clases!\n\n\ncomenzando\n\n\n\n\nlunes agosto 7, 2023 at 12:00 AM\n\n\nInformaciones de la semana\n\n\ninfo\n\n\n\n\n\nNo hay resultados\n\n\n\n\n\n\n\n\nSuscribirse!\n\n\n\nPuedes usar un lector de feeds como Feedly o un servicio RSS-to-email como Blogtrottr para suscribirte a cualquiera de estos mensajes. ::: {.grid}\n\n\n RSS\n\n\n\n\n\n\n\n\n\n:::"
  },
  {
    "objectID": "news/2023-01-09_welcome.html",
    "href": "news/2023-01-09_welcome.html",
    "title": "Bienvenid_s a clases!",
    "section": "",
    "text": "← News\n\n\n\n\nHola a todos!"
  },
  {
    "objectID": "herramientas/index.html",
    "href": "herramientas/index.html",
    "title": "Herramientas",
    "section": "",
    "text": "En esta sección encontrarán todas las herramientas y softwares que facilitan el trabajo reproducible.\nEn construcción…",
    "crumbs": [
      "Herramientas",
      "Información general",
      "Herramientas"
    ]
  },
  {
    "objectID": "example/index.html",
    "href": "example/index.html",
    "title": "Code examples",
    "section": "",
    "text": "Visit this section after you have finished the readings and lecture videos. It contains fully annotated R code and other supplementary information and it will be indispensable as you work on your problem sets and project.\nMany sections also contain videos of me live coding the examples so you can see what it looks like to work with R in real time. You’ll notice me make all sorts of little errors, which is totally normal—everyone does!"
  },
  {
    "objectID": "content/index.html",
    "href": "content/index.html",
    "title": "Clases",
    "section": "",
    "text": "En esta sección podrán encontrar todas las clases del curso. Se irán subiendo semana a semana.",
    "crumbs": [
      "Clases",
      "Información general",
      "Clases"
    ]
  },
  {
    "objectID": "content/04-content.html#lecturas",
    "href": "content/04-content.html#lecturas",
    "title": "Clase 4",
    "section": "Lecturas",
    "text": "Lecturas",
    "crumbs": [
      "Clases",
      "04: Clase 4"
    ]
  },
  {
    "objectID": "content/04-content.html#moore-1.comprensión-de-los-datos-1-54",
    "href": "content/04-content.html#moore-1.comprensión-de-los-datos-1-54",
    "title": "Clase 4",
    "section": "Moore: 1.Comprensión de los datos (1-54)",
    "text": "Moore: 1.Comprensión de los datos (1-54)",
    "crumbs": [
      "Clases",
      "04: Clase 4"
    ]
  },
  {
    "objectID": "content/02-content.html#lecturas",
    "href": "content/02-content.html#lecturas",
    "title": "Clase 2",
    "section": "Lecturas",
    "text": "Lecturas\nR for Data Science",
    "crumbs": [
      "Clases",
      "02: Clase 2"
    ]
  },
  {
    "objectID": "assignment/index.html",
    "href": "assignment/index.html",
    "title": "Trabajos",
    "section": "",
    "text": "En esta sección se encuentran las instrucciones de los Trabajos a realizar durante el curso.\n\nEvaluaciones\nEl curso tendrá cinco instancias de evaluación (fechas en pestaña de planificación y en el programa del curso):\n4 trabajos individuales acumulativos (15% c/u).\n1 presentación de resultados (10%).\nLa nota ponderada de las evaluaciones equivaldrá al 70% de la nota del curso y el examen final al 30% restante.\n\n\nSobre temas y datos\nEl tema de trabajo es libre. Sin embargo, de modo de lograr una mayor colaboración desde el equipo docente a sus trabajos, sugerimos desarrollar los siguientes temas:\n\nDesigualdad social, Estratificación social, justicia distributiva, percepción de desigualdad\nEducación cívica, política educativa\nCohesión social, sociología política, economía gig\n\nLa base de datos a utilizar también es libre, pero recomendamos las siguientes:\n\nEstudio Longitudinal Social de Chile (Ola 1 2016)\nCASEN 2022\nSIMCE\nLAPOP\nLATINOBARÓMETRO",
    "crumbs": [
      "Trabajos",
      "Información general",
      "Trabajos"
    ]
  },
  {
    "objectID": "assignment/02-trabajo.html",
    "href": "assignment/02-trabajo.html",
    "title": "Trabajo 2. Procesamiento y visualización de análisis descriptivo",
    "section": "",
    "text": "El objetivo de este trabajo es realizar un reporte dinámico a través de Quarto, que contenga el análisis descriptivo del problema de investigación propuesto en el Trabajo 1. El documento final debe ser subido a Github Pages y se debe enviar el link a este documento para su revisión.",
    "crumbs": [
      "Trabajos",
      "Trabajo 2"
    ]
  },
  {
    "objectID": "assignment/02-trabajo.html#objetivos-del-trabajo",
    "href": "assignment/02-trabajo.html#objetivos-del-trabajo",
    "title": "Trabajo 2. Procesamiento y visualización de análisis descriptivo",
    "section": "",
    "text": "El objetivo de este trabajo es realizar un reporte dinámico a través de Quarto, que contenga el análisis descriptivo del problema de investigación propuesto en el Trabajo 1. El documento final debe ser subido a Github Pages y se debe enviar el link a este documento para su revisión.",
    "crumbs": [
      "Trabajos",
      "Trabajo 2"
    ]
  },
  {
    "objectID": "assignment/02-trabajo.html#instrucciones-generales",
    "href": "assignment/02-trabajo.html#instrucciones-generales",
    "title": "Trabajo 2. Procesamiento y visualización de análisis descriptivo",
    "section": "Instrucciones generales",
    "text": "Instrucciones generales\n\nDescargar la base de datos que se utilizará en la investigación y guardarla en la carpeta correspondiente (input)\nOperacionalización: Script de R llamado “Preparacion” y guardado en la carpeta que corresponde (Procesamiento). Manipulación de datos para obtener las variables utilizadas en la investigación. Se espera que l-s estudiantes sean capaces de seleccionar las variables relevantes para la problemática escogida, agruparlas, reordenarlas y asignarles los nombres y etiquetas según corresponda.\nVisualización de datos: Elaboración de tablas y/o gráficos, en el contexto de un reporte científico de investigación, que intente responder, ejemplificar y/o demostrar los principales hallazgos de la investigación. Para esta primera entrega se espera que sean capaces de generar una tabla descriptiva que muestre las medidas de tendencia central de las variables utilizadas en la investigación, así como su contraparte de tablas de frecuencias en el caso de variables categóricas. También se espera que sean capaces de elaborar dos gráficos descriptivos que permitan visualizar la distribución de las principales variables de interés.\nNo es necesario elaborar un informe teórico sobre el tema de investigación. En la introducción de este reporte debe ir la propuesta elaborada en el Trabajo 1, pero es importante mencionar la fuente de datos utilizada. El objetivo del trabajo es que sean capaces de operacionalizar variables, escoger la mejor forma de visualizar sus medidas de tendencia central y/o frecuencias e interpretar estas tablas/gráficos.\n\nEntrega:\n\nJueves 18 de Abril a través de Teams.\nSe debe enviar el link al repositorio de github\nNo más de 5000 palabras\nSe deben mantener las referencias de la literatura / bases de datos revisadas\natrasos, 0,5 por día de atraso.\n\nRúbrica de evaluación:\n\n\n\n\n\n\n\n\nÍtem\nObjetivo\nPuntaje\n\n\n\n\n1. Cargar base de datos\nL-s estudiantes son capaces de descargar la base de datos y posteriormente cargarla en R\n2pts\n\n\n2. Selección de variables\nL-s estudiantes son capaces de seleccionar las variables relevantes según su problema de investigación\n2pts\n\n\n3. Operacionalización de variables\nL-s estudiantes son capaces de operacionalizar correctamente las variables de interés. Las variables deben tener un correcto nivel de medición (2pto), correcto paso a NA (1pto), correcto orden de medición, es decir, valores positivos como valores más altos (1pto) y etiquetas correctas (1pto)\n5pts\n\n\n4. Visualización de resultados\nL-s estudiantes son capaces de visualizar correctamente las variables de interés. Se espera que el reporte incluya una tabla descriptiva (3ptos) y dos gráficos univariados (3ptos)\n6ptos\n\n\n5. Interpretación de resultados\nL-s estudiantes son capaces de interpretar correctamente las tablas y gráficos presentados\n3pts\n\n\nTotal\n-\n18puntos",
    "crumbs": [
      "Trabajos",
      "Trabajo 2"
    ]
  },
  {
    "objectID": "assignment/01-trabajo.html",
    "href": "assignment/01-trabajo.html",
    "title": "Trabajo 1. Reporte en Quarto",
    "section": "",
    "text": "El objetivo de este trabajo es realizar un reporte dinámico a través de Quarto, que contenga la introducción y planteamiento de un problema de investigación, fundamentado a través de referencias automáticas desde Zotero. El documento final debe ser subido a Github Pages y se debe enviar el link a este documento para su revisión.\n\n\n\n\nTítulo: Breve, lo principal es hacer alusión al objeto central del estudio.\nIntroducción: Definición de la problemática a abordar, su relevancia y sus principales conceptos asociados (MÁXIMO 1000 palabras)\n\nEs importante considerar\n\nRelevancia del problema de investigación: además de que el “tema” pueda ser relevante (ej: aumento de desigualdad económica, disminución de niveles de participación), la relevancia del problema se refiere al aporte distintivo desde una perspectiva académica y disciplinar (sociología) (ej: “existe evidencia que los bajos niveles de participación se ven afectados por el nivel educacional (Pérez, 1999”).\nPrecisar el concepto central que se va a investigar: Ejemplo “vamos a estudiar participación política de estudiantes, entendiendo por ello la frecuencia de participación en actividades como marchas, tomas y en redes sociales”.\nPrecisar argumento / hipótesis central, que tiene que ver con el predictor principal: “Se espera que a medida que aumenta el nivel de percepción de desigualdad económica, aumenta la participación política de los/as estudiantes”\nSe deben incluir al menos 4 referencias correctamente citadas, según el procedimiento visto en clases de vinculación entre Zotero y RStudio\nEl documento final debe ser subido a Github Pages y se debe enviar el link a este documento para su revisión.",
    "crumbs": [
      "Trabajos",
      "Trabajo 1"
    ]
  },
  {
    "objectID": "assignment/01-trabajo.html#objetivos-del-trabajo",
    "href": "assignment/01-trabajo.html#objetivos-del-trabajo",
    "title": "Trabajo 1. Reporte en Quarto",
    "section": "",
    "text": "El objetivo de este trabajo es realizar un reporte dinámico a través de Quarto, que contenga la introducción y planteamiento de un problema de investigación, fundamentado a través de referencias automáticas desde Zotero. El documento final debe ser subido a Github Pages y se debe enviar el link a este documento para su revisión.",
    "crumbs": [
      "Trabajos",
      "Trabajo 1"
    ]
  },
  {
    "objectID": "assignment/01-trabajo.html#secciones-del-trabajo",
    "href": "assignment/01-trabajo.html#secciones-del-trabajo",
    "title": "Trabajo 1. Reporte en Quarto",
    "section": "",
    "text": "Título: Breve, lo principal es hacer alusión al objeto central del estudio.\nIntroducción: Definición de la problemática a abordar, su relevancia y sus principales conceptos asociados (MÁXIMO 1000 palabras)\n\nEs importante considerar\n\nRelevancia del problema de investigación: además de que el “tema” pueda ser relevante (ej: aumento de desigualdad económica, disminución de niveles de participación), la relevancia del problema se refiere al aporte distintivo desde una perspectiva académica y disciplinar (sociología) (ej: “existe evidencia que los bajos niveles de participación se ven afectados por el nivel educacional (Pérez, 1999”).\nPrecisar el concepto central que se va a investigar: Ejemplo “vamos a estudiar participación política de estudiantes, entendiendo por ello la frecuencia de participación en actividades como marchas, tomas y en redes sociales”.\nPrecisar argumento / hipótesis central, que tiene que ver con el predictor principal: “Se espera que a medida que aumenta el nivel de percepción de desigualdad económica, aumenta la participación política de los/as estudiantes”\nSe deben incluir al menos 4 referencias correctamente citadas, según el procedimiento visto en clases de vinculación entre Zotero y RStudio\nEl documento final debe ser subido a Github Pages y se debe enviar el link a este documento para su revisión.",
    "crumbs": [
      "Trabajos",
      "Trabajo 1"
    ]
  },
  {
    "objectID": "assignment/03-trabajo.html",
    "href": "assignment/03-trabajo.html",
    "title": "Trabajo 3. Asociación de variables y construcción de índices",
    "section": "",
    "text": "El objetivo de este trabajo es realizar un reporte dinámico a través de Quarto, que contenga el análisis descriptivo (trabajo 2) del problema de investigación propuesto en el Trabajo 1 y la visualización e interpretación de la asociación de estas variables. El documento final debe ser subido a Github Pages y se debe enviar el link a este documento para su revisión.",
    "crumbs": [
      "Trabajos",
      "Trabajo 3"
    ]
  },
  {
    "objectID": "assignment/03-trabajo.html#objetivos-del-trabajo",
    "href": "assignment/03-trabajo.html#objetivos-del-trabajo",
    "title": "Trabajo 3. Asociación de variables y construcción de índices",
    "section": "",
    "text": "El objetivo de este trabajo es realizar un reporte dinámico a través de Quarto, que contenga el análisis descriptivo (trabajo 2) del problema de investigación propuesto en el Trabajo 1 y la visualización e interpretación de la asociación de estas variables. El documento final debe ser subido a Github Pages y se debe enviar el link a este documento para su revisión.",
    "crumbs": [
      "Trabajos",
      "Trabajo 3"
    ]
  },
  {
    "objectID": "assignment/03-trabajo.html#instrucciones-generales",
    "href": "assignment/03-trabajo.html#instrucciones-generales",
    "title": "Trabajo 3. Asociación de variables y construcción de índices",
    "section": "Instrucciones generales",
    "text": "Instrucciones generales\n\nDescargar la base de datos que se utilizará en la investigación y guardarla en la carpeta correspondiente (input)\nOperacionalización: Script de R llamado “Preparacion” y guardado en la carpeta que corresponde (Procesamiento). Manipulación de datos para obtener las variables utilizadas en la investigación. Se espera que l-s estudiantes sean capaces de seleccionar las variables relevantes para la problemática escogida, agruparlas, reordenarlas y asignarles los nombres y etiquetas según corresponda.\nVisualización de datos: Elaboración de tablas y/o gráficos, en el contexto de un reporte científico de investigación, que intente responder, ejemplificar y/o demostrar los principales hallazgos de la investigación. Para esta segunda entrega se espera que sean capaces de generar una tabla de correlaciones que muestre el grado de asociación de las variables utilizadas en la investigación. También se espera que sean capaces de elaborar al menos un índice ponderado y/o una escalados con su respectivo reporte de consistencia interna (alfa de cronbach) según corresponda.\nNo es necesario elaborar un informe teórico sobre el tema de investigación. En la introducción de este reporte debe ir la propuesta elaborada en el Trabajo 1, mencionando la fuente de datos utilizada. En la segunda sección debe ir el reporte descriptivo del trabajo 2. El objetivo de este trabajo 3 es que sean capaces de operacionalizar variables, estimar y visualizar su grado de asociación y construir índices y/o escalas.\n\nEntrega:\n\nJueves 09 de mayo a través de Teams.\nSi se entrega a través de github pages se otorgarán 0,5 décimas adicionales\nNo más de 5000 palabras\nSe deben mantener las referencias de la literatura / bases de datos revisadas\natrasos, 0,5 por día de atraso.\n\nRúbrica de evaluación:\n\n\n\n\n\n\n\n\nÍtem\nObjetivo\nPuntaje\n\n\n\n\n1. Carga y Selección de variables\nL-s estudiantes son capaces de seleccionar las variables relevantes según su problema de investigación\n2pts\n\n\n2. Operacionalización de variables\nL-s estudiantes son capaces de operacionalizar correctamente las variables de interés.\n3pts\n\n\n3. Asociación de variables\nL-s estudiantes son capaces de reportar y visualizar correctamente la asociación entre sus variables. Se espera que el reporte incluya al menos una tabla y/o gráfico\n5ptos\n\n\n4. Construcción de índices y escalas\nL-s estudiantes son capaces de construir al menos un índice ponderado (reportando un autor o informe que justifique la ponderación) y/o una escala con el reporte de su consistencia interna\n5ptos\n\n\n5. Interpretación de resultados\nL-s estudiantes son capaces de interpretar correctamente las tablas y gráficos presentados\n3pts\n\n\nTotal\n-\n18puntos",
    "crumbs": [
      "Trabajos",
      "Trabajo 3"
    ]
  },
  {
    "objectID": "content/01-content.html#lecturas",
    "href": "content/01-content.html#lecturas",
    "title": "Presentación",
    "section": "Lecturas",
    "text": "Lecturas\nR for Data Science",
    "crumbs": [
      "Clases",
      "01: Clase 1"
    ]
  },
  {
    "objectID": "content/03-content.html#lecturas",
    "href": "content/03-content.html#lecturas",
    "title": "Clase 3",
    "section": "Lecturas",
    "text": "Lecturas",
    "crumbs": [
      "Clases",
      "03: Clase 3"
    ]
  },
  {
    "objectID": "content/03-content.html#moore-1.comprensión-de-los-datos-1-54",
    "href": "content/03-content.html#moore-1.comprensión-de-los-datos-1-54",
    "title": "Clase 3",
    "section": "Moore: 1.Comprensión de los datos (1-54)",
    "text": "Moore: 1.Comprensión de los datos (1-54)",
    "crumbs": [
      "Clases",
      "03: Clase 3"
    ]
  },
  {
    "objectID": "example/cace.html",
    "href": "example/cace.html",
    "title": "Complier average treatment effects",
    "section": "",
    "text": "Throughout this course, we’ve talked about the difference between the average treatment effect (ATE), or the average effect of a program for an entire population, and conditional average treatment effect (CATE), or the average effect of a program for some segment of the population. There are all sorts of CATEs: you can find the CATE for men vs. women, for people who are treated with the program (the average treatment on the treated, or ATT or TOT), for people who are not treated with the program (the average treatment on the untreated, or ATU), and so on.\nOne important type of CATE is the effect of a program on just those who comply with the program. We can call this the complier average treatment effect, but the acronym would be the same as conditional average treatment effect, so we’ll call it the complier average causal effect or CACE.\nThinking about compliance is important. You might randomly assign people to receive treatment or a program, but people might not do what you tell them. Additionally, people might do the program if assigned to do it, but they would have done it anyway. We can split the population into four types of people:\n\nCompliers: People who follow whatever their assignment is (if assigned to treatment, they do the program; if assigned to control, they don’t)\nAlways takers: People who will receive or seek out the program regardless of assignment (if assigned to treatment, they do the program; if assigned to control, they still do the program)\nNever takers: People who will not receive or seek out the program regardless of assignment (if assigned to treatment, they don’t do the program; if assigned to control, they also don’t do it)\nDefiers: People who will do the opposite of whatever their assignment is (if assigned to treatment, they don’t do the program; if assigned to control, they do the program)\n\nTo simplify things, evaluators and econometricians assume that defiers don’t exist based on the idea of monotonicity, which means that we can assume that the effect of being assigned to treatment only increases the likelihood of participating in the program (and doesn’t make it more likely).\nThe tricky part about trying to find who the compliers are in a sample is that we can’t know what people would have done in the absence of treatment. If we see that someone in the experiment was assigned to be in the treatment group and they then participated in the program, they could be a complier (since they did what they were assigned to do), or they could be an always taker (they did what they were assigned to do, but they would have done it anyway). Due to the fundamental problem of causal inference, we cannot know what each person would have done in a parallel world.\nWe can use data from a hypothetical program to see how these three types of compliers distort our outcomes, and more importantly, how we can disentangle compliers from their always- and never-taker counterparts.\nIf you want to follow along with this example, you can download these two datasets:\n\n bed_nets_time_machine.csv\n bed_nets_observed.csv"
  },
  {
    "objectID": "example/cace.html#compliance-and-treatment-effects",
    "href": "example/cace.html#compliance-and-treatment-effects",
    "title": "Complier average treatment effects",
    "section": "",
    "text": "Throughout this course, we’ve talked about the difference between the average treatment effect (ATE), or the average effect of a program for an entire population, and conditional average treatment effect (CATE), or the average effect of a program for some segment of the population. There are all sorts of CATEs: you can find the CATE for men vs. women, for people who are treated with the program (the average treatment on the treated, or ATT or TOT), for people who are not treated with the program (the average treatment on the untreated, or ATU), and so on.\nOne important type of CATE is the effect of a program on just those who comply with the program. We can call this the complier average treatment effect, but the acronym would be the same as conditional average treatment effect, so we’ll call it the complier average causal effect or CACE.\nThinking about compliance is important. You might randomly assign people to receive treatment or a program, but people might not do what you tell them. Additionally, people might do the program if assigned to do it, but they would have done it anyway. We can split the population into four types of people:\n\nCompliers: People who follow whatever their assignment is (if assigned to treatment, they do the program; if assigned to control, they don’t)\nAlways takers: People who will receive or seek out the program regardless of assignment (if assigned to treatment, they do the program; if assigned to control, they still do the program)\nNever takers: People who will not receive or seek out the program regardless of assignment (if assigned to treatment, they don’t do the program; if assigned to control, they also don’t do it)\nDefiers: People who will do the opposite of whatever their assignment is (if assigned to treatment, they don’t do the program; if assigned to control, they do the program)\n\nTo simplify things, evaluators and econometricians assume that defiers don’t exist based on the idea of monotonicity, which means that we can assume that the effect of being assigned to treatment only increases the likelihood of participating in the program (and doesn’t make it more likely).\nThe tricky part about trying to find who the compliers are in a sample is that we can’t know what people would have done in the absence of treatment. If we see that someone in the experiment was assigned to be in the treatment group and they then participated in the program, they could be a complier (since they did what they were assigned to do), or they could be an always taker (they did what they were assigned to do, but they would have done it anyway). Due to the fundamental problem of causal inference, we cannot know what each person would have done in a parallel world.\nWe can use data from a hypothetical program to see how these three types of compliers distort our outcomes, and more importantly, how we can disentangle compliers from their always- and never-taker counterparts.\nIf you want to follow along with this example, you can download these two datasets:\n\n bed_nets_time_machine.csv\n bed_nets_observed.csv"
  },
  {
    "objectID": "example/cace.html#finding-compliers-with-a-mind-reading-time-machine",
    "href": "example/cace.html#finding-compliers-with-a-mind-reading-time-machine",
    "title": "Complier average treatment effects",
    "section": "Finding compliers with a mind-reading time machine",
    "text": "Finding compliers with a mind-reading time machine\nFirst let’s load the data and reorder some of the categories:\n\n\nCode\nlibrary(tidyverse)  # ggplot(), %&gt;%, mutate(), and friends\nlibrary(broom)  # Convert models to data frames\nlibrary(estimatr)  # Run 2SLS models in one step with iv_robust()\n\nbed_nets &lt;- read_csv(\"data/bed_nets_observed.csv\") %&gt;%\n  # Make \"No bed net\" (control) come first\n  mutate(bed_net = fct_relevel(bed_net, \"No bed net\"))\n\nbed_nets_time_machine &lt;- read_csv(\"data/bed_nets_time_machine.csv\") %&gt;%\n  # Make \"No bed net\" come first and \"Complier\" come first\n  mutate(bed_net = fct_relevel(bed_net, \"No bed net\"),\n         status = fct_relevel(status, \"Complier\"))\n\n\nThis is what we would be able to see if we could read everyone’s minds. There are always takers who will use a bed net regardless of the program, and they’ll have higher health outcomes. However, those better outcomes are because of something endogenous—there’s something else that makes these people always pursue bed nets, and that’s likely related to health. We probably want to not consider them when looking for the program effect. There are never takers who won’t ever use a bed net, and they have worse health outcomes. Again, there’s endogeneity here—something is causing them to not use the bed nets, and it likely also causes their health level. We don’t want to look at them either.\nThe first group—the compliers—are the people we want to focus on. Here we see that the program had an effect when compared to a control group.\n\n\nCode\nset.seed(1234)  # Make the jittering the same every time\n\nggplot(bed_nets_time_machine, aes(y = health, x = treatment)) +\n  geom_point(aes(shape = bed_net, color = status),\n             position = position_jitter(height = NULL, width = 0.25)) +\n  facet_wrap(vars(status)) +\n  labs(color = \"Type of person\", shape = \"Compliance\",\n       x = NULL, y = \"Health status\") +\n  scale_color_viridis_d(option = \"plasma\", end = 0.85) +\n  theme_bw()"
  },
  {
    "objectID": "example/cace.html#finding-compliers-in-actual-data",
    "href": "example/cace.html#finding-compliers-in-actual-data",
    "title": "Complier average treatment effects",
    "section": "Finding compliers in actual data",
    "text": "Finding compliers in actual data\nThis is what we actually see in the data, though. You can tell who some of the always takers are (those who used bed nets after being assigned to the control group) and who some of the never takers are (those who did not use a bed net after being assigned to the treatment group), but compliers are mixed up with the always and never takers. We have to somehow disentangle them!\n\n\nCode\nset.seed(1234)\nggplot(bed_nets_time_machine, aes(y = health, x = bed_net)) +\n  geom_point(aes(shape = bed_net, color = status),\n             position = position_jitter(height = NULL, width = 0.25)) +\n  facet_wrap(vars(treatment)) +\n  labs(color = \"Type of person\", shape = \"Compliance\",\n       x = NULL, y = \"Health status\") +\n  scale_color_viridis_d(option = \"plasma\", end = 0.85) +\n  theme_bw()\n\n\n\n\n\n\n\n\n\nWe can do this by assuming the proportion of compliers, never takers, and always takers are equally spread across treatment and control (which we can assume through the magic of randomization). If that’s the case, we can calculate the intent to treat (ITT) effect, which is the CATE of being assigned treatment (or the effect of being assigned treatment on health status, regardless of actual compliance).\nThe ITT is actually composed of three different causal effects: the complier average causal effect (CACE), the always taker average causal effect (ATACE), and the never taker average causal effect (NTACE). In the formula below, \\(\\pi\\) stands for the proportion of people in each group. Formally, the ITT can be defined like this:\n\\[\n\\begin{aligned}\n\\text{ITT}\\ =\\ & \\color{#0D0887}{\\pi_\\text{compliers} \\times (\\text{T} - \\text{C})_\\text{compliers}} + \\\\\n&\\color{#B7318A}{\\pi_\\text{always takers} \\times (\\text{T} - \\text{C})_\\text{always takers}} + \\\\\n&\\color{#FEBA2C}{\\pi_\\text{never takers} \\times (\\text{T} - \\text{C})_\\text{never takers}}\n\\end{aligned}\n\\]\nWe can simplify this to this acronymized version:\n\\[\n\\text{ITT}\\ =\\ \\color{#0D0887}{\\pi_\\text{C} \\text{CACE}} + \\color{#B7318A}{\\pi_\\text{A} \\text{ATACE}} + \\color{#FEBA2C}{\\pi_\\text{N} \\text{NTACE}}\n\\]\nThe number we care about the most here is the CACE, which is stuck in the middle of the equation. But we can rescue it with some fun logical and algebraic trickery!\nIf we assume that assignment to treatment doesn’t make someone more likely to be an always taker or a never taker, we can set the ATACE and NTACE to zero, leaving us with just three variables to worry about: ITT, \\(\\pi_\\text{c}\\), and CACE:\n\\[\n\\begin{aligned}\n\\text{ITT}\\ =\\ & \\color{#0D0887}{\\pi_\\text{C} \\text{CACE}} + \\color{#B7318A}{\\pi_\\text{A} \\text{ATACE}} + \\color{#FEBA2C}{\\pi_\\text{N} \\text{NTACE}} \\\\[6pt]\n=\\ & \\color{#0D0887}{\\pi_\\text{C} \\text{CACE}} + \\color{#B7318A}{\\pi_\\text{A} \\times 0} + \\color{#FEBA2C}{\\pi_\\text{N} \\times 0}\\\\[6pt]\n\\text{ITT}\\ =\\ & \\color{#0D0887}{\\pi_\\text{C} \\text{CACE}}\n\\end{aligned}\n\\]\nWe can use algebra to rearrange this formula so that we’re left with an equation that starts with CACE (since that’s the value we care about):\n\\[\n\\text{CACE} = \\frac{\\text{ITT}}{\\pi_\\text{C}}\n\\]\nIf we can find the ITT and the proportion of compliers, we can find the complier average causal effect (CACE). Fortunately, both those pieces—ITT and \\(\\pi_\\text{C}\\)—are findable in the data we have!"
  },
  {
    "objectID": "example/cace.html#finding-the-itt",
    "href": "example/cace.html#finding-the-itt",
    "title": "Complier average treatment effects",
    "section": "Finding the ITT",
    "text": "Finding the ITT\nThe ITT is easy to find with a simple OLS model:\n\n\nCode\nitt_model &lt;- lm(health ~ treatment, data = bed_nets)\n\ntidy(itt_model)\n## # A tibble: 2 × 5\n##   term               estimate std.error statistic  p.value\n##   &lt;chr&gt;                 &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n## 1 (Intercept)           40.9      0.444     92.1  0       \n## 2 treatmentTreatment     5.99     0.630      9.51 5.20e-21\n\nITT &lt;- tidy(itt_model) %&gt;%\n  filter(term == \"treatmentTreatment\") %&gt;%\n  pull(estimate)\n\n\nThe ITT here is ≈6—being assigned treatment increases average health status by 5.99 health points."
  },
  {
    "objectID": "example/cace.html#finding-the-proportion-of-compliers",
    "href": "example/cace.html#finding-the-proportion-of-compliers",
    "title": "Complier average treatment effects",
    "section": "Finding the proportion of compliers",
    "text": "Finding the proportion of compliers\nThe proportion of compliers is a little trickier, but doable with some algebraic trickery. Recall from the graph above that the people who were in the treatment group and who complied are a combination of always takers and compliers. This means we can say:\n\\[\n\\begin{aligned}\n\\pi_\\text{A} + \\pi_\\text{C} =& \\text{% yes in treatment; or} \\\\\n\\pi_\\text{C} =& \\text{% yes in treatment} - \\pi_\\text{A}\n\\end{aligned}\n\\]\nWe actually know \\(\\pi_\\text{A}\\)—remember in the graph above that the people who were in the control group and who used bed nets are guaranteed to be always takers (none of them are compliers or never takers). If we assume that the proportion of always takers is the same in both treatment and control, we can use that percent here, giving us this final equation for \\(\\pi_\\text{C}\\):\n\\[\n\\begin{aligned}\n\\pi_\\text{C} =& \\text{% yes in treatment} - \\pi_\\text{A} \\\\\n=& \\text{% yes in treatment} - \\text{% yes in control}\n\\end{aligned}\n\\]\nSo, if we can find the percent of people assigned to treatment who used bed nets, find the percent of people assigned to control and used bed nets, and subtract the two percentages, we’ll have the proportion of compliers, or \\(\\pi_\\text{C}\\). We can do that with the data we have (61% - 19.5% = 41.5% compliers):\n\n\nCode\nbed_nets %&gt;%\n  group_by(treatment, bed_net) %&gt;%\n  summarize(n = n()) %&gt;%\n  mutate(prop = n / sum(n))\n## # A tibble: 4 × 4\n## # Groups:   treatment [2]\n##   treatment bed_net        n  prop\n##   &lt;chr&gt;     &lt;fct&gt;      &lt;int&gt; &lt;dbl&gt;\n## 1 Control   No bed net   808 0.805\n## 2 Control   Bed net      196 0.195\n## 3 Treatment No bed net   388 0.390\n## 4 Treatment Bed net      608 0.610\n\n# pi_c = prop yes in treatment - prop yes in control\npi_c &lt;- 0.6104418 - 0.1952191\n\n\nFinally, now that we know both the ITT and \\(\\pi_\\text{C}\\), we can find the CACE (or the LATE):\n\n\nCode\nCACE &lt;- ITT / pi_c\nCACE\n## [1] 14.43\n\n\nIt’s 14.4, which means that using bed nets increased health by 14 health points for compliers (which is a lot bigger than the 6 that we found before). We successfully filtered out the always takers and the never takers, and we have our complier-specific causal effect."
  },
  {
    "objectID": "example/cace.html#finding-the-cacelate-with-iv2sls",
    "href": "example/cace.html#finding-the-cacelate-with-iv2sls",
    "title": "Complier average treatment effects",
    "section": "Finding the CACE/LATE with IV/2SLS",
    "text": "Finding the CACE/LATE with IV/2SLS\nDoing that is super tedious though! What if there was an easier way to find the effect of the bed net program for just the compliers? We can do this with IV/2SLS regression by using assignment to treatment as an instrument.\nAssignment to treatment works as an instrument because it’s (1) relevant, since being told to use bed nets is probably highly correlated with using bed nets, (2) exclusive, since the only way that being told to use bed nets can cause changes in health is through the actual use of the bed nets, and (3) exogenous, since being told to use bed nets probably isn’t related to other things that cause health.\nHere’s a 2SLS regression with assignment to treatment as the instrument:\n\n\nCode\nmodel_2sls &lt;- iv_robust(health ~ bed_net | treatment, data = bed_nets)\ntidy(model_2sls)\n##             term estimate std.error statistic   p.value conf.low conf.high   df outcome\n## 1    (Intercept)    38.12    0.5151     74.01 0.000e+00    37.11     39.13 1998  health\n## 2 bed_netBed net    14.43    1.2538     11.51 1.038e-29    11.97     16.89 1998  health\n\n\nThe coefficient for bed_net is identical to the CACE that we found manually! Instrumental variables are helpful for isolated program effects to only compliers when you’re dealing with noncompliance."
  },
  {
    "objectID": "herramientas/01-content.html",
    "href": "herramientas/01-content.html",
    "title": "Github",
    "section": "",
    "text": "Github es una plataforma de desarrollo colaborativo que permite alojar proyectos utilizando el sistema de control de versiones Git. Se utiliza principalmente para la creación de código fuente de programas (software).\n\n\n\n\n\n\nNota\n\n\n\nEl 4 de junio de 2018 Microsoft compró GitHub por la cantidad de 7500 millones de dólares. Al inicio, el cambio de propietario generó preocupaciones y la salida de algunos proyectos de este sitio; sin embargo, no fueron representativos. GitHub continúa siendo la plataforma más importante de colaboración para proyectos de código abierto.\n\n\n\n\n\nUn repositorio contiene todo el código, tus archivos y el historial de revisiones y cambios de cada uno de ellos. Es el elemento más básico de Github.\nLos repositorios pueden contar con múltiples colaboradores y pueden ser públicos o privados.\n\n\n\n\n\n\n\n\n\n\nTérmino\nDefinición\n\n\n\n\nBranch\nUna versión paralela del código contenido en el repositorio, pero que no afecta a la rama principal.\n\n\nClonar\nPara descargar una copia completa de los datos de un repositorio de GitHub.com, incluidas todas las versiones de cada archivo y carpeta.\n\n\nFork\nUn nuevo repositorio que comparte la configuración de visibilidad y código con el repositorio «ascendente» original.\n\n\nMerge\nPara aplicar los cambios de una rama y en otra.\n\n\nPull request\nUna solicitud para combinar los cambios de una branch en otra.\n\n\nRemote\nUn repositorio almacenado en GitHub, no en el equipo.\n\n\nUpstream\nLa branch de un repositorio original que se ha forkeado o clonado. La branch correspondiente de la branch clonada o forkeada se denomina «descendente».\n\n\n\n\n\n\n\nAcceder a la página de github\n\nRegistrarse ingresando correo electrónico y siguiendo los pasos siguientes (crear contraseña y nombre de usuario)\n\nLa personalización de la cuenta se puede saltar haciendo click en skip abajo de la selección de opciones\n\nDescargar e instalar Github Desktop\n\n\n\n\n\nEn la página principal de github hacer click en el ícono de usuario de la esquina superior derecha y luego ir a Tus repositorios\n\nUna vez accedemos a Tus repositorios hacemos click en New/Nuevo\n\nLuego le ponemos un nombre a nuestro repositorio, evitando siempre espacios, ñ y tíldes, y apretamos Crear repositorio\n\n\n\n\nUna vez creado un repositorio, lo que nos interesa es descargarlo. Al abrir la aplicación de Github desktop por primera vez (descargada anteriormente), nos debería aparecer la opción de clonar nuestro repositorio R-data-analisis en la pantalla de inicio. Lo clonamos y seleccionamos una carpeta de nuestro computador para almacenarlo.\nPara todas las siguientes veces, las instrucciones son estas:\n1- Apretamos Repositorio actual en la esquina superior izquierda\n2- Apretamos añadir\n3- Apretamos clonar repositorio…\n\n4- Seleccionamos nuestro repositorio\n5- seleccionamos la carpeta donde se almacenará. Siempre evitando tener tíldes, ñ y espacios en la dirección de almacenamiento.",
    "crumbs": [
      "Herramientas",
      "Github"
    ]
  },
  {
    "objectID": "herramientas/01-content.html#descripción",
    "href": "herramientas/01-content.html#descripción",
    "title": "Github",
    "section": "",
    "text": "Github es una plataforma de desarrollo colaborativo que permite alojar proyectos utilizando el sistema de control de versiones Git. Se utiliza principalmente para la creación de código fuente de programas (software).\n\n\n\n\n\n\nNota\n\n\n\nEl 4 de junio de 2018 Microsoft compró GitHub por la cantidad de 7500 millones de dólares. Al inicio, el cambio de propietario generó preocupaciones y la salida de algunos proyectos de este sitio; sin embargo, no fueron representativos. GitHub continúa siendo la plataforma más importante de colaboración para proyectos de código abierto.",
    "crumbs": [
      "Herramientas",
      "Github"
    ]
  },
  {
    "objectID": "herramientas/01-content.html#repositorios",
    "href": "herramientas/01-content.html#repositorios",
    "title": "Github",
    "section": "",
    "text": "Un repositorio contiene todo el código, tus archivos y el historial de revisiones y cambios de cada uno de ellos. Es el elemento más básico de Github.\nLos repositorios pueden contar con múltiples colaboradores y pueden ser públicos o privados.",
    "crumbs": [
      "Herramientas",
      "Github"
    ]
  },
  {
    "objectID": "herramientas/01-content.html#principales-términos",
    "href": "herramientas/01-content.html#principales-términos",
    "title": "Github",
    "section": "",
    "text": "Término\nDefinición\n\n\n\n\nBranch\nUna versión paralela del código contenido en el repositorio, pero que no afecta a la rama principal.\n\n\nClonar\nPara descargar una copia completa de los datos de un repositorio de GitHub.com, incluidas todas las versiones de cada archivo y carpeta.\n\n\nFork\nUn nuevo repositorio que comparte la configuración de visibilidad y código con el repositorio «ascendente» original.\n\n\nMerge\nPara aplicar los cambios de una rama y en otra.\n\n\nPull request\nUna solicitud para combinar los cambios de una branch en otra.\n\n\nRemote\nUn repositorio almacenado en GitHub, no en el equipo.\n\n\nUpstream\nLa branch de un repositorio original que se ha forkeado o clonado. La branch correspondiente de la branch clonada o forkeada se denomina «descendente».",
    "crumbs": [
      "Herramientas",
      "Github"
    ]
  },
  {
    "objectID": "herramientas/01-content.html#crear-cuenta-e-instalación",
    "href": "herramientas/01-content.html#crear-cuenta-e-instalación",
    "title": "Github",
    "section": "",
    "text": "Acceder a la página de github\n\nRegistrarse ingresando correo electrónico y siguiendo los pasos siguientes (crear contraseña y nombre de usuario)\n\nLa personalización de la cuenta se puede saltar haciendo click en skip abajo de la selección de opciones\n\nDescargar e instalar Github Desktop",
    "crumbs": [
      "Herramientas",
      "Github"
    ]
  },
  {
    "objectID": "herramientas/01-content.html#crear-repositorio",
    "href": "herramientas/01-content.html#crear-repositorio",
    "title": "Github",
    "section": "",
    "text": "En la página principal de github hacer click en el ícono de usuario de la esquina superior derecha y luego ir a Tus repositorios\n\nUna vez accedemos a Tus repositorios hacemos click en New/Nuevo\n\nLuego le ponemos un nombre a nuestro repositorio, evitando siempre espacios, ñ y tíldes, y apretamos Crear repositorio",
    "crumbs": [
      "Herramientas",
      "Github"
    ]
  },
  {
    "objectID": "herramientas/01-content.html#github-desktop",
    "href": "herramientas/01-content.html#github-desktop",
    "title": "Github",
    "section": "",
    "text": "Una vez creado un repositorio, lo que nos interesa es descargarlo. Al abrir la aplicación de Github desktop por primera vez (descargada anteriormente), nos debería aparecer la opción de clonar nuestro repositorio R-data-analisis en la pantalla de inicio. Lo clonamos y seleccionamos una carpeta de nuestro computador para almacenarlo.\nPara todas las siguientes veces, las instrucciones son estas:\n1- Apretamos Repositorio actual en la esquina superior izquierda\n2- Apretamos añadir\n3- Apretamos clonar repositorio…\n\n4- Seleccionamos nuestro repositorio\n5- seleccionamos la carpeta donde se almacenará. Siempre evitando tener tíldes, ñ y espacios en la dirección de almacenamiento.",
    "crumbs": [
      "Herramientas",
      "Github"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "\n            R para análisis estadístico\n        ",
    "section": "",
    "text": "R para análisis estadístico\n        \n        \n            Departamento de Sociología - Facultad de Ciencias Sociales de la Universidad Alberto Hurtado\n        \n        \n            CSSOCIAL 6607-SOC1(1052) • Primer semestre 2024Departamento de SociologíaUniversidad Alberto Hurtado\n        \n    \n    \n      \n        \n        \n        \n      \n    \n\n\n\n\n\nEquipo docente\nProfesor\n\n   Kevin Carrasco\n   ?var:instructor.office\n   &lt;a href=“mailto:kevin.carrasco@ug.uchile.cl”&gt;\n\nAyudante\n\n   Javiera Wompner\n   &lt;a href=“mailto:Javiera.wompner@ug.uchile.cl”&gt;Javiera.wompner@ug.uchile.cl\n\n\n\nInformación del curso\n\n   Martes\n   Marzo 12 - Julio 15 2024\n   16:00 a 17:20 y 17:30 a 18:50\n   Sala E67"
  },
  {
    "objectID": "news/2023-08-14_infos.html",
    "href": "news/2023-08-14_infos.html",
    "title": "Informaciones de la semana",
    "section": "",
    "text": "← News\n\n\n\n\nActualizaciones sitio web:"
  },
  {
    "objectID": "practicos/01-content.html",
    "href": "practicos/01-content.html",
    "title": "Práctico 1. Aproximación inicial a R",
    "section": "",
    "text": "Esta práctica tiene dos objetivos: 1) Generar un primer acercamiento al uso de R y Rstudio, conociendo su interfaz y sus principales funcionalidades y 2) revisar algunos procedimientos básicos de la preparación de datos con R, que son necesarios para luego poder aplicar los contenidos más específicos de este curso.\n\n\n\n\nevitar uso de tilde, ñ, espacios y mayúsculas tanto en carpetas y archivos, así como también en los nombres de las variables\nal momento de hacer consultas sobre problemas en la ejecución del código, adjuntar la siguiente información:\n\n\nCódigo completo hasta que se produce el problema\nIndicar línea del código donde se produce el problema\nAdjuntar el resultado del output de la información de la sesión (sessionInfo())\n\n\n\n\nEn primer lugar vamos a abrir un archivo de R (script). Esto se puede hacer manualmente con File -&gt; new file -&gt; R script o directamente con ctrl + shift + N\nEsta es nuestra hoja de código, que utilizaremos para procesar bases de datos, modificar variables y crear tablas y gráficos.\n\n\nR puede ser una calculadora\n\n\nCódigo\n10 + 5 # ¿cuánto es 10 + 5?\n\n\n[1] 15\n\n\n\n\nCódigo\n10 * 5 # ¿cuánto es 10 * 5?\n\n\n[1] 50\n\n\nSe pueden crear objetos y asignarles valores\n\n\nCódigo\na &lt;- 28\nb &lt;- 8\n\na + b\n\n\n[1] 36\n\n\nO asignar operaciones a un objeto\n\n\nCódigo\nc &lt;- a + b\n\n\nSin embargo, la mayor parte del tiempo usamos funciones que ya existen en R\n\n\nCódigo\nsum(28,8)\n\n\n[1] 36\n\n\n\n\nCódigo\nround(10.14536) #aproximar\n\n\n[1] 10\n\n\nY muchas de estas funciones que utilizamos en R están contenidas en librerías o paquetes (packages)\n\n\n\nLa lógica de R es instalar librerías (solo 1 vez, con install.packages(\"librería\")), y luego cargarlas cada vez que es necesario usarlas (con library(librería)). El problema de esto es que a veces no se sabe claramente qué librerías están instaladas y cuales no, lo que va a arrojar error al cargarlas. Y, como sucede en R, existe una librería para solucionar este problema que se llama pacman (package manager). Lo que hace pacman es cargar la librería, y si no está instalada, la instala y la carga:\nPara utilizar la primera vez (si es que no está instalada):\n\n\nCódigo\ninstall.packages(\"pacman\")\n\n\nY en adelante, las librerías se cargan así  pacman::p_load(libreria1,libreria2,libreriaX) :\n\n\nCódigo\npacman::p_load(dplyr, guaguas, ggplot2)\n\n\nInstalling package into 'C:/Users/kevin/AppData/Local/R/win-library/4.4'\n(as 'lib' is unspecified)\n\n\nWarning: unable to access index for repository http://www.stats.ox.ac.uk/pub/RWin/bin/windows/contrib/4.4:\n  no fue posible abrir la URL 'http://www.stats.ox.ac.uk/pub/RWin/bin/windows/contrib/4.4/PACKAGES'\n\n\npackage 'guaguas' successfully unpacked and MD5 sums checked\n\nThe downloaded binary packages are in\n    C:\\Users\\kevin\\AppData\\Local\\Temp\\RtmpA9ayBc\\downloaded_packages\n\n\n\nguaguas installed\n\n\nPara esta sesión las librerías que vamos a utilizar son:\n\ndplyr: ajuste general de datos\nguaguas: Paquete que contiene los datos de nombres de guaguas (bebés) registrados en Chile entre 1920 y 2021 según el Registro Civil e Identificación\nggplot2: Visualización de datos\n\n\n\n\nAjustar espacio de trabajo\nPrevio a la carga de nuestra base de datos, se recomienda ejecutar los siguientes comandos:\n\n\nCódigo\nrm(list=ls())       # borrar todos los objetos en el espacio de trabajo\noptions(scipen=999) # valores sin notación científica\n\n\nLa función rm(list=ls()) permite comenzar con un espacio de trabajo (environment) vacío y sin otros objetos. Así también, la función options(scipen=999) desactiva la notación científica, es decir, veremos los valores numéricos con todos sus decimales.\nDatos\nCargamos la base de datos desde el paquete (para otras bases de datos se deben importar de otra forma, esto es solo como ejemplo)\n\n\nCódigo\nbase &lt;- guaguas\n\n\nConocemos las dimensiones de la base de datos\n\n\nCódigo\ndim(base)\n\n\n[1] 858782      5\n\n\nSon 858782 casos y 5 variables. Los nombres de estas variables son:\n\n\nCódigo\nnames(base)\n\n\n[1] \"anio\"       \"nombre\"     \"sexo\"       \"n\"          \"proporcion\"\n\n\nY la base se ve así:\n\n\nCódigo\nhead(base)\n\n\n# A tibble: 6 × 5\n   anio nombre sexo      n proporcion\n  &lt;dbl&gt; &lt;chr&gt;  &lt;chr&gt; &lt;dbl&gt;      &lt;dbl&gt;\n1  1920 María  F      2130     0.104 \n2  1920 José   M       984     0.0483\n3  1920 Juan   M       636     0.0312\n4  1920 Luis   M       631     0.0310\n5  1920 Rosa   F       426     0.0209\n6  1920 Ana    F       340     0.0167\n\n\nAhora probemos algunas funciones para seguir explorando la base\n\n\nCódigo\ntable(base$sexo)\n\n\n\n     F      I      M \n531038    318 327426 \n\n\nPodemos ver la cantidad de nombres “F” (femenino), “M” (masculino) e “I” (indefinido) inscritos entre 1920 y 2021.\nPueden buscar sus nombres y probar, utilizamos la funcion filter del paquete dplyr\n\n\nCódigo\nfilter(base, nombre==\"Kevin\")\n\n\n# A tibble: 63 × 5\n    anio nombre sexo      n proporcion\n   &lt;dbl&gt; &lt;chr&gt;  &lt;chr&gt; &lt;dbl&gt;      &lt;dbl&gt;\n 1  1931 Kevin  M         1 0.0000120 \n 2  1963 Kevin  M         1 0.0000035 \n 3  1964 Kevin  M         1 0.00000344\n 4  1967 Kevin  M         4 0.0000131 \n 5  1970 Kevin  M         6 0.0000210 \n 6  1971 Kevin  M         3 0.00000936\n 7  1972 Kevin  M         3 0.00000945\n 8  1973 Kevin  M         2 0.00000633\n 9  1974 Kevin  M         5 0.0000163 \n10  1976 Kevin  M         2 0.00000724\n# ℹ 53 more rows\n\n\nE incluso pueden ver la cantidad de personas con su nombre, en el mismo año que ustedes nacieron\n\n\nCódigo\nd &lt;- filter(base, nombre==\"Kevin\" & anio==1996)\nsum(d$n)\n\n\n[1] 1312\n\n\nAvanzando un poco más, podemos utilizar ggplot2 para hacer un gráfico de líneas que muestre la evolución en el tiempo\n\n\nCódigo\ndatos &lt;- filter(base, nombre==\"Kevin\")\nggplot(datos, aes(x = anio, y = n)) +\n  geom_line() + \n  labs(x = \"Año\", y = \"Número de personas\", title = \"Número de personas llamadas Kevin por año\")\n\n\n\n\n\n\n\n\n\n¿Qué puede explicar el peak de “Kevins” previo a los 2000?\nspoiler: link\n\n\n\n\n\n\nCódigo\nguaguas %&gt;% \n  filter(nombre %in% c(\"Salvador\", \"Augusto\"), anio &gt;= 1960 & anio &lt;= 1979) %&gt;% \n  ggplot(aes(anio, n, color = nombre)) + \n  geom_line() +\n  labs(x = \"año\", y = \"total inscripciones\", color = \"nombre\", \n       title = \"Inscripciones de 'Salvador' y 'Augusto' entre 1960 - 1979\")",
    "crumbs": [
      "Prácticos",
      "Talleres",
      "01: Práctico 1"
    ]
  },
  {
    "objectID": "practicos/01-content.html#objetivos-de-la-práctica",
    "href": "practicos/01-content.html#objetivos-de-la-práctica",
    "title": "Práctico 1. Aproximación inicial a R",
    "section": "",
    "text": "Esta práctica tiene dos objetivos: 1) Generar un primer acercamiento al uso de R y Rstudio, conociendo su interfaz y sus principales funcionalidades y 2) revisar algunos procedimientos básicos de la preparación de datos con R, que son necesarios para luego poder aplicar los contenidos más específicos de este curso.",
    "crumbs": [
      "Prácticos",
      "Talleres",
      "01: Práctico 1"
    ]
  },
  {
    "objectID": "practicos/01-content.html#recomendaciones-generales",
    "href": "practicos/01-content.html#recomendaciones-generales",
    "title": "Práctico 1. Aproximación inicial a R",
    "section": "",
    "text": "evitar uso de tilde, ñ, espacios y mayúsculas tanto en carpetas y archivos, así como también en los nombres de las variables\nal momento de hacer consultas sobre problemas en la ejecución del código, adjuntar la siguiente información:\n\n\nCódigo completo hasta que se produce el problema\nIndicar línea del código donde se produce el problema\nAdjuntar el resultado del output de la información de la sesión (sessionInfo())",
    "crumbs": [
      "Prácticos",
      "Talleres",
      "01: Práctico 1"
    ]
  },
  {
    "objectID": "practicos/01-content.html#primeros-pasos",
    "href": "practicos/01-content.html#primeros-pasos",
    "title": "Práctico 1. Aproximación inicial a R",
    "section": "",
    "text": "En primer lugar vamos a abrir un archivo de R (script). Esto se puede hacer manualmente con File -&gt; new file -&gt; R script o directamente con ctrl + shift + N\nEsta es nuestra hoja de código, que utilizaremos para procesar bases de datos, modificar variables y crear tablas y gráficos.\n\n\nR puede ser una calculadora\n\n\nCódigo\n10 + 5 # ¿cuánto es 10 + 5?\n\n\n[1] 15\n\n\n\n\nCódigo\n10 * 5 # ¿cuánto es 10 * 5?\n\n\n[1] 50\n\n\nSe pueden crear objetos y asignarles valores\n\n\nCódigo\na &lt;- 28\nb &lt;- 8\n\na + b\n\n\n[1] 36\n\n\nO asignar operaciones a un objeto\n\n\nCódigo\nc &lt;- a + b\n\n\nSin embargo, la mayor parte del tiempo usamos funciones que ya existen en R\n\n\nCódigo\nsum(28,8)\n\n\n[1] 36\n\n\n\n\nCódigo\nround(10.14536) #aproximar\n\n\n[1] 10\n\n\nY muchas de estas funciones que utilizamos en R están contenidas en librerías o paquetes (packages)\n\n\n\nLa lógica de R es instalar librerías (solo 1 vez, con install.packages(\"librería\")), y luego cargarlas cada vez que es necesario usarlas (con library(librería)). El problema de esto es que a veces no se sabe claramente qué librerías están instaladas y cuales no, lo que va a arrojar error al cargarlas. Y, como sucede en R, existe una librería para solucionar este problema que se llama pacman (package manager). Lo que hace pacman es cargar la librería, y si no está instalada, la instala y la carga:\nPara utilizar la primera vez (si es que no está instalada):\n\n\nCódigo\ninstall.packages(\"pacman\")\n\n\nY en adelante, las librerías se cargan así  pacman::p_load(libreria1,libreria2,libreriaX) :\n\n\nCódigo\npacman::p_load(dplyr, guaguas, ggplot2)\n\n\nInstalling package into 'C:/Users/kevin/AppData/Local/R/win-library/4.4'\n(as 'lib' is unspecified)\n\n\nWarning: unable to access index for repository http://www.stats.ox.ac.uk/pub/RWin/bin/windows/contrib/4.4:\n  no fue posible abrir la URL 'http://www.stats.ox.ac.uk/pub/RWin/bin/windows/contrib/4.4/PACKAGES'\n\n\npackage 'guaguas' successfully unpacked and MD5 sums checked\n\nThe downloaded binary packages are in\n    C:\\Users\\kevin\\AppData\\Local\\Temp\\RtmpA9ayBc\\downloaded_packages\n\n\n\nguaguas installed\n\n\nPara esta sesión las librerías que vamos a utilizar son:\n\ndplyr: ajuste general de datos\nguaguas: Paquete que contiene los datos de nombres de guaguas (bebés) registrados en Chile entre 1920 y 2021 según el Registro Civil e Identificación\nggplot2: Visualización de datos\n\n\n\n\nAjustar espacio de trabajo\nPrevio a la carga de nuestra base de datos, se recomienda ejecutar los siguientes comandos:\n\n\nCódigo\nrm(list=ls())       # borrar todos los objetos en el espacio de trabajo\noptions(scipen=999) # valores sin notación científica\n\n\nLa función rm(list=ls()) permite comenzar con un espacio de trabajo (environment) vacío y sin otros objetos. Así también, la función options(scipen=999) desactiva la notación científica, es decir, veremos los valores numéricos con todos sus decimales.\nDatos\nCargamos la base de datos desde el paquete (para otras bases de datos se deben importar de otra forma, esto es solo como ejemplo)\n\n\nCódigo\nbase &lt;- guaguas\n\n\nConocemos las dimensiones de la base de datos\n\n\nCódigo\ndim(base)\n\n\n[1] 858782      5\n\n\nSon 858782 casos y 5 variables. Los nombres de estas variables son:\n\n\nCódigo\nnames(base)\n\n\n[1] \"anio\"       \"nombre\"     \"sexo\"       \"n\"          \"proporcion\"\n\n\nY la base se ve así:\n\n\nCódigo\nhead(base)\n\n\n# A tibble: 6 × 5\n   anio nombre sexo      n proporcion\n  &lt;dbl&gt; &lt;chr&gt;  &lt;chr&gt; &lt;dbl&gt;      &lt;dbl&gt;\n1  1920 María  F      2130     0.104 \n2  1920 José   M       984     0.0483\n3  1920 Juan   M       636     0.0312\n4  1920 Luis   M       631     0.0310\n5  1920 Rosa   F       426     0.0209\n6  1920 Ana    F       340     0.0167\n\n\nAhora probemos algunas funciones para seguir explorando la base\n\n\nCódigo\ntable(base$sexo)\n\n\n\n     F      I      M \n531038    318 327426 \n\n\nPodemos ver la cantidad de nombres “F” (femenino), “M” (masculino) e “I” (indefinido) inscritos entre 1920 y 2021.\nPueden buscar sus nombres y probar, utilizamos la funcion filter del paquete dplyr\n\n\nCódigo\nfilter(base, nombre==\"Kevin\")\n\n\n# A tibble: 63 × 5\n    anio nombre sexo      n proporcion\n   &lt;dbl&gt; &lt;chr&gt;  &lt;chr&gt; &lt;dbl&gt;      &lt;dbl&gt;\n 1  1931 Kevin  M         1 0.0000120 \n 2  1963 Kevin  M         1 0.0000035 \n 3  1964 Kevin  M         1 0.00000344\n 4  1967 Kevin  M         4 0.0000131 \n 5  1970 Kevin  M         6 0.0000210 \n 6  1971 Kevin  M         3 0.00000936\n 7  1972 Kevin  M         3 0.00000945\n 8  1973 Kevin  M         2 0.00000633\n 9  1974 Kevin  M         5 0.0000163 \n10  1976 Kevin  M         2 0.00000724\n# ℹ 53 more rows\n\n\nE incluso pueden ver la cantidad de personas con su nombre, en el mismo año que ustedes nacieron\n\n\nCódigo\nd &lt;- filter(base, nombre==\"Kevin\" & anio==1996)\nsum(d$n)\n\n\n[1] 1312\n\n\nAvanzando un poco más, podemos utilizar ggplot2 para hacer un gráfico de líneas que muestre la evolución en el tiempo\n\n\nCódigo\ndatos &lt;- filter(base, nombre==\"Kevin\")\nggplot(datos, aes(x = anio, y = n)) +\n  geom_line() + \n  labs(x = \"Año\", y = \"Número de personas\", title = \"Número de personas llamadas Kevin por año\")\n\n\n\n\n\n\n\n\n\n¿Qué puede explicar el peak de “Kevins” previo a los 2000?\nspoiler: link",
    "crumbs": [
      "Prácticos",
      "Talleres",
      "01: Práctico 1"
    ]
  },
  {
    "objectID": "practicos/01-content.html#otro-ejemplo",
    "href": "practicos/01-content.html#otro-ejemplo",
    "title": "Práctico 1. Aproximación inicial a R",
    "section": "",
    "text": "Código\nguaguas %&gt;% \n  filter(nombre %in% c(\"Salvador\", \"Augusto\"), anio &gt;= 1960 & anio &lt;= 1979) %&gt;% \n  ggplot(aes(anio, n, color = nombre)) + \n  geom_line() +\n  labs(x = \"año\", y = \"total inscripciones\", color = \"nombre\", \n       title = \"Inscripciones de 'Salvador' y 'Augusto' entre 1960 - 1979\")",
    "crumbs": [
      "Prácticos",
      "Talleres",
      "01: Práctico 1"
    ]
  },
  {
    "objectID": "practicos/01-content.html#rproject",
    "href": "practicos/01-content.html#rproject",
    "title": "Práctico 1. Aproximación inicial a R",
    "section": "Rproject",
    "text": "Rproject\nUn Rproject es una herramienta de R que nos permite establecer un directorio de trabajo en una carpeta de nuestro computador. Al hacerlo, establecemos un espacio de trabajo que permite crear una estructura de carpetas donde guardar los documentos asociados al proyecto. De esta forma, creamos un conjunto de archivos autocontenidos en un solo lugar que nos permite organizar nuestro trabajo y facilitar la reproducibilidad. En las próximas sesiones estableceremos un protocolo de trabajo que permite organizar y armonizar el trabajo: el protocolo IPO.\nPara crear un Rproject:\n\nAbrir Rstudio\nSeleccionar Archivo -&gt; Nuevo proyecto\n\n\n\nSeleccionamos la opción de directorio existente\nSeleccionamos la carpeta donde descargamos nuestro repositorio de Github en el paso anterior\nApretamos el botón de crear proyecto",
    "crumbs": [
      "Prácticos",
      "Talleres",
      "01: Práctico 1"
    ]
  },
  {
    "objectID": "practicos/03-content.html",
    "href": "practicos/03-content.html",
    "title": "Práctico 3. Operacionalización de variables",
    "section": "",
    "text": "El desarrollo de esta guía tiene por objetivo revisar algunos procedimientos básicos de la preparación de datos con R, que son necesarios para luego poder analizar e interpretar los datos.\nPor temas de orden y reproducibilidad, en este curso vamos a separar en dos momentos el trabajo con datos, y dos archivos de código correspondientes:\n\nPreparación corresponde a lo que se conoce generalmente como “limpieza”, es decir, realizar las modificaciones necesarias para poder efectuar los análisis. Estas modificaciones previas al análisis son necesarias ya que los datos originales con los que se va a trabajar en general no vienen perfectamente adaptados a los análisis que se quieren hacer. Por lo tanto, en cuanto a datos también hacemos la distinción entre datos originales y datos preparados (o procesados).\nAnálisis: se relaciona tanto con análisis descriptivos asociados a las preguntas de investigación y como también modelamiento de datos para contrastar hipótesis de investigación.\n\n\n\n\nTanto la preparación como el análisis (que son parte del concepto más general de procesamiento) quedan registrados cada uno en un archivo de código.\nArchivo de código R: archivo con extensión .R donde se almacena el código de análisis. Para generarlo desde RStudio: File &gt; New File &gt; R Script (o ctrl+shift+N), y para grabarlo File &gt; Save (o ctrl+s), y darle nombre la primera vez (recordar: sin tilde ni ñ, y evitar espacios) \nEl documento de código de preparación posee 5 partes, más una sección de identificación inicial:\n\nIdentificación y descripción general: Título, autor(es), fecha, información breve sobre el contenido del documento\nLibrerías: cargar librerías a utilizar\nDatos: carga de datos\nSelección de variables a utilizar\nProcesamiento de variables: en este punto, por cada variable se realiza lo siguiente:\n\nDescriptivo básico\nRecodificación: datos perdidos y valores (en caso de ser necesario)\nEtiquetamiento: de variable y valores (en caso de ser necesario)\nOtros ajustes\n\nGeneración de base de datos preparada para el análisis.\n\n\nDe rutas, estructura de carpetas y otros \n\nEncontrando la ruta a carpeta local: lo más fácil es crear la carpeta donde se desean guardar los datos desde el administrador de archivos del computador. Luego, posicionarse con el cursor sobre la carpeta y seleccionar “Propiedades”, en la ventana emergente debería aparecer la ruta hacia la carpeta en “Ubicación”. Copiar esa ruta y agregar al final el nombre de la carpeta (separada por slash)\nSobre los “slashes” (\\ o /): en la ruta las carpetas y el archivo final aparecen separados por slashes, que según el sistema utilizado pueden ser slash (/) o backslash (\\). En R por defecto se usa slash, pero en Windows backslash, por lo que si se usa Windows hay que reemplazarlos por backslash o también puede ser por un doble slash (//).\nPor temas de compatibilidad general, en las rutas se recomienda evitar tildes, eñes, espacios, mayúsculas y guiones bajos (_).\nEstructura de carpetas: para mantener el orden se sugiere seguir un protocolo de estructura de carpetas de proyecto, para lo que recomendamos el protocolo IPO, y que se adapta al flujo de trabajo presentado anteriormente. Básicamente son tres carpetas: input, procesamiento, output. En la carpeta input crear la subcarpeta data-orig para guardar datos originales, y data-proc para los procesados. En procesamiento se guardan los archivos de código y en output las tablas y los gráficos.\n\n\n\n\n\n\n\nAl final de esta práctica la idea es que cada un_ elabore y entienda su propio documento de preparación de datos.\nEn el ejemplo vamos a procesar variables de confianza en instituciones políticas y variables de caracterización sociodemográfica utilizando los datos de la encuesta Latinobarómetro .\n\n\n\n\nLatinobarómetro es un estudio de opinión pública que aplica anualmente alrededor de 20.000 entrevistas en 18 países de América Latina representando a más de 600 millones de habitantes\n“Los gobiernos latinoamericanos, que venían en declive junto con sus democracias desde inicios de la década de 2010, como reflejan los datos de Latinobarómetro, llegaron a fines de 2018 al annus horribilis con la caída de Nicaragua y Venezuela desde su condición de democracias para entrar en la categoría de autocracias y dictadura.\nDe los hiperpresidentes de la primera década del siglo con altos niveles de crecimiento en todos los países y altos niveles de aprobación, la región pasó en la segunda década a los subpresidentes, con una baja en aprobación de gobierno a la mitad, en menos de 10 años. Este rechazo al desempeño de las elites gobernantes, indica su fracaso a fines de 2019 en varios países de la región.” (Latinobarómetro, informe 2021, p. 7)\nEl presente ejercicio tiene por objetivo el procesar los datos para obtener las variables relevantes para el estudio de la Confianza en instituciones políticas, entendida como el grado en que los individuos confian en distintas instituciones políticas a nivel nacional, como el gobierno, la justicia, los partidos políticos, etc. Para ello, junto con variables de confianza, consideraremos también variables de estatus (educación), y variables de caracterización sociodemográfica (sexo y edad).",
    "crumbs": [
      "Prácticos",
      "Talleres",
      "03: Práctico 3"
    ]
  },
  {
    "objectID": "practicos/03-content.html#objetivo-de-la-práctica",
    "href": "practicos/03-content.html#objetivo-de-la-práctica",
    "title": "Práctico 3. Operacionalización de variables",
    "section": "",
    "text": "El desarrollo de esta guía tiene por objetivo revisar algunos procedimientos básicos de la preparación de datos con R, que son necesarios para luego poder analizar e interpretar los datos.\nPor temas de orden y reproducibilidad, en este curso vamos a separar en dos momentos el trabajo con datos, y dos archivos de código correspondientes:\n\nPreparación corresponde a lo que se conoce generalmente como “limpieza”, es decir, realizar las modificaciones necesarias para poder efectuar los análisis. Estas modificaciones previas al análisis son necesarias ya que los datos originales con los que se va a trabajar en general no vienen perfectamente adaptados a los análisis que se quieren hacer. Por lo tanto, en cuanto a datos también hacemos la distinción entre datos originales y datos preparados (o procesados).\nAnálisis: se relaciona tanto con análisis descriptivos asociados a las preguntas de investigación y como también modelamiento de datos para contrastar hipótesis de investigación.\n\n\n\n\nTanto la preparación como el análisis (que son parte del concepto más general de procesamiento) quedan registrados cada uno en un archivo de código.\nArchivo de código R: archivo con extensión .R donde se almacena el código de análisis. Para generarlo desde RStudio: File &gt; New File &gt; R Script (o ctrl+shift+N), y para grabarlo File &gt; Save (o ctrl+s), y darle nombre la primera vez (recordar: sin tilde ni ñ, y evitar espacios) \nEl documento de código de preparación posee 5 partes, más una sección de identificación inicial:\n\nIdentificación y descripción general: Título, autor(es), fecha, información breve sobre el contenido del documento\nLibrerías: cargar librerías a utilizar\nDatos: carga de datos\nSelección de variables a utilizar\nProcesamiento de variables: en este punto, por cada variable se realiza lo siguiente:\n\nDescriptivo básico\nRecodificación: datos perdidos y valores (en caso de ser necesario)\nEtiquetamiento: de variable y valores (en caso de ser necesario)\nOtros ajustes\n\nGeneración de base de datos preparada para el análisis.\n\n\nDe rutas, estructura de carpetas y otros \n\nEncontrando la ruta a carpeta local: lo más fácil es crear la carpeta donde se desean guardar los datos desde el administrador de archivos del computador. Luego, posicionarse con el cursor sobre la carpeta y seleccionar “Propiedades”, en la ventana emergente debería aparecer la ruta hacia la carpeta en “Ubicación”. Copiar esa ruta y agregar al final el nombre de la carpeta (separada por slash)\nSobre los “slashes” (\\ o /): en la ruta las carpetas y el archivo final aparecen separados por slashes, que según el sistema utilizado pueden ser slash (/) o backslash (\\). En R por defecto se usa slash, pero en Windows backslash, por lo que si se usa Windows hay que reemplazarlos por backslash o también puede ser por un doble slash (//).\nPor temas de compatibilidad general, en las rutas se recomienda evitar tildes, eñes, espacios, mayúsculas y guiones bajos (_).\nEstructura de carpetas: para mantener el orden se sugiere seguir un protocolo de estructura de carpetas de proyecto, para lo que recomendamos el protocolo IPO, y que se adapta al flujo de trabajo presentado anteriormente. Básicamente son tres carpetas: input, procesamiento, output. En la carpeta input crear la subcarpeta data-orig para guardar datos originales, y data-proc para los procesados. En procesamiento se guardan los archivos de código y en output las tablas y los gráficos.\n\n\n\n\n\n\n\nAl final de esta práctica la idea es que cada un_ elabore y entienda su propio documento de preparación de datos.\nEn el ejemplo vamos a procesar variables de confianza en instituciones políticas y variables de caracterización sociodemográfica utilizando los datos de la encuesta Latinobarómetro .",
    "crumbs": [
      "Prácticos",
      "Talleres",
      "03: Práctico 3"
    ]
  },
  {
    "objectID": "practicos/03-content.html#antecedentes-de-los-datos-a-utilizar",
    "href": "practicos/03-content.html#antecedentes-de-los-datos-a-utilizar",
    "title": "Práctico 3. Operacionalización de variables",
    "section": "",
    "text": "Latinobarómetro es un estudio de opinión pública que aplica anualmente alrededor de 20.000 entrevistas en 18 países de América Latina representando a más de 600 millones de habitantes\n“Los gobiernos latinoamericanos, que venían en declive junto con sus democracias desde inicios de la década de 2010, como reflejan los datos de Latinobarómetro, llegaron a fines de 2018 al annus horribilis con la caída de Nicaragua y Venezuela desde su condición de democracias para entrar en la categoría de autocracias y dictadura.\nDe los hiperpresidentes de la primera década del siglo con altos niveles de crecimiento en todos los países y altos niveles de aprobación, la región pasó en la segunda década a los subpresidentes, con una baja en aprobación de gobierno a la mitad, en menos de 10 años. Este rechazo al desempeño de las elites gobernantes, indica su fracaso a fines de 2019 en varios países de la región.” (Latinobarómetro, informe 2021, p. 7)\nEl presente ejercicio tiene por objetivo el procesar los datos para obtener las variables relevantes para el estudio de la Confianza en instituciones políticas, entendida como el grado en que los individuos confian en distintas instituciones políticas a nivel nacional, como el gobierno, la justicia, los partidos políticos, etc. Para ello, junto con variables de confianza, consideraremos también variables de estatus (educación), y variables de caracterización sociodemográfica (sexo y edad).",
    "crumbs": [
      "Prácticos",
      "Talleres",
      "03: Práctico 3"
    ]
  },
  {
    "objectID": "practicos/03-content.html#librerias",
    "href": "practicos/03-content.html#librerias",
    "title": "Práctico 3. Operacionalización de variables",
    "section": "1. Librerías principales (de R) a utilizar en el análisis",
    "text": "1. Librerías principales (de R) a utilizar en el análisis\nComo sabemos, la lógica de R es instalar librerías (solo 1 vez, con install.packages(\"librería\")), y luego cargarlas cada vez que es necesario usarlas (con library(librería)). El problema de esto es que a veces no se sabe claramente qué librerías están instaladas y cuales no, lo que va a arrojar error al cargarlas. Y, como sucede en R, existe una librería para solucionar este problema que se llama pacman (package manager). Lo que hace pacman es cargar la librería, y si no está instalada, la instala y la carga:\nPara utilizar la primera vez (si es que no está instalada):\n\n\nCódigo\ninstall.packages(\"pacman\")\n\n\nY en adelante, las librerías se cargan así  pacman::p_load(libreria1,libreria2,libreriaX) :\n\n\nCódigo\npacman::p_load(dplyr, sjmisc, car, sjlabelled, stargazer, haven)\n\n\nPara esta sesión vamos a utilizar Las librerías que vamos a utilizar son:\n\ndplyr: ajuste general de datos\nsjmisc: descripción y exploración de base de datos\ncar: principalmente la función recode para recodificar/agrupar valores de variable\nstargazer: para tabla descriptiva",
    "crumbs": [
      "Prácticos",
      "Talleres",
      "03: Práctico 3"
    ]
  },
  {
    "objectID": "practicos/03-content.html#cargar-base-de-datos",
    "href": "practicos/03-content.html#cargar-base-de-datos",
    "title": "Práctico 3. Operacionalización de variables",
    "section": "2. Cargar base de datos",
    "text": "2. Cargar base de datos\nAjustar espacio de trabajo\nPrevio a la carga de nuestra base de datos, se recomienda ejecutar los siguientes comandos:\n\n\nCódigo\nrm(list=ls())       # borrar todos los objetos en el espacio de trabajo\noptions(scipen=999) # valores sin notación científica\n\n\nLa función rm(list=ls()) permite comenzar con un espacio de trabajo (environment) vacío y sin otros objetos. Así también, la función options(scipen=999) desactiva la notación científica, es decir, veremos los valores numéricos con todos sus decimales.\nDatos\nLas bases de datos se pueden cargar de un archivo local o en línea. Para este caso utilizaremos un archivo en línea que viene en formato RData: latinobarometro2020.RData. Abrir bases de datos en otros formatos: Los formatos mas comunes en que se almacenan las bases de datos son .dta (Stata), .sav (Spss) y RData (R). Para abrir desde R utlilizamos la librería haven y sus funciones read_dta y read_sav según corresponda. Ej: datos &lt;- read_dta(\"base_casen.dta\"). Recordar antes instalar/cargar la librería: pacman::p_load(haven) \n\n\nCódigo\n#cargamos la base de datos desde internet\nload(url(\"https://github.com/Kevin-carrasco/metod1-MCS/raw/main/files/data/external_data/latinobarometro2020.RData\"))\n\n\no de manera local:\n\n\nCódigo\nlatinobarometro2020 &lt;- read_dta(\"../files/data/external_data/latinobarometro2020.dta\", encoding = \"UTF-8\")\n\n\nLa base de datos aparece como un objeto en nuestro espacio de trabajo, con el nombre original con la que fue guardada (latinobarometro2020):\n\nRealizamos un chequeo básico de la lectura de datos: nombres de las variables y tamaño de la base en términos de casos y variables (en este ejemplo, 20204, 408 ).\n\n\nCódigo\ndim(latinobarometro2020) # dimension de la base\n\n\n[1] 20204   408\n\n\nY si se quiere revisar en formato de planilla de datos:\n\n\nCódigo\nView(latinobarometro2020)",
    "crumbs": [
      "Prácticos",
      "Talleres",
      "03: Práctico 3"
    ]
  },
  {
    "objectID": "practicos/03-content.html#selección-de-variables-a-utilizar",
    "href": "practicos/03-content.html#selección-de-variables-a-utilizar",
    "title": "Práctico 3. Operacionalización de variables",
    "section": "3. Selección de variables a utilizar",
    "text": "3. Selección de variables a utilizar\nEste paso consiste en crear un subset reducido de datos que contenga solo las variables de interés. Para ello:\n\nSe identifica el nombre de las variables que registran la información de preguntas o items del instrumento: esto aparece en el libro de códigos y/o en el cuestionario, o también se puede hacer buscando en la base de datos mediante alguna palabra clave asociada a la pregunta. Por ejemplo, si queremos buscar variables asociadas a educación, utilizamos la función find_var (de sjmisc, librería que cargamos en el paso 1), que nos entrega nombre de la variable en columna var.name. Por ejemplo, si buscamos alguna variable asociada al concepto Confianza:\n\n\n\nCódigo\nfind_var(data = latinobarometro2020,\"Confianza\")\n\n\n   col.nr   var.name\n1      36    p9stgbs\n2      41 P13STGBS_A\n3      42 P13STGBS_B\n4      43    p13st_c\n5      44    p13st_d\n6      45    p13st_e\n7      46    p13st_f\n8      47    p13st_g\n9      48    p13st_h\n10     49    p13st_i\n11     51    p15st_a\n12     52    p15st_b\n13     53    p15st_c\n14     54    p15st_d\n15     55    p15st_e\n16     56    p15st_f\n17     57    p15st_g\n18     58     p15n_h\n19     59     p15n_i\n20     60     p15n_j\n21     61     p15n_k\n22    154     p36n_a\n23    155     p36n_b\n24    160  P36STMB_A\n25    161  P36STMB_B\n26    162  P36STMB_C\n27    163  P36STMB_D\n                                                                          var.label\n1                                                   P9STGBS Confianza Interpersonal\n2                                       P13STGBS.A Confianza en las Fuerzas Armadas\n3                                  P13STGBS.B Confianza en la Policía / Carabineros\n4                                                   P13ST.C Confianza en la Iglesia\n5                                                  P13ST.D Confianza en el Congreso\n6                                                  P13ST.E Confianza en el Gobierno\n7                                            P13ST.F Confianza en el Poder Judicial\n8                                       P13ST.G Confianza en los Partidos Políticos\n9                           P13ST.H Confianza en: La institución Electoral del país\n10                                              P13ST.I Confianza en: El presidente\n11 P15ST.A Confianza en que las instituciones operan para mejorar nuestra calidad d\n12 P15ST.B Confianza en que las instituciones operan para mejorar nuestra calidad d\n13 P15ST.C Confianza en que las instituciones operan para mejorar nuestra calidad d\n14 P15ST.D Confianza en que las instituciones operan para mejorar nuestra calidad d\n15 P15ST.E Confianza en que las instituciones operan para mejorar nuestra calidad d\n16 P15ST.F Confianza en que las instituciones operan para mejorar nuestra calidad d\n17 P15ST.G Confianza en que las instituciones operan para mejorar nuestra calidad d\n18 P15N.H Confianza en que las instituciones operan para mejorar nuestra calidad de\n19 P15N.I Confianza en que las instituciones operan para mejorar nuestra calidad de\n20 P15N.J Confianza en que las instituciones operan para mejorar nuestra calidad de\n21 P15N.K Confianza en que las instituciones operan para mejorar nuestra calidad de\n22                        P36N.A Confianza en las Fuerzas Armadas de Estados Unidos\n23                                   P36N.B Confianza en las fuerzas Armadas Chinas\n24                    P36STMB.A Confianza en el FMI (Fondo Monetario Internacional)\n25               P36STMB.B Confianza en el BID (Banco Interamericano de Desarrollo)\n26            P36STMB.C Confianza en el CAF (Banco de Desarrollo de América Latina)\n27                                          P36STMB.D Confianza en el Banco Mundial\n\n\nNos informa que hay una serie de variables relacionadas con confianza interpersonal y con instituciones. Probemos con la variable p13st_e.\nMediante la función select de dplyr, seleccionamos cada una de nuestras variables de interés y creamos una nueva base con el nombre proc_data, donde “proc” hace referencia a base procesada:\n\n\nCódigo\nproc_data &lt;- latinobarometro2020 %&gt;% select(p13st_e, # Confianza en el Gobierno\n                          p13st_d, # Confianza en el congreso\n                          p13st_f, # Confianza en el Poder Judicial\n                          p13st_g, # Confianza en los partidos políticos\n                          reeduc_1,# nivel educacional\n                          sexo,# sexo\n                          edad,# edad\n                          idenpa) # pais \n\n# Comprobar\nnames(proc_data)\n\n\n[1] \"p13st_e\"  \"p13st_d\"  \"p13st_f\"  \"p13st_g\"  \"reeduc_1\" \"sexo\"     \"edad\"    \n[8] \"idenpa\"  \n\n\nMediante el comando get_label obtenemos el atributo label de las variables.\n\n\nCódigo\nsjlabelled::get_label(proc_data)\n\n\n                                                             p13st_e \n                                  \"P13ST.E Confianza en el Gobierno\" \n                                                             p13st_d \n                                  \"P13ST.D Confianza en el Congreso\" \n                                                             p13st_f \n                            \"P13ST.F Confianza en el Poder Judicial\" \n                                                             p13st_g \n                       \"P13ST.G Confianza en los Partidos Políticos\" \n                                                            reeduc_1 \n\"REEDUC.1 Nivel de estudios alcanzado - Entrevistado (recodificado)\" \n                                                                sexo \n                                                         \"SEXO Sexo\" \n                                                                edad \n                                                         \"EDAD Edad\" \n                                                              idenpa \n                                    \"IDENPA Identificación del País\" \n\n\nPodemos ver que son largas o con códigos poco informativos, por lo tanto, es necesario cambiarlas por etiquetas más cortas y de fácil identificación.\nPara facilitar el análisis, vamos a filtrar la base de datos para quedarnos solo con los casos de Chile. Para esto utilizamos la función filter de dplyr. Si revisamos el libro de códigos, el identificador de Chile es 152\n\n\nCódigo\nproc_data &lt;- proc_data %&gt;% dplyr::filter(idenpa==152)",
    "crumbs": [
      "Prácticos",
      "Talleres",
      "03: Práctico 3"
    ]
  },
  {
    "objectID": "practicos/03-content.html#procesamiento-de-variables",
    "href": "practicos/03-content.html#procesamiento-de-variables",
    "title": "Práctico 3. Operacionalización de variables",
    "section": "4. Procesamiento de variables",
    "text": "4. Procesamiento de variables\nPara el procesamiento de cada variable se seguirá el siguiente flujo de trabajo:\n\nDescriptivo general\nRecodificación: de casos perdidos y otros valores (en caso necesario)\nEtiquetado: cambio de nombres de variables y valores (en caso necesario)\nOtros ajustes\n\nY se recomienda también un descriptivo final para revisar que el procesamiento de cada variable está ok.\n\n4.1 Confianza en el Gobierno\nEn Latinobarómetro, lass variables que permiten medir la Confianza en instituciones políticas en Chile son las siguientes:\n\n[p13st_e]: “P13ST.E Confianza en el Gobierno” (1 = Mucha; 4 = Ninguna)\n[p13st_d]: “P13ST.D Confianza en el Congreso” (1 = Mucha; 4 = Ninguna)\n[p13st_f]: “P13ST.F Confianza en el Poder Judicial” (1 = Mucha; 4 = Ninguna)\n[p13st_g]: “P13ST.G Confianza en los Partidos Políticos” (1 = Mucha; 4 = Ninguna)\n\na. Descriptivo\nPara los descriptivos se utilizará la función frq, de la librería sjmisc:\n\n\nCódigo\nfrq(proc_data$p13st_e)\n\n\nx &lt;numeric&gt; \n# total N=1200 valid N=1200 mean=3.27 sd=0.99\n\nValue |   N | Raw % | Valid % | Cum. %\n--------------------------------------\n   -2 |   8 |  0.67 |    0.67 |   0.67\n   -1 |  11 |  0.92 |    0.92 |   1.58\n    1 |  23 |  1.92 |    1.92 |   3.50\n    2 | 176 | 14.67 |   14.67 |  18.17\n    3 | 358 | 29.83 |   29.83 |  48.00\n    4 | 624 | 52.00 |   52.00 | 100.00\n &lt;NA&gt; |   0 |  0.00 |    &lt;NA&gt; |   &lt;NA&gt;\n\n\nEn esta variable vemos valores asociados a la opción “No contesta” (-2) y “No sabe” (-1), que corresponde definirlos como casos perdidos (en el caso de R, como casos NA). El resto de los valores y etiquetas se encuentran en un orden contraintuitivo (mayor valor indica menos confianza), así que en la recodificiación nos haremos cargo de los casos perdidos y de reordenar las categorías.\nb. Recodificación\nPara recodificar utilizamos la función recode, de la librería car\n\n\nCódigo\nproc_data$p13st_e &lt;- recode(proc_data$p13st_e, \"c(-2,-1)=NA\")\nproc_data$p13st_d &lt;- recode(proc_data$p13st_d, \"c(-2,-1)=NA\")\nproc_data$p13st_f &lt;- recode(proc_data$p13st_f, \"c(-2,-1)=NA\")\nproc_data$p13st_g &lt;- recode(proc_data$p13st_g, \"c(-2,-1)=NA\")\n\n\nnota: con la función set_na de la librería sjmisc podemos recodificar toda la base de datos con un solo código, pero debemos estar completamente segur-s de que estos valores no tienen otra categoría asociada en otra variable.\n\n\nCódigo\nproc_data &lt;- proc_data %&gt;% set_na(., na = c(-2, -1))\n\n\nPara reordenar las categorías volvemos a utilizar la función recode, de la librería car\n\n\nCódigo\nproc_data$p13st_e &lt;- recode(proc_data$p13st_e, \"1=3; 2=2; 3=1; 4=0\")\nproc_data$p13st_d &lt;- recode(proc_data$p13st_d, \"1=3; 2=2; 3=1; 4=0\")\nproc_data$p13st_f &lt;- recode(proc_data$p13st_f, \"1=3; 2=2; 3=1; 4=0\")\nproc_data$p13st_g &lt;- recode(proc_data$p13st_g, \"1=3; 2=2; 3=1; 4=0\")\n\n\nc - Etiquetado\nVamos a dar un nombre más sustantivo a las variables con la función rename, de la librería dplyr:\n\n\nCódigo\nproc_data &lt;- proc_data %&gt;% rename(\"conf_gob\"=p13st_e, # Confianza en el gobierno\n                                  \"conf_cong\"=p13st_d, # Confianza en el congreso\n                                  \"conf_jud\"=p13st_f, # Confianza en el Poder Judicial\n                                  \"conf_partpol\"=p13st_g) # Confianza en los partidos políticos \n\n\nAdemás de cambiar el nombre, queremos cambiar las etiquetas de las variables.\n\n\nCódigo\nproc_data$conf_gob &lt;- set_label(x = proc_data$conf_gob,label = \"Confianza: Gobierno\")\nget_label(proc_data$conf_gob)\n\n\n[1] \"Confianza: Gobierno\"\n\n\nCódigo\nproc_data$conf_cong  &lt;- set_label(x = proc_data$conf_cong, label = \"Confianza: Congreso\")\nget_label(proc_data$conf_cong)\n\n\n[1] \"Confianza: Congreso\"\n\n\nCódigo\nproc_data$conf_jud  &lt;- set_label(x = proc_data$conf_jud, label = \"Confianza: Poder judicial\")\nget_label(proc_data$conf_jud)\n\n\n[1] \"Confianza: Poder judicial\"\n\n\nCódigo\nproc_data$conf_partpol  &lt;- set_label(x = proc_data$conf_partpol, label = \"Confianza: Partidos politicos\")\nget_label(proc_data$conf_partpol)\n\n\n[1] \"Confianza: Partidos politicos\"\n\n\nd. Otros ajustes\nPara este caso vamos a crear una variable que sea la suma de los cuatro items de confianza.\n\n\nCódigo\nproc_data$conf_inst &lt;- (proc_data$conf_gob+proc_data$conf_cong+proc_data$conf_jud+proc_data$conf_partpol)\nsummary(proc_data$conf_inst)\n\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n   0.00    0.00    2.00    2.42    4.00   12.00      38 \n\n\n\n\nCódigo\nget_label(proc_data$conf_inst)\n\n\n[1] \"Confianza: Gobierno\"\n\n\nVemos que una etiqueta de la variable anterior.\n\n\nCódigo\nproc_data$conf_inst  &lt;- set_label(x = proc_data$conf_inst, label = \"Confianza en instituciones\")\n\n\nRevisión final\nNuevamente un descriptivo de cada variable para confirmar que el procesamiento está ok:\n\n\nCódigo\nfrq(proc_data$conf_gob)\n\n\nConfianza: Gobierno (x) &lt;numeric&gt; \n# total N=1200 valid N=1181 mean=0.66 sd=0.80\n\nValue |   N | Raw % | Valid % | Cum. %\n--------------------------------------\n    0 | 624 | 52.00 |   52.84 |  52.84\n    1 | 358 | 29.83 |   30.31 |  83.15\n    2 | 176 | 14.67 |   14.90 |  98.05\n    3 |  23 |  1.92 |    1.95 | 100.00\n &lt;NA&gt; |  19 |  1.58 |    &lt;NA&gt; |   &lt;NA&gt;\n\n\nCódigo\nfrq(proc_data$conf_cong)\n\n\nConfianza: Congreso (x) &lt;numeric&gt; \n# total N=1200 valid N=1178 mean=0.59 sd=0.71\n\nValue |   N | Raw % | Valid % | Cum. %\n--------------------------------------\n    0 | 628 | 52.33 |   53.31 |  53.31\n    1 | 408 | 34.00 |   34.63 |  87.95\n    2 | 134 | 11.17 |   11.38 |  99.32\n    3 |   8 |  0.67 |    0.68 | 100.00\n &lt;NA&gt; |  22 |  1.83 |    &lt;NA&gt; |   &lt;NA&gt;\n\n\nCódigo\nfrq(proc_data$conf_inst)\n\n\nConfianza en instituciones (x) &lt;numeric&gt; \n# total N=1200 valid N=1162 mean=2.42 sd=2.49\n\nValue |   N | Raw % | Valid % | Cum. %\n--------------------------------------\n    0 | 397 | 33.08 |   34.17 |  34.17\n    1 | 141 | 11.75 |   12.13 |  46.30\n    2 | 130 | 10.83 |   11.19 |  57.49\n    3 | 111 |  9.25 |    9.55 |  67.04\n    4 | 169 | 14.08 |   14.54 |  81.58\n    5 |  71 |  5.92 |    6.11 |  87.69\n    6 |  41 |  3.42 |    3.53 |  91.22\n    7 |  41 |  3.42 |    3.53 |  94.75\n    8 |  44 |  3.67 |    3.79 |  98.54\n    9 |  11 |  0.92 |    0.95 |  99.48\n   10 |   4 |  0.33 |    0.34 |  99.83\n   11 |   1 |  0.08 |    0.09 |  99.91\n   12 |   1 |  0.08 |    0.09 | 100.00\n &lt;NA&gt; |  38 |  3.17 |    &lt;NA&gt; |   &lt;NA&gt;\n\n\nVemos que los valores (labels) de cada categoría de las primeras variables que recodificamos no se corresponden con el nuevo valor. Para re-etiquetar valores usamos la función set_labels, de la librería sjlabelled\n\n\nCódigo\nproc_data$conf_gob &lt;- set_labels(proc_data$conf_gob,\n            labels=c( \"Ninguna\"=0,\n                      \"Poca\"=1,\n                      \"Algo\"=2,\n                      \"Mucha\"=3))\n\nproc_data$conf_cong &lt;- set_labels(proc_data$conf_cong,\n            labels=c( \"Ninguna\"=0,\n                      \"Poca\"=1,\n                      \"Algo\"=2,\n                      \"Mucha\"=3))\n\nproc_data$conf_jud &lt;- set_labels(proc_data$conf_jud,\n            labels=c( \"Ninguna\"=0,\n                      \"Poca\"=1,\n                      \"Algo\"=2,\n                      \"Mucha\"=3))\n\nproc_data$conf_partpol &lt;- set_labels(proc_data$conf_partpol,\n            labels=c( \"Ninguna\"=0,\n                      \"Poca\"=1,\n                      \"Algo\"=2,\n                      \"Mucha\"=3))\n\n\ny volvemos a revisar\n\n\nCódigo\nfrq(proc_data$conf_gob)\n\n\nConfianza: Gobierno (x) &lt;numeric&gt; \n# total N=1200 valid N=1181 mean=0.66 sd=0.80\n\nValue |   Label |   N | Raw % | Valid % | Cum. %\n------------------------------------------------\n    0 | Ninguna | 624 | 52.00 |   52.84 |  52.84\n    1 |    Poca | 358 | 29.83 |   30.31 |  83.15\n    2 |    Algo | 176 | 14.67 |   14.90 |  98.05\n    3 |   Mucha |  23 |  1.92 |    1.95 | 100.00\n &lt;NA&gt; |    &lt;NA&gt; |  19 |  1.58 |    &lt;NA&gt; |   &lt;NA&gt;\n\n\nCódigo\nfrq(proc_data$conf_cong)\n\n\nConfianza: Congreso (x) &lt;numeric&gt; \n# total N=1200 valid N=1178 mean=0.59 sd=0.71\n\nValue |   Label |   N | Raw % | Valid % | Cum. %\n------------------------------------------------\n    0 | Ninguna | 628 | 52.33 |   53.31 |  53.31\n    1 |    Poca | 408 | 34.00 |   34.63 |  87.95\n    2 |    Algo | 134 | 11.17 |   11.38 |  99.32\n    3 |   Mucha |   8 |  0.67 |    0.68 | 100.00\n &lt;NA&gt; |    &lt;NA&gt; |  22 |  1.83 |    &lt;NA&gt; |   &lt;NA&gt;\n\n\n\n4.2. Educación\n\n[reeduc_1] = REEDUC.1 Nivel de estudios alcanzado - Entrevistado (recodificado)\n\na. Descriptivo\n\n\nCódigo\nfrq(proc_data$reeduc_1)\n\n\nx &lt;numeric&gt; \n# total N=1200 valid N=1200 mean=5.05 sd=1.22\n\nValue |   N | Raw % | Valid % | Cum. %\n--------------------------------------\n    1 |   8 |  0.67 |    0.67 |   0.67\n    2 |  53 |  4.42 |    4.42 |   5.08\n    3 |  36 |  3.00 |    3.00 |   8.08\n    4 | 161 | 13.42 |   13.42 |  21.50\n    5 | 643 | 53.58 |   53.58 |  75.08\n    6 | 109 |  9.08 |    9.08 |  84.17\n    7 | 190 | 15.83 |   15.83 | 100.00\n &lt;NA&gt; |   0 |  0.00 |    &lt;NA&gt; |   &lt;NA&gt;\n\n\nb. Recodificación\n\nVemos que no hay datos perdidos\nValores\n\nPara hacer más fácil el análisis, recodificamos en tres categorías (en este caso decisión arbitraria. Se debería tener una razón teórica para recodificar)\n1.  Analfabeto                                =   Educacion basica    =   1\n2   Básica incompleta                         =   Educacion basica    =   1\n3.  Básica completa                           =   Educacion basica    =   1\n4.  Secundaria, media, técnica incompleta     =   Educacion media     =   2\n5.  Secundaria, media, técnica completa       =   Educacion media     =   2\n6.  Superior incompleta                       =   Educacion superior  =   3\n7.  Superior completa                         =   Educacion superior  =   3\n\n\n\nCódigo\n# recodificacion usando funcion 'recode' de la libreria car\nproc_data$reeduc_1 &lt;- car::recode(proc_data$reeduc_1, \"c(1,2,3)=1; c(4,5)=2; c(6,7)=3\")\n\n\nComprobar con un nuevo descriptivo:\n\n\nCódigo\nfrq(proc_data$reeduc_1)\n\n\nx &lt;numeric&gt; \n# total N=1200 valid N=1200 mean=2.17 sd=0.55\n\nValue |   N | Raw % | Valid % | Cum. %\n--------------------------------------\n    1 |  97 |  8.08 |    8.08 |   8.08\n    2 | 804 | 67.00 |   67.00 |  75.08\n    3 | 299 | 24.92 |   24.92 | 100.00\n &lt;NA&gt; |   0 |  0.00 |    &lt;NA&gt; |   &lt;NA&gt;\n\n\nSe observa que los valores coinciden con la recodificación (los casos se acumulan entre las categorías 1 y 3), pero las etiquetas ahora no coinciden; se soluciona en el siguiente paso.\nc. Etiquetado\nPara re-etiquetar valores usamos la función factor, de R base. Con esta función aprovechamos de transformar la variable educación en una variable categórica, que es lo que corresponde para una variable ordinal.\n\n\nCódigo\nproc_data$reeduc_1 &lt;- factor(proc_data$reeduc_1,\n                             labels = c(\"Educacion basica\", \"Educacion media\", \"Educacion superior\"),\n                             levels = c(1, 2, 3))\n\n\nLuego renombramos la variable con un nombre más sustantivo\n\n\nCódigo\nproc_data &lt;- rename(proc_data,\"educacion\"=reeduc_1)\n\n\nAdemás de cambiar el nombre, queremos cambiar la etiqueta de la variable.\n\n\nCódigo\nget_label(proc_data$educacion)\n\n\nNULL\n\n\nCódigo\nproc_data$educacion &lt;- set_label(x = proc_data$educacion,label = \"Educación\")\n\n\n\n\n\n4.3. Sexo\n\n[sexo] = SEXO Sexo\n\na. Descriptivo\n\n\nCódigo\nfrq(proc_data$sexo)\n\n\nx &lt;numeric&gt; \n# total N=1200 valid N=1200 mean=1.54 sd=0.50\n\nValue |   N | Raw % | Valid % | Cum. %\n--------------------------------------\n    1 | 555 | 46.25 |   46.25 |  46.25\n    2 | 645 | 53.75 |   53.75 | 100.00\n &lt;NA&gt; |   0 |  0.00 |    &lt;NA&gt; |   &lt;NA&gt;\n\n\nb. Recodificación\nEn general esta variable no tiene problemas de casos perdidos ni de etiquetas, pero de todas maneras vamos a hacer un cambio de acuerdo a convenciones en análisis de datos, donde por lo general hombres tienen valor 0 y mujeres 1:\n\n\nCódigo\nproc_data$sexo &lt;- car::recode(proc_data$sexo, \"1=0;2=1\")\n\n\nc. Etiquetado\nY ahora cambiamos las etiquetas de acuerdo a la recodificación anterior:\n\n\nCódigo\nproc_data$sexo &lt;- factor(proc_data$sexo,\n            labels=c( \"Hombre\",\n                      \"Mujer\"),\n            levels=c(0,1))\n\n\nTambién queremos cambiar la etiqueta de la variable.\n\n\nCódigo\nget_label(proc_data$sexo)\n\n\nNULL\n\n\nCódigo\nproc_data$sexo &lt;- set_label(x = proc_data$sexo,label = \"Sexo\")\n\n\nRevisar con un nuevo descriptivo:\n\n\nCódigo\nfrq(proc_data$sexo)\n\n\nSexo (x) &lt;categorical&gt; \n# total N=1200 valid N=1200 mean=1.54 sd=0.50\n\nValue  |   N | Raw % | Valid % | Cum. %\n---------------------------------------\nHombre | 555 | 46.25 |   46.25 |  46.25\nMujer  | 645 | 53.75 |   53.75 | 100.00\n&lt;NA&gt;   |   0 |  0.00 |    &lt;NA&gt; |   &lt;NA&gt;\n\n\n\n\n4.4 Edad\n\n[edad] = EDAD Edad.\n\na. Descriptivo\n\n\nCódigo\nfrq(proc_data$edad)\n\n\nx &lt;numeric&gt; \n# total N=1200 valid N=1200 mean=44.49 sd=17.01\n\nValue |  N | Raw % | Valid % | Cum. %\n-------------------------------------\n   18 | 31 |  2.58 |    2.58 |   2.58\n   19 | 29 |  2.42 |    2.42 |   5.00\n   20 | 25 |  2.08 |    2.08 |   7.08\n   21 | 23 |  1.92 |    1.92 |   9.00\n   22 | 21 |  1.75 |    1.75 |  10.75\n   23 | 26 |  2.17 |    2.17 |  12.92\n   24 | 28 |  2.33 |    2.33 |  15.25\n   25 | 19 |  1.58 |    1.58 |  16.83\n   26 | 21 |  1.75 |    1.75 |  18.58\n   27 | 23 |  1.92 |    1.92 |  20.50\n   28 | 19 |  1.58 |    1.58 |  22.08\n   29 | 22 |  1.83 |    1.83 |  23.92\n   30 | 34 |  2.83 |    2.83 |  26.75\n   31 | 21 |  1.75 |    1.75 |  28.50\n   32 | 26 |  2.17 |    2.17 |  30.67\n   33 | 21 |  1.75 |    1.75 |  32.42\n   34 | 14 |  1.17 |    1.17 |  33.58\n   35 | 22 |  1.83 |    1.83 |  35.42\n   36 | 28 |  2.33 |    2.33 |  37.75\n   37 | 14 |  1.17 |    1.17 |  38.92\n   38 | 24 |  2.00 |    2.00 |  40.92\n   39 | 23 |  1.92 |    1.92 |  42.83\n   40 | 32 |  2.67 |    2.67 |  45.50\n   41 | 21 |  1.75 |    1.75 |  47.25\n   42 | 16 |  1.33 |    1.33 |  48.58\n   43 | 22 |  1.83 |    1.83 |  50.42\n   44 | 16 |  1.33 |    1.33 |  51.75\n   45 | 25 |  2.08 |    2.08 |  53.83\n   46 | 19 |  1.58 |    1.58 |  55.42\n   47 | 15 |  1.25 |    1.25 |  56.67\n   48 | 26 |  2.17 |    2.17 |  58.83\n   49 | 19 |  1.58 |    1.58 |  60.42\n   50 | 35 |  2.92 |    2.92 |  63.33\n   51 |  6 |  0.50 |    0.50 |  63.83\n   52 | 24 |  2.00 |    2.00 |  65.83\n   53 |  7 |  0.58 |    0.58 |  66.42\n   54 | 13 |  1.08 |    1.08 |  67.50\n   55 | 27 |  2.25 |    2.25 |  69.75\n   56 | 18 |  1.50 |    1.50 |  71.25\n   57 | 17 |  1.42 |    1.42 |  72.67\n   58 | 34 |  2.83 |    2.83 |  75.50\n   59 | 17 |  1.42 |    1.42 |  76.92\n   60 | 24 |  2.00 |    2.00 |  78.92\n   61 | 18 |  1.50 |    1.50 |  80.42\n   62 | 21 |  1.75 |    1.75 |  82.17\n   63 | 15 |  1.25 |    1.25 |  83.42\n   64 | 20 |  1.67 |    1.67 |  85.08\n   65 | 12 |  1.00 |    1.00 |  86.08\n   66 | 24 |  2.00 |    2.00 |  88.08\n   67 |  9 |  0.75 |    0.75 |  88.83\n   68 | 12 |  1.00 |    1.00 |  89.83\n   69 | 15 |  1.25 |    1.25 |  91.08\n   70 | 30 |  2.50 |    2.50 |  93.58\n   71 |  9 |  0.75 |    0.75 |  94.33\n   72 | 10 |  0.83 |    0.83 |  95.17\n   73 |  8 |  0.67 |    0.67 |  95.83\n   74 |  8 |  0.67 |    0.67 |  96.50\n   75 |  8 |  0.67 |    0.67 |  97.17\n   76 | 12 |  1.00 |    1.00 |  98.17\n   77 |  5 |  0.42 |    0.42 |  98.58\n   78 |  2 |  0.17 |    0.17 |  98.75\n   79 |  2 |  0.17 |    0.17 |  98.92\n   80 |  4 |  0.33 |    0.33 |  99.25\n   82 |  1 |  0.08 |    0.08 |  99.33\n   84 |  2 |  0.17 |    0.17 |  99.50\n   85 |  3 |  0.25 |    0.25 |  99.75\n   86 |  1 |  0.08 |    0.08 |  99.83\n   87 |  1 |  0.08 |    0.08 |  99.92\n   89 |  1 |  0.08 |    0.08 | 100.00\n &lt;NA&gt; |  0 |  0.00 |    &lt;NA&gt; |   &lt;NA&gt;\n\n\nb. Recodificación: no es necesario en este caso\nc. Etiquetado\nCambio la etiqueta de la variable.\n\n\nCódigo\nget_label(proc_data$edad)\n\n\nNULL\n\n\nCódigo\nproc_data$edad &lt;- set_label(x = proc_data$edad,label = \"Edad\")",
    "crumbs": [
      "Prácticos",
      "Talleres",
      "03: Práctico 3"
    ]
  },
  {
    "objectID": "practicos/03-content.html#generación-de-base-de-datos-procesada-para-el-análisis",
    "href": "practicos/03-content.html#generación-de-base-de-datos-procesada-para-el-análisis",
    "title": "Práctico 3. Operacionalización de variables",
    "section": "5. Generación de base de datos procesada para el análisis",
    "text": "5. Generación de base de datos procesada para el análisis\nAntes de guardar la base procesada, revisamos nuevamente todas las variables con una tabla descriptiva general mediante la función stargazer (de la librería homónima)\nPrimero vamos a reformatear el objeto proc_data como base de datos (as.data.frame), paso necesario para que sea reconocido como tal por stargazer\n\n\nCódigo\nproc_data &lt;-as.data.frame(proc_data)\nstargazer(proc_data, type=\"text\")\n\n\n\n===========================================\nStatistic      N    Mean   St. Dev. Min Max\n-------------------------------------------\nconf_gob     1,181  0.660   0.800    0   3 \nconf_cong    1,178  0.594   0.714    0   3 \nconf_jud     1,186  0.717   0.789    0   3 \nconf_partpol 1,178  0.451   0.673    0   3 \nedad         1,200 44.491   17.008  18  89 \nidenpa       1,200 152.000  0.000   152 152\nconf_inst    1,162  2.420   2.489    0  12 \n-------------------------------------------\n\n\n\nSi se desea modificar las columnas que aparecen en la tabla se puede ocupar la opción summary.stat, donde se pueden especificar:\n\n“max” maximum\n“mean” mean\n“median” median\n“min” minimum\n“n” number of observations\n“p25” 25th percentile\n“p75” 75th percentile\n“sd” standard deviation\n\nPor ejemplo, si quiero una tabla solo con promedio, n, sd y p75: stargazer(data, type=\"text\", summary.stat = c(\"mean\", \"n\", \"sd\", \"p75\"))\n\n\nGuardar base de datos procesada: en carpeta local La ruta hacia su carpeta local si está trabajando en windows debería ser algo como “C:/Users/Lenovo/Clases/y aquí nombre del archivo a grabar\n\nEl comando para guardar es save:\n\n\nCódigo\nsave(proc_data,file = \"[ruta hacia carpeta local en su computador]/ELSOC_ess_merit2016.RData\")\n\n\nEn este caso, seguimos una estructura de carpetas de datos, separando en una carpeta los datos originales, y en otra (proc) los datos procesados:\n\n\nCódigo\nsave(proc_data,file = \"files/data/latinobarometro_proc.RData\")",
    "crumbs": [
      "Prácticos",
      "Talleres",
      "03: Práctico 3"
    ]
  },
  {
    "objectID": "practicos/03-content.html#descriptivos-básicos-de-las-variables",
    "href": "practicos/03-content.html#descriptivos-básicos-de-las-variables",
    "title": "Práctico 3. Operacionalización de variables",
    "section": "Descriptivos básicos de las variables",
    "text": "Descriptivos básicos de las variables\nPodemos conocer ciertas medidas de tendencia central utilizando algunas funciones de dplyr\n\nMedia por grupos\n\n\nCódigo\nproc_data %&gt;% dplyr::group_by(sexo) %&gt;% summarise(mean(conf_inst, na.rm=TRUE))\n\n\n# A tibble: 2 × 2\n  sexo   `mean(conf_inst, na.rm = TRUE)`\n  &lt;fct&gt;                            &lt;dbl&gt;\n1 Hombre                            2.48\n2 Mujer                             2.36\n\n\n\n\nCódigo\nproc_data %&gt;% dplyr::group_by(educacion) %&gt;% summarise(mean(conf_inst, na.rm=TRUE))\n\n\n# A tibble: 3 × 2\n  educacion          `mean(conf_inst, na.rm = TRUE)`\n  &lt;fct&gt;                                        &lt;dbl&gt;\n1 Educacion basica                              2.96\n2 Educacion media                               2.38\n3 Educacion superior                            2.36\n\n\n\n\nRepresentación\n\n\nCódigo\nlibrary(sjPlot)\n\n\n#refugeeswelcome\n\n\nCódigo\nsjt.xtab(proc_data$educacion, proc_data$conf_inst, encoding = \"UTF-8\")\n\n\n\n \n Educación\n Confianza eninstituciones\n Total\n \n \n\n 0\n 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n 10\n 11\n 12\n \n \n \nEducacion basica\n30\n11\n6\n6\n12\n6\n4\n4\n7\n3\n0\n0\n1\n90 \n\n \n \nEducacion media\n268\n95\n83\n79\n121\n45\n24\n29\n28\n3\n4\n1\n0\n780 \n\n \n \nEducacion superior\n99\n35\n41\n26\n36\n20\n13\n8\n9\n5\n0\n0\n0\n292 \n\n \n \nTotal\n397\n141\n130\n111\n169\n71\n41\n41\n44\n11\n4\n1\n1\n1162 \n\nχ2=37.850 · df=24 · Cramer's V=0.128 · Fisher's p=0.132",
    "crumbs": [
      "Prácticos",
      "Talleres",
      "03: Práctico 3"
    ]
  },
  {
    "objectID": "practicos/05-content.html#cargar-paquetes",
    "href": "practicos/05-content.html#cargar-paquetes",
    "title": "Práctico 5. Visualización de variables en Quarto",
    "section": "Cargar paquetes",
    "text": "Cargar paquetes\n\n\nCódigo\npacman::p_load(sjlabelled,\n               dplyr, #Manipulacion de datos\n              stargazer, #Tablas\n              sjmisc, # Tablas\n              summarytools, # Tablas\n              kableExtra, #Tablas\n              sjPlot, #Tablas y gráficos\n              corrplot, # Correlaciones\n              sessioninfo, # Información de la sesión de trabajo\n              ggplot2) # Para la mayoría de los gráficos",
    "crumbs": [
      "Prácticos",
      "Talleres",
      "05: Práctico 5"
    ]
  },
  {
    "objectID": "practicos/05-content.html#cargar-bases-de-datos",
    "href": "practicos/05-content.html#cargar-bases-de-datos",
    "title": "Práctico 5. Visualización de variables en Quarto",
    "section": "Cargar bases de datos",
    "text": "Cargar bases de datos\nCargamos ambas bases de datos desde internet\n\n\nCódigo\nload(url(\"https://github.com/Kevin-carrasco/R-data-analisis/raw/main/files/data/latinobarometro_total.RData\")) #Cargar base de datos\nload(url(\"https://github.com/Kevin-carrasco/R-data-analisis/raw/main/files/data/data_wvs.RData\")) #Cargar base de datos\n\n\nPara trabajar con ambas bases, agruparemos las variables de interés por país, por lo que ya no trabajaremos directamente con individuos.\n\n\nCódigo\ncontext_data &lt;- wvs %&gt;% group_by(B_COUNTRY) %&gt;% # Agrupar por país\n  summarise(gdp = mean(GDPpercap1, na.rm = TRUE), # Promedio de GDP per capita\n         life_exp = mean(lifeexpect, na.rm = TRUE), # Promedio esperanza de vida\n         gini = mean(giniWB, na.rm = TRUE)) %&gt;%  # Promedio gini\n  rename(idenpa=B_COUNTRY) # Para poder vincular ambas bases, es necesario que la variable de identificación se llamen igual\ncontext_data$idenpa &lt;- as.numeric(context_data$idenpa) # Como era categórica, la dejamos numérica\n\nproc_data &lt;- proc_data %&gt;% group_by(idenpa) %&gt;%  # agrupamos por país\n  summarise(promedio = mean(conf_inst, na.rm = TRUE)) # promedio de confianza en instituciones por país",
    "crumbs": [
      "Prácticos",
      "Talleres",
      "05: Práctico 5"
    ]
  },
  {
    "objectID": "practicos/05-content.html#unir-bases-de-datos",
    "href": "practicos/05-content.html#unir-bases-de-datos",
    "title": "Práctico 5. Visualización de variables en Quarto",
    "section": "Unir bases de datos",
    "text": "Unir bases de datos\nPara vincular nuestras bases de datos existen múltiples opciones, la primera es ‘merge’ de R base y las siguientes tres vienen desde dplyr: ‘right_join’, ‘full_join’ y ‘left_join’. Cada una tiene sus propias potencialidades y limitaciones y dependerá de cada caso cuál usemos\n\nProbemos merge\n\n\nCódigo\ndata &lt;- merge(proc_data, context_data, by=\"idenpa\")\n\n\n\n\nCódigo\ndata &lt;- data %&gt;%\n  mutate(idenpa = as.character(idenpa)) %&gt;%\n  mutate(idenpa = case_when(\n    idenpa == \"32\" ~ \"Argentina\",\n    idenpa == \"68\" ~ \"Bolivia\",\n    idenpa == \"76\" ~ \"Brasil\",\n    idenpa == \"152\" ~ \"Chile\",\n    idenpa == \"170\" ~ \"Colombia\",\n    idenpa == \"188\" ~ \"Costa Rica\",\n    idenpa == \"214\" ~ \"Cuba\",\n    idenpa == \"218\" ~ \"República Dominicana\",\n    idenpa == \"222\" ~ \"Ecuador\",\n    idenpa == \"320\" ~ \"El Salvador\",\n    idenpa == \"340\" ~ \"Guatemala\",\n    idenpa == \"484\" ~ \"Honduras\",\n    idenpa == \"558\" ~ \"México\",\n    idenpa == \"591\" ~ \"Nicaragua\",\n    idenpa == \"600\" ~ \"Panamá\",\n    idenpa == \"604\" ~ \"Paraguay\",\n    idenpa == \"858\" ~ \"Uruguay\",\n    idenpa == \"862\" ~ \"Venezuela\"))\n\ndata$gdp &lt;- as.numeric(data$gdp)\ndata$gdp[data$gdp==0] &lt;- NA\ndata &lt;- na.omit(data)",
    "crumbs": [
      "Prácticos",
      "Talleres",
      "05: Práctico 5"
    ]
  },
  {
    "objectID": "practicos/05-content.html#visualizaciones",
    "href": "practicos/05-content.html#visualizaciones",
    "title": "Práctico 5. Visualización de variables en Quarto",
    "section": "Visualizaciones",
    "text": "Visualizaciones\nPodemos establecer referencias cruzadas para las tablas y gráficos dentro del texto, para poder automatizarlo, como ejemplo así, pero dentro del chunk:\n#| label: tbl-sjmisc\n#| tbl-cap: “Descriptivos con sjmisc”\n\nDescriptivos\nEl Chunk se debería ver así:\n#| label: tbl-sjmisc #| tbl-cap: “Descriptivos con sjmisc”\nsjmisc::descr(data, show = c(“label”,“range”, “mean”, “sd”, “NA.prc”, “n”))%&gt;% # Selecciona estadísticos kable(.,“markdown”) # Esto es para que se vea bien en quarto\n\n\nCódigo\nsjmisc::descr(data,\n      show = c(\"label\",\"range\", \"mean\", \"sd\", \"NA.prc\", \"n\"))%&gt;% # Selecciona estadísticos\n      kable(.,\"markdown\") # Esto es para que se vea bien en quarto\n\n\n\n\nTabla 1: Descriptivos con sjmisc\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nvar\nlabel\nn\nNA.prc\nmean\nsd\nrange\n\n\n\n\n4\npromedio\npromedio\n11\n0\n3.40077\n1.016976\n3.59 (2.3-5.9)\n\n\n1\ngdp\ngdp\n11\n0\n15528.18364\n6480.045512\n19523.79 (5631.2-25154.99)\n\n\n3\nlife_exp\nlife_exp\n11\n0\n75.90909\n2.286593\n8.8 (71.24-80.04)\n\n\n2\ngini\ngini\n11\n0\n45.46364\n4.156266\n14.2 (39.7-53.9)\n\n\n\n\n\n\n\n\nLuego de establecer el link y el nombre de la tabla, podemos referenciar acá con un @, así: @ tbl-sjmisc (pero junto), y que se vería así Tabla 1\n\n\notra opción\n\nCódigo\nview(dfSummary(data, headings=FALSE))\n\n\n\n\nTabla 2: Descriptivos con summarytools\n\n\n\nSwitching method to 'browser'\n\n\nOutput file written: C:\\Users\\kevin\\AppData\\Local\\Temp\\RtmpQFOyCu\\file1d0c2a6246cb.html\n\n\n\n\nLa tabla Tabla 2 muestra los estadísticos descriptivos de la base de datos hecha con summarytools\n\n\nGráficos\nY para los gráficos se hace de la misma forma:\n#| label: fig-gdp\n#| fig-cap: “Plots”\n\n\nCódigo\nggplot(data, aes(x = idenpa, y = gdp)) +\n  geom_point() +\n  labs(x = \"País\", y = \"Gdp\") +\n  theme_minimal()+\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))\n\n\n\n\n\n\n\n\nFigura 1: Producto interno bruto por país\n\n\n\n\n\nSin embargo la Figura 1 entrega información desordenada. Mejor ordenar por tamaño de PIB que por orden alfabético de los países. Para eso\n\n\nCódigo\ndata_sorted &lt;- data %&gt;% arrange(desc(gdp))\nggplot(data_sorted, aes(x = factor(idenpa, levels = idenpa), y = gdp)) +\n  geom_point() +\n  labs(x = \"País\", y = \"GDP\") +\n  theme_minimal() +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))\n\n\n\n\n\n\n\n\nFigura 2: Producto interno bruto por país ordenado\n\n\n\n\n\nAhora sí la Figura 2 muestra un gráfico más ordenado.\nY comparar el promedio de confianza en instituciones según producto interno bruto por país?\n\n\nCódigo\ndata %&gt;%\n  ggplot(aes(x = gdp, y = promedio, label = idenpa)) +\n  geom_point() +\n  geom_text(vjust = -0.5) +\n  labs(x = \"GDP\", y = \"Promedio\") +\n  theme_bw()\n\n\n\n\n\n\n\n\nFigura 3: Confianza en instituciones según el producto interno bruto por país\n\n\n\n\n\nLa Figura 3 muestra la relación que existe entre el producto interno bruto y la confianza en instituciones para los 18 países analizados. Es interesante comparar los casos de Chile y urugay, que al tener similar GDP, tienen un nivel de confianza en instituciones muy diferente.",
    "crumbs": [
      "Prácticos",
      "Talleres",
      "05: Práctico 5"
    ]
  },
  {
    "objectID": "practicos/05-content.html#footnotes",
    "href": "practicos/05-content.html#footnotes",
    "title": "Práctico 5. Visualización de variables en Quarto",
    "section": "Notas",
    "text": "Notas\n\n\nEsta es la nota al pie↩︎",
    "crumbs": [
      "Prácticos",
      "Talleres",
      "05: Práctico 5"
    ]
  },
  {
    "objectID": "practicos/07-content.html",
    "href": "practicos/07-content.html",
    "title": "Práctico 7. Índices y escalas",
    "section": "",
    "text": "El Programa de las Naciones Unidas para el Desarrollo (PNUD) es la agencia de la Organización de las Naciones Unidas encargada de promover el desarrollo sostenible a nivel mundial, y uno de sus enfoques es la erradicación de la pobreza. En este contexto, el PNUD reconoce la importancia de abordar la pobreza multidimensional para lograr un desarrollo sostenible y mejorar el bienestar de las personas en todas las dimensiones de sus vidas.\nDesde el año 2016 Chile cuenta con la medida actual de pobreza multidimensional. El propósito de esta medida es complementar la medición de la pobreza basada en ingresos con un indicador que refleje las condiciones de vida de la población en aspectos relevantes para el bienestar social y una vida digna. Desde su creación, se ha buscado obtener un diagnóstico más completo de la pobreza y contar con una herramienta útil para el diseño, implementación, monitoreo y evaluación de políticas públicas.\nInicialmente, la medida de pobreza multidimensional incluyó 4 dimensiones (Educación, Salud, Trabajo y Seguridad Social, y Vivienda) con tres indicadores por dimensión (12 indicadores en total), cada uno con igual ponderación (8,3%), por lo tanto, con dimensiones cuyo peso representan el 25% de la medida.Posteriormente, con los resultados de la encuesta Casen 2015 se incorpora una quinta dimensión de Redes y Cohesión Social y se amplía la dimensión de Vivienda para incluir el concepto de Entorno. Desde entonces, la medida ha estado compuesta por 5 dimensiones (Educación, Salud, Trabajo y Seguridad Social, Vivienda y Entorno, y Redes y Cohesión Social), manteniendo la definición de 3 indicadores por dimensión, de modo que la medida queda compuesta por 15 indicadores. Respecto del peso de las dimensiones, con el fin de favorecer cierta estabilidad de la medida, la dimensión de Redes y Cohesión Social se incorpora con un peso de 10% y se mantiene la igualdad de ponderación entre las demás dimensiones, ahora con una ponderación de 22,5%.\n\n\n\nEl objetivo de este ejercicio práctico es comprender y estimar el proceso de construcción de índices ponderados y no ponderados en R.\n\n\n\n\n\nCódigo\npacman::p_load(tidyverse, #Conjunto de paquetes, sobre todo dplyr y ggplot2\n               car, #Para recodificar\n               haven,\n               summarytools, #Para descriptivos\n               sjmisc,\n               psych     # para Alfa de Chronbach\n               )\n\n\nInstalling package into 'C:/Users/kevin/AppData/Local/R/win-library/4.4'\n(as 'lib' is unspecified)\n\n\nalso installing the dependency 'mnormt'\n\n\nWarning: unable to access index for repository http://www.stats.ox.ac.uk/pub/RWin/bin/windows/contrib/4.4:\n  no fue posible abrir la URL 'http://www.stats.ox.ac.uk/pub/RWin/bin/windows/contrib/4.4/PACKAGES'\n\n\npackage 'mnormt' successfully unpacked and MD5 sums checked\npackage 'psych' successfully unpacked and MD5 sums checked\n\nThe downloaded binary packages are in\n    C:\\Users\\kevin\\AppData\\Local\\Temp\\RtmpCUjsc5\\downloaded_packages\n\n\n\npsych installed\n\n\nCódigo\noptions(scipen = 999) # para desactivar notacion cientifica\nrm(list = ls()) # para limpiar el entorno de trabajo\n\n\n\n\n\nLa base de datos a utilizar es la CASEN 2022 (Encuesta de Caracterización Socioeconómica Nacional). La base de datos está disponible en este link y el cuestionario en este link.\nSin embargo, para realizar este ejercicio práctico utilizaremos una muestra aleatoria de esta base de datos para simplificar el proceso de construcción de índices. El código que crea este subset está disponible acá\n\n\n\n\nCódigo\nload(url(\"https://github.com/cursos-metodos-facso/investigacion-cuantitativa/raw/main/files/data/casen2022.RData\")) #Cargar base de datos\n\n\n\n\n\n\n\nCódigo\nview(dfSummary(casen2022, headings=FALSE, graph.col = FALSE))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNo\nVariable\nLabel\nStats / Values\nFreqs (% of Valid)\nValid\nMissing\n\n\n\n\n1\nasistencia [haven_labelled, vctrs_vctr, double]\nHogar carente en asistencia\n\n\n\nMin : 0\n\n\nMean : 0\n\n\nMax : 1\n\n\n\n\n\n\n0\n:\n9815\n(\n98.2%\n)\n\n\n1\n:\n185\n(\n1.8%\n)\n\n\n\n10000 (100.0%)\n0 (0.0%)\n\n\n2\nrezago [haven_labelled, vctrs_vctr, double]\nHogar carente en rezago escolar\n\n\n\nMin : 0\n\n\nMean : 0\n\n\nMax : 1\n\n\n\n\n\n\n0\n:\n9911\n(\n99.1%\n)\n\n\n1\n:\n89\n(\n0.9%\n)\n\n\n\n10000 (100.0%)\n0 (0.0%)\n\n\n3\nescolaridad [haven_labelled, vctrs_vctr, double]\nHogar carente en escolaridad\n\n\n\nMin : 0\n\n\nMean : 0.3\n\n\nMax : 1\n\n\n\n\n\n\n0\n:\n6944\n(\n69.5%\n)\n\n\n1\n:\n3046\n(\n30.5%\n)\n\n\n\n9990 (99.9%)\n10 (0.1%)\n\n\n4\nmalnutricion [haven_labelled, vctrs_vctr, double]\nHogar carente en malnutrición en niños/as\n\n\n\nMin : 0\n\n\nMean : 0\n\n\nMax : 1\n\n\n\n\n\n\n0\n:\n9694\n(\n97.0%\n)\n\n\n1\n:\n301\n(\n3.0%\n)\n\n\n\n9995 (100.0%)\n5 (0.0%)\n\n\n5\nsist_salud [haven_labelled, vctrs_vctr, double]\nHogar carente en adscripción a sistema de salud\n\n\n\nMin : 0\n\n\nMean : 0\n\n\nMax : 1\n\n\n\n\n\n\n0\n:\n9592\n(\n96.1%\n)\n\n\n1\n:\n390\n(\n3.9%\n)\n\n\n\n9982 (99.8%)\n18 (0.2%)\n\n\n6\natencion [haven_labelled, vctrs_vctr, double]\nHogar carente en atención\n\n\n\nMin : 0\n\n\nMean : 0.1\n\n\nMax : 1\n\n\n\n\n\n\n0\n:\n9476\n(\n94.8%\n)\n\n\n1\n:\n521\n(\n5.2%\n)\n\n\n\n9997 (100.0%)\n3 (0.0%)\n\n\n7\nocupacion [haven_labelled, vctrs_vctr, double]\nHogar carente en ocupación\n\n\n\nMin : 0\n\n\nMean : 0.1\n\n\nMax : 1\n\n\n\n\n\n\n0\n:\n8994\n(\n89.9%\n)\n\n\n1\n:\n1006\n(\n10.1%\n)\n\n\n\n10000 (100.0%)\n0 (0.0%)\n\n\n8\nseg_social [haven_labelled, vctrs_vctr, double]\nHogar carente en seguridad social\n\n\n\nMin : 0\n\n\nMean : 0.3\n\n\nMax : 1\n\n\n\n\n\n\n0\n:\n7011\n(\n70.5%\n)\n\n\n1\n:\n2934\n(\n29.5%\n)\n\n\n\n9945 (99.4%)\n55 (0.5%)\n\n\n9\njubilacion [haven_labelled, vctrs_vctr, double]\nHogar carente en jubilaciones\n\n\n\nMin : 0\n\n\nMean : 0.1\n\n\nMax : 1\n\n\n\n\n\n\n0\n:\n8828\n(\n88.3%\n)\n\n\n1\n:\n1172\n(\n11.7%\n)\n\n\n\n10000 (100.0%)\n0 (0.0%)\n\n\n10\nhabitabilidad [haven_labelled, vctrs_vctr, double]\nHogar carente en habitabilidad\n\n\n\nMin : 0\n\n\nMean : 0.2\n\n\nMax : 1\n\n\n\n\n\n\n0\n:\n8372\n(\n83.8%\n)\n\n\n1\n:\n1620\n(\n16.2%\n)\n\n\n\n9992 (99.9%)\n8 (0.1%)\n\n\n11\nhacinamiento [haven_labelled, vctrs_vctr, double]\nHogar carente en hacinamiento\n\n\n\nMin : 0\n\n\nMean : 0\n\n\nMax : 1\n\n\n\n\n\n\n0\n:\n9576\n(\n95.8%\n)\n\n\n1\n:\n415\n(\n4.2%\n)\n\n\n\n9991 (99.9%)\n9 (0.1%)\n\n\n12\nvivienda [haven_labelled, vctrs_vctr, double]\nHogar carente en estado de la vivienda\n\n\n\nMin : 0\n\n\nMean : 0.1\n\n\nMax : 1\n\n\n\n\n\n\n0\n:\n8687\n(\n86.9%\n)\n\n\n1\n:\n1313\n(\n13.1%\n)\n\n\n\n10000 (100.0%)\n0 (0.0%)\n\n\n13\nserv_basicos [haven_labelled, vctrs_vctr, double]\nHogar carente en servicios básicos\n\n\n\nMin : 0\n\n\nMean : 0.1\n\n\nMax : 1\n\n\n\n\n\n\n0\n:\n9218\n(\n92.2%\n)\n\n\n1\n:\n782\n(\n7.8%\n)\n\n\n\n10000 (100.0%)\n0 (0.0%)\n\n\n14\nentorno [haven_labelled, vctrs_vctr, double]\nHogar carente en entorno\n\n\n\nMin : 0\n\n\nMean : 0.1\n\n\nMax : 1\n\n\n\n\n\n\n0\n:\n8772\n(\n88.0%\n)\n\n\n1\n:\n1191\n(\n12.0%\n)\n\n\n\n9963 (99.6%)\n37 (0.4%)\n\n\n15\nap_part_social [haven_labelled, vctrs_vctr, double]\nHogar carente en apoyo y participación social\n\n\n\nMin : 0\n\n\nMean : 0.1\n\n\nMax : 1\n\n\n\n\n\n\n0\n:\n9315\n(\n93.5%\n)\n\n\n1\n:\n652\n(\n6.5%\n)\n\n\n\n9967 (99.7%)\n33 (0.3%)\n\n\n16\ntrato [haven_labelled, vctrs_vctr, double]\nHogar carente en trato igualitario\n\n\n\nMin : 0\n\n\nMean : 0.2\n\n\nMax : 1\n\n\n\n\n\n\n0\n:\n8443\n(\n84.4%\n)\n\n\n1\n:\n1557\n(\n15.6%\n)\n\n\n\n10000 (100.0%)\n0 (0.0%)\n\n\n17\nseguridad [haven_labelled, vctrs_vctr, double]\nHogar carente en seguridad\n\n\n\nMin : 0\n\n\nMean : 0.1\n\n\nMax : 1\n\n\n\n\n\n\n0\n:\n9057\n(\n90.6%\n)\n\n\n1\n:\n943\n(\n9.4%\n)\n\n\n\n10000 (100.0%)\n0 (0.0%)\n\n\n18\nregion [haven_labelled, vctrs_vctr, double]\nRegión\n\n\n\nMean (sd) : 8.8 (4.3)\n\n\nmin ≤ med ≤ max:\n\n\n1 ≤ 8 ≤ 16\n\n\nIQR (CV) : 8 (0.5)\n\n\n\n16 distinct values\n10000 (100.0%)\n0 (0.0%)\n\n\n19\narea [haven_labelled, vctrs_vctr, double]\nÁrea\n\n\n\nMin : 1\n\n\nMean : 1.2\n\n\nMax : 2\n\n\n\n\n\n\n1\n:\n7907\n(\n79.1%\n)\n\n\n2\n:\n2093\n(\n20.9%\n)\n\n\n\n10000 (100.0%)\n0 (0.0%)\n\n\n\n\nGenerated by summarytools 1.0.1 (R version 4.4.0)2024-05-15\n\n\n\n\nEn esta base de datos, las variables de interés que están presentes (ej. asistencia, rezago, escolaridad) son variables dummy, es decir, variables que tienen como valores posibles 0 y 1. Donde 0 implica la ausencia de un atributo y 1 la presencia del mismo atributo.\nPara medir pobreza multidimensional, 1 indica la carencia de un servicio o cualidad, por ejemplo, se considera que un hogar es carente en escolaridad si al menos uno de sus integrantes mayores de 18 años ha alcanzado menos años de escolaridad que los establecidos por ley, de acuerdo a su edad. Por lo tanto, en la variable escolaridad 1) indica un hogar carente en escolaridad, que según nuestra base de datos corresponde a 3065 hogares (30.7% de nuestra sub-muestra).\n\n\n\n\n\nSeleccionamos solo los indicadores que eran utilizados hasta 2014\n\n\nCódigo\nindicadores2014 &lt;- casen2022 %&gt;% select(asistencia, \n                                        rezago, \n                                        escolaridad, \n                                        malnutricion, \n                                        sist_salud, \n                                        atencion, \n                                        ocupacion, \n                                        seg_social, \n                                        jubilacion, \n                                        hacinamiento, \n                                        estado_vivienda=vivienda, \n                                        serv_basicos)  %&gt;% \n  na.omit() %&gt;% # Eliminar Na's\n  mutate_all(~(as.numeric(.))) # Convertimos todas las variables a numéricas\n\n\nCon la función mutate creamos una nueva variable para cada dimensión, que contenga el promedio simple de los tres indicadores correspondientes.\n\n\nCódigo\nindicadores2014 = indicadores2014 %&gt;% \n  rowwise() %&gt;%\n  mutate(educ = mean(c(asistencia, rezago, escolaridad)),\n         salud = mean(c(malnutricion, sist_salud, atencion)),\n         trabajo= mean(c(ocupacion, seg_social, jubilacion)),\n         vivienda= mean(c(hacinamiento, estado_vivienda, serv_basicos))) %&gt;% \n  ungroup()\n\n\nLuego, como la pobreza multidimensional consideraba cuatro dimensiones equivalentes (sin ponderar), es posible obtener el índice de pobreza multidimensional a partir del promedio de las cuatro dimensiones.\n\n\nCódigo\nindicadores2014 = indicadores2014 %&gt;% \n  rowwise() %&gt;%\n  mutate(pobreza = mean(c(educ, salud, trabajo, vivienda))) %&gt;% \n  ungroup()\n\n\nLo que nos da este resultado:\n\n\nCódigo\nindicadores2014 %&gt;% select(pobreza) %&gt;% head(10) # Primeros 10 casos\n\n\n# A tibble: 10 × 1\n   pobreza\n     &lt;dbl&gt;\n 1  0.167 \n 2  0.25  \n 3  0     \n 4  0.167 \n 5  0.167 \n 6  0.167 \n 7  0     \n 8  0.167 \n 9  0     \n10  0.0833\n\n\nCódigo\nsummary(indicadores2014$pobreza) # Resumen\n\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n0.00000 0.00000 0.08333 0.10142 0.16667 0.66667 \n\n\n¿Cómo podemos conocer el porcentaje total de pobreza multidimensional del país?\nEl PNUD considera como límite para el índice de cuatro dimensiones un 25% de pobreza multidimensional (lo que equivale a tener carencia en los tres indicadores de una dimensión). Por lo tanto, podemos utilizar un condicional que indique “si” existe pobreza muldimensional cuando nuestra variable “pobreza” sea mayor o igual a 0.25 y que indique que “no” existe pobreza multidimensional cuando la variable “pobreza” sea menor a 0.25. case_when viene en dplyr.\n\n\nCódigo\nindicadores2014 &lt;- indicadores2014 %&gt;% mutate(pobreza = case_when(pobreza&gt;=0.25~\"si\",\n                                                      pobreza&lt;0.25~\"no\")\n                           )\nprop.table(table(indicadores2014$pobreza))*100\n\n\n\n      no       si \n87.03161 12.96839 \n\n\nSegún el análisis realizado con la submuestra aleatoria de la CASEN, considerando las cuatro dimensiones que se utilizaban hasta el 2014, existe un 12.97% de pobreza multidimensional en Chile\n\n\n\nVeamos ahora el mismo proceso, pero considerando la quinta dimensión que fue agregada en 2016 sobre Redes y Cohesión Social.\n\nEn esta operacionalización del índice de pobreza multidimensional las cuatro dimensiones originales equivalen a un 22.5% cada una, mientras que la nueva dimensión de redes y cohesión social equivale a un 10%.\nSeleccionemos solo los indicadores que son utilizados desde 2016.\n\n\nCódigo\nindicadores2016 &lt;- casen2022 %&gt;% select(asistencia, \n                                        rezago, \n                                        escolaridad, \n                                        malnutricion, \n                                        sist_salud, \n                                        atencion, \n                                        ocupacion, \n                                        seg_social, \n                                        jubilacion, \n                                        habitabilidad, \n                                        serv_basicos,\n                                        entorno,\n                                        ap_part_social,\n                                        trato,\n                                        seguridad,\n                                        area,\n                                        region) %&gt;% \n  na.omit() %&gt;% # Eliminar Na's\n  mutate_all(~(as.numeric(.))) # Convertimos todas las variables a numéricas\n\n\nSeguimos los mismos pasos que con el índice anterior, estimando un promedio simple para cada una de las dimensiones.\n\n\nCódigo\nindicadores2016 = indicadores2016 %&gt;% \n  rowwise() %&gt;%\n  mutate(educ = mean(c(asistencia, rezago, escolaridad)),\n         salud = mean(c(malnutricion, sist_salud, atencion)),\n         trabajo= mean(c(ocupacion, seg_social, jubilacion)),\n         vivienda= mean(c(habitabilidad, serv_basicos, entorno)),\n         redes_cohesion= mean(c(ap_part_social, trato, seguridad))) %&gt;% \n  ungroup()\n\n\nSin embargo, como en esta ocasión se trata de un índice ponderado (con dimensiones con distinto peso cada una), multiplicamos cada dimensión por su peso correspondiente y las sumamos.\n\n\nCódigo\nindicadores2016 = indicadores2016 %&gt;% \n  rowwise() %&gt;%\n  mutate(pobreza_pond = (educ*22.5) + (salud*22.5) + (trabajo*22.5) + (vivienda*22.5) + (redes_cohesion*10)) %&gt;%  \n  ungroup()\n\n\nLo que nos da este resultado:\n\n\nCódigo\nindicadores2016 %&gt;% select(pobreza_pond) %&gt;% head(10) # Primeros 10 casos\n\n\n# A tibble: 10 × 1\n   pobreza_pond\n          &lt;dbl&gt;\n 1        18.3 \n 2        22.5 \n 3         3.33\n 4        22.5 \n 5        15   \n 6        15   \n 7         0   \n 8        15   \n 9         0   \n10        18.3 \n\n\nCódigo\nsummary(indicadores2016$pobreza_pond) # Resumen\n\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  0.000   3.333   7.500  10.988  15.000  62.500 \n\n\n¿Cómo podemos conocer el porcentaje total de pobreza multidimensional del país?\nEl PNUD considera como límite para el índice de cinco dimensiones un 22.5% de pobreza multidimensional (lo que equivale a tener carencia en los tres indicadores de una dimensión). Por lo tanto, podemos utilizar un condicional que indique “si” existe pobreza muldimensional cuando nuestra variable “pobreza” sea mayor o igual a 22.5 y que indique que “no” existe pobreza multidimensional cuando la variable “pobreza” sea menor a 22.5.\n\n\nCódigo\nindicadores2016 &lt;- indicadores2016 %&gt;% mutate(pobreza = case_when(pobreza_pond&gt;=22.5~\"si\",\n                                                      pobreza_pond&lt;22.5~\"no\")\n                           )\n                          \nprop.table(table(indicadores2016$pobreza))*100\n\n\n\n      no       si \n84.18912 15.81088 \n\n\nSegún el análisis realizado con la submuestra aleatoria de la CASEN, considerando las cinco dimensiones que se comenzaron a utilizar en 2016, existe un 15.73% de pobreza multidimensional en Chile.\n\n\nPodemos utilizar otras variables de la CASEN para poder conocer cómo se distribuye la pobreza multidimensional en Chile. Por ejemplo, porcentaje de pobreza multidimensional por región:\n\n\nCódigo\nprop.table(table(indicadores2016$region, indicadores2016$pobreza), margin = 1)\n\n\n    \n            no        si\n  1  0.7965261 0.2034739\n  2  0.7975000 0.2025000\n  3  0.8097345 0.1902655\n  4  0.8484108 0.1515892\n  5  0.8487230 0.1512770\n  6  0.8826025 0.1173975\n  7  0.8703170 0.1296830\n  8  0.8543689 0.1456311\n  9  0.8083736 0.1916264\n  10 0.7571702 0.2428298\n  11 0.8910891 0.1089109\n  12 0.9531250 0.0468750\n  13 0.8496241 0.1503759\n  14 0.8079096 0.1920904\n  15 0.8575198 0.1424802\n  16 0.8536585 0.1463415\n\n\no pobreza multidimensional por zona geográfica 1) urbano 2) rural\n\n\nCódigo\nprop.table(table(indicadores2016$area, indicadores2016$pobreza), margin = 1)\n\n\n   \n           no        si\n  1 0.8735691 0.1264309\n  2 0.7223301 0.2776699",
    "crumbs": [
      "Prácticos",
      "Talleres",
      "07: Práctico 7"
    ]
  },
  {
    "objectID": "practicos/07-content.html#presentación",
    "href": "practicos/07-content.html#presentación",
    "title": "Práctico 7. Índices y escalas",
    "section": "",
    "text": "El Programa de las Naciones Unidas para el Desarrollo (PNUD) es la agencia de la Organización de las Naciones Unidas encargada de promover el desarrollo sostenible a nivel mundial, y uno de sus enfoques es la erradicación de la pobreza. En este contexto, el PNUD reconoce la importancia de abordar la pobreza multidimensional para lograr un desarrollo sostenible y mejorar el bienestar de las personas en todas las dimensiones de sus vidas.\nDesde el año 2016 Chile cuenta con la medida actual de pobreza multidimensional. El propósito de esta medida es complementar la medición de la pobreza basada en ingresos con un indicador que refleje las condiciones de vida de la población en aspectos relevantes para el bienestar social y una vida digna. Desde su creación, se ha buscado obtener un diagnóstico más completo de la pobreza y contar con una herramienta útil para el diseño, implementación, monitoreo y evaluación de políticas públicas.\nInicialmente, la medida de pobreza multidimensional incluyó 4 dimensiones (Educación, Salud, Trabajo y Seguridad Social, y Vivienda) con tres indicadores por dimensión (12 indicadores en total), cada uno con igual ponderación (8,3%), por lo tanto, con dimensiones cuyo peso representan el 25% de la medida.Posteriormente, con los resultados de la encuesta Casen 2015 se incorpora una quinta dimensión de Redes y Cohesión Social y se amplía la dimensión de Vivienda para incluir el concepto de Entorno. Desde entonces, la medida ha estado compuesta por 5 dimensiones (Educación, Salud, Trabajo y Seguridad Social, Vivienda y Entorno, y Redes y Cohesión Social), manteniendo la definición de 3 indicadores por dimensión, de modo que la medida queda compuesta por 15 indicadores. Respecto del peso de las dimensiones, con el fin de favorecer cierta estabilidad de la medida, la dimensión de Redes y Cohesión Social se incorpora con un peso de 10% y se mantiene la igualdad de ponderación entre las demás dimensiones, ahora con una ponderación de 22,5%.",
    "crumbs": [
      "Prácticos",
      "Talleres",
      "07: Práctico 7"
    ]
  },
  {
    "objectID": "practicos/07-content.html#objetivo-general",
    "href": "practicos/07-content.html#objetivo-general",
    "title": "Práctico 7. Índices y escalas",
    "section": "",
    "text": "El objetivo de este ejercicio práctico es comprender y estimar el proceso de construcción de índices ponderados y no ponderados en R.",
    "crumbs": [
      "Prácticos",
      "Talleres",
      "07: Práctico 7"
    ]
  },
  {
    "objectID": "practicos/07-content.html#cargar-paquetes",
    "href": "practicos/07-content.html#cargar-paquetes",
    "title": "Práctico 7. Índices y escalas",
    "section": "",
    "text": "Código\npacman::p_load(tidyverse, #Conjunto de paquetes, sobre todo dplyr y ggplot2\n               car, #Para recodificar\n               haven,\n               summarytools, #Para descriptivos\n               sjmisc,\n               psych     # para Alfa de Chronbach\n               )\n\n\nInstalling package into 'C:/Users/kevin/AppData/Local/R/win-library/4.4'\n(as 'lib' is unspecified)\n\n\nalso installing the dependency 'mnormt'\n\n\nWarning: unable to access index for repository http://www.stats.ox.ac.uk/pub/RWin/bin/windows/contrib/4.4:\n  no fue posible abrir la URL 'http://www.stats.ox.ac.uk/pub/RWin/bin/windows/contrib/4.4/PACKAGES'\n\n\npackage 'mnormt' successfully unpacked and MD5 sums checked\npackage 'psych' successfully unpacked and MD5 sums checked\n\nThe downloaded binary packages are in\n    C:\\Users\\kevin\\AppData\\Local\\Temp\\RtmpCUjsc5\\downloaded_packages\n\n\n\npsych installed\n\n\nCódigo\noptions(scipen = 999) # para desactivar notacion cientifica\nrm(list = ls()) # para limpiar el entorno de trabajo",
    "crumbs": [
      "Prácticos",
      "Talleres",
      "07: Práctico 7"
    ]
  },
  {
    "objectID": "practicos/07-content.html#datos-y-variables",
    "href": "practicos/07-content.html#datos-y-variables",
    "title": "Práctico 7. Índices y escalas",
    "section": "",
    "text": "La base de datos a utilizar es la CASEN 2022 (Encuesta de Caracterización Socioeconómica Nacional). La base de datos está disponible en este link y el cuestionario en este link.\nSin embargo, para realizar este ejercicio práctico utilizaremos una muestra aleatoria de esta base de datos para simplificar el proceso de construcción de índices. El código que crea este subset está disponible acá\n\n\n\n\nCódigo\nload(url(\"https://github.com/cursos-metodos-facso/investigacion-cuantitativa/raw/main/files/data/casen2022.RData\")) #Cargar base de datos\n\n\n\n\n\n\n\nCódigo\nview(dfSummary(casen2022, headings=FALSE, graph.col = FALSE))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNo\nVariable\nLabel\nStats / Values\nFreqs (% of Valid)\nValid\nMissing\n\n\n\n\n1\nasistencia [haven_labelled, vctrs_vctr, double]\nHogar carente en asistencia\n\n\n\nMin : 0\n\n\nMean : 0\n\n\nMax : 1\n\n\n\n\n\n\n0\n:\n9815\n(\n98.2%\n)\n\n\n1\n:\n185\n(\n1.8%\n)\n\n\n\n10000 (100.0%)\n0 (0.0%)\n\n\n2\nrezago [haven_labelled, vctrs_vctr, double]\nHogar carente en rezago escolar\n\n\n\nMin : 0\n\n\nMean : 0\n\n\nMax : 1\n\n\n\n\n\n\n0\n:\n9911\n(\n99.1%\n)\n\n\n1\n:\n89\n(\n0.9%\n)\n\n\n\n10000 (100.0%)\n0 (0.0%)\n\n\n3\nescolaridad [haven_labelled, vctrs_vctr, double]\nHogar carente en escolaridad\n\n\n\nMin : 0\n\n\nMean : 0.3\n\n\nMax : 1\n\n\n\n\n\n\n0\n:\n6944\n(\n69.5%\n)\n\n\n1\n:\n3046\n(\n30.5%\n)\n\n\n\n9990 (99.9%)\n10 (0.1%)\n\n\n4\nmalnutricion [haven_labelled, vctrs_vctr, double]\nHogar carente en malnutrición en niños/as\n\n\n\nMin : 0\n\n\nMean : 0\n\n\nMax : 1\n\n\n\n\n\n\n0\n:\n9694\n(\n97.0%\n)\n\n\n1\n:\n301\n(\n3.0%\n)\n\n\n\n9995 (100.0%)\n5 (0.0%)\n\n\n5\nsist_salud [haven_labelled, vctrs_vctr, double]\nHogar carente en adscripción a sistema de salud\n\n\n\nMin : 0\n\n\nMean : 0\n\n\nMax : 1\n\n\n\n\n\n\n0\n:\n9592\n(\n96.1%\n)\n\n\n1\n:\n390\n(\n3.9%\n)\n\n\n\n9982 (99.8%)\n18 (0.2%)\n\n\n6\natencion [haven_labelled, vctrs_vctr, double]\nHogar carente en atención\n\n\n\nMin : 0\n\n\nMean : 0.1\n\n\nMax : 1\n\n\n\n\n\n\n0\n:\n9476\n(\n94.8%\n)\n\n\n1\n:\n521\n(\n5.2%\n)\n\n\n\n9997 (100.0%)\n3 (0.0%)\n\n\n7\nocupacion [haven_labelled, vctrs_vctr, double]\nHogar carente en ocupación\n\n\n\nMin : 0\n\n\nMean : 0.1\n\n\nMax : 1\n\n\n\n\n\n\n0\n:\n8994\n(\n89.9%\n)\n\n\n1\n:\n1006\n(\n10.1%\n)\n\n\n\n10000 (100.0%)\n0 (0.0%)\n\n\n8\nseg_social [haven_labelled, vctrs_vctr, double]\nHogar carente en seguridad social\n\n\n\nMin : 0\n\n\nMean : 0.3\n\n\nMax : 1\n\n\n\n\n\n\n0\n:\n7011\n(\n70.5%\n)\n\n\n1\n:\n2934\n(\n29.5%\n)\n\n\n\n9945 (99.4%)\n55 (0.5%)\n\n\n9\njubilacion [haven_labelled, vctrs_vctr, double]\nHogar carente en jubilaciones\n\n\n\nMin : 0\n\n\nMean : 0.1\n\n\nMax : 1\n\n\n\n\n\n\n0\n:\n8828\n(\n88.3%\n)\n\n\n1\n:\n1172\n(\n11.7%\n)\n\n\n\n10000 (100.0%)\n0 (0.0%)\n\n\n10\nhabitabilidad [haven_labelled, vctrs_vctr, double]\nHogar carente en habitabilidad\n\n\n\nMin : 0\n\n\nMean : 0.2\n\n\nMax : 1\n\n\n\n\n\n\n0\n:\n8372\n(\n83.8%\n)\n\n\n1\n:\n1620\n(\n16.2%\n)\n\n\n\n9992 (99.9%)\n8 (0.1%)\n\n\n11\nhacinamiento [haven_labelled, vctrs_vctr, double]\nHogar carente en hacinamiento\n\n\n\nMin : 0\n\n\nMean : 0\n\n\nMax : 1\n\n\n\n\n\n\n0\n:\n9576\n(\n95.8%\n)\n\n\n1\n:\n415\n(\n4.2%\n)\n\n\n\n9991 (99.9%)\n9 (0.1%)\n\n\n12\nvivienda [haven_labelled, vctrs_vctr, double]\nHogar carente en estado de la vivienda\n\n\n\nMin : 0\n\n\nMean : 0.1\n\n\nMax : 1\n\n\n\n\n\n\n0\n:\n8687\n(\n86.9%\n)\n\n\n1\n:\n1313\n(\n13.1%\n)\n\n\n\n10000 (100.0%)\n0 (0.0%)\n\n\n13\nserv_basicos [haven_labelled, vctrs_vctr, double]\nHogar carente en servicios básicos\n\n\n\nMin : 0\n\n\nMean : 0.1\n\n\nMax : 1\n\n\n\n\n\n\n0\n:\n9218\n(\n92.2%\n)\n\n\n1\n:\n782\n(\n7.8%\n)\n\n\n\n10000 (100.0%)\n0 (0.0%)\n\n\n14\nentorno [haven_labelled, vctrs_vctr, double]\nHogar carente en entorno\n\n\n\nMin : 0\n\n\nMean : 0.1\n\n\nMax : 1\n\n\n\n\n\n\n0\n:\n8772\n(\n88.0%\n)\n\n\n1\n:\n1191\n(\n12.0%\n)\n\n\n\n9963 (99.6%)\n37 (0.4%)\n\n\n15\nap_part_social [haven_labelled, vctrs_vctr, double]\nHogar carente en apoyo y participación social\n\n\n\nMin : 0\n\n\nMean : 0.1\n\n\nMax : 1\n\n\n\n\n\n\n0\n:\n9315\n(\n93.5%\n)\n\n\n1\n:\n652\n(\n6.5%\n)\n\n\n\n9967 (99.7%)\n33 (0.3%)\n\n\n16\ntrato [haven_labelled, vctrs_vctr, double]\nHogar carente en trato igualitario\n\n\n\nMin : 0\n\n\nMean : 0.2\n\n\nMax : 1\n\n\n\n\n\n\n0\n:\n8443\n(\n84.4%\n)\n\n\n1\n:\n1557\n(\n15.6%\n)\n\n\n\n10000 (100.0%)\n0 (0.0%)\n\n\n17\nseguridad [haven_labelled, vctrs_vctr, double]\nHogar carente en seguridad\n\n\n\nMin : 0\n\n\nMean : 0.1\n\n\nMax : 1\n\n\n\n\n\n\n0\n:\n9057\n(\n90.6%\n)\n\n\n1\n:\n943\n(\n9.4%\n)\n\n\n\n10000 (100.0%)\n0 (0.0%)\n\n\n18\nregion [haven_labelled, vctrs_vctr, double]\nRegión\n\n\n\nMean (sd) : 8.8 (4.3)\n\n\nmin ≤ med ≤ max:\n\n\n1 ≤ 8 ≤ 16\n\n\nIQR (CV) : 8 (0.5)\n\n\n\n16 distinct values\n10000 (100.0%)\n0 (0.0%)\n\n\n19\narea [haven_labelled, vctrs_vctr, double]\nÁrea\n\n\n\nMin : 1\n\n\nMean : 1.2\n\n\nMax : 2\n\n\n\n\n\n\n1\n:\n7907\n(\n79.1%\n)\n\n\n2\n:\n2093\n(\n20.9%\n)\n\n\n\n10000 (100.0%)\n0 (0.0%)\n\n\n\n\nGenerated by summarytools 1.0.1 (R version 4.4.0)2024-05-15\n\n\n\n\nEn esta base de datos, las variables de interés que están presentes (ej. asistencia, rezago, escolaridad) son variables dummy, es decir, variables que tienen como valores posibles 0 y 1. Donde 0 implica la ausencia de un atributo y 1 la presencia del mismo atributo.\nPara medir pobreza multidimensional, 1 indica la carencia de un servicio o cualidad, por ejemplo, se considera que un hogar es carente en escolaridad si al menos uno de sus integrantes mayores de 18 años ha alcanzado menos años de escolaridad que los establecidos por ley, de acuerdo a su edad. Por lo tanto, en la variable escolaridad 1) indica un hogar carente en escolaridad, que según nuestra base de datos corresponde a 3065 hogares (30.7% de nuestra sub-muestra).",
    "crumbs": [
      "Prácticos",
      "Talleres",
      "07: Práctico 7"
    ]
  },
  {
    "objectID": "practicos/07-content.html#medición-de-pobreza-multidimensional-en-cuatro-dimensiones-hasta-2014",
    "href": "practicos/07-content.html#medición-de-pobreza-multidimensional-en-cuatro-dimensiones-hasta-2014",
    "title": "Práctico 7. Índices y escalas",
    "section": "",
    "text": "Seleccionamos solo los indicadores que eran utilizados hasta 2014\n\n\nCódigo\nindicadores2014 &lt;- casen2022 %&gt;% select(asistencia, \n                                        rezago, \n                                        escolaridad, \n                                        malnutricion, \n                                        sist_salud, \n                                        atencion, \n                                        ocupacion, \n                                        seg_social, \n                                        jubilacion, \n                                        hacinamiento, \n                                        estado_vivienda=vivienda, \n                                        serv_basicos)  %&gt;% \n  na.omit() %&gt;% # Eliminar Na's\n  mutate_all(~(as.numeric(.))) # Convertimos todas las variables a numéricas\n\n\nCon la función mutate creamos una nueva variable para cada dimensión, que contenga el promedio simple de los tres indicadores correspondientes.\n\n\nCódigo\nindicadores2014 = indicadores2014 %&gt;% \n  rowwise() %&gt;%\n  mutate(educ = mean(c(asistencia, rezago, escolaridad)),\n         salud = mean(c(malnutricion, sist_salud, atencion)),\n         trabajo= mean(c(ocupacion, seg_social, jubilacion)),\n         vivienda= mean(c(hacinamiento, estado_vivienda, serv_basicos))) %&gt;% \n  ungroup()\n\n\nLuego, como la pobreza multidimensional consideraba cuatro dimensiones equivalentes (sin ponderar), es posible obtener el índice de pobreza multidimensional a partir del promedio de las cuatro dimensiones.\n\n\nCódigo\nindicadores2014 = indicadores2014 %&gt;% \n  rowwise() %&gt;%\n  mutate(pobreza = mean(c(educ, salud, trabajo, vivienda))) %&gt;% \n  ungroup()\n\n\nLo que nos da este resultado:\n\n\nCódigo\nindicadores2014 %&gt;% select(pobreza) %&gt;% head(10) # Primeros 10 casos\n\n\n# A tibble: 10 × 1\n   pobreza\n     &lt;dbl&gt;\n 1  0.167 \n 2  0.25  \n 3  0     \n 4  0.167 \n 5  0.167 \n 6  0.167 \n 7  0     \n 8  0.167 \n 9  0     \n10  0.0833\n\n\nCódigo\nsummary(indicadores2014$pobreza) # Resumen\n\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n0.00000 0.00000 0.08333 0.10142 0.16667 0.66667 \n\n\n¿Cómo podemos conocer el porcentaje total de pobreza multidimensional del país?\nEl PNUD considera como límite para el índice de cuatro dimensiones un 25% de pobreza multidimensional (lo que equivale a tener carencia en los tres indicadores de una dimensión). Por lo tanto, podemos utilizar un condicional que indique “si” existe pobreza muldimensional cuando nuestra variable “pobreza” sea mayor o igual a 0.25 y que indique que “no” existe pobreza multidimensional cuando la variable “pobreza” sea menor a 0.25. case_when viene en dplyr.\n\n\nCódigo\nindicadores2014 &lt;- indicadores2014 %&gt;% mutate(pobreza = case_when(pobreza&gt;=0.25~\"si\",\n                                                      pobreza&lt;0.25~\"no\")\n                           )\nprop.table(table(indicadores2014$pobreza))*100\n\n\n\n      no       si \n87.03161 12.96839 \n\n\nSegún el análisis realizado con la submuestra aleatoria de la CASEN, considerando las cuatro dimensiones que se utilizaban hasta el 2014, existe un 12.97% de pobreza multidimensional en Chile",
    "crumbs": [
      "Prácticos",
      "Talleres",
      "07: Práctico 7"
    ]
  },
  {
    "objectID": "practicos/07-content.html#medición-de-pobreza-multidimensional-en-cinco-dimensiones-desde-2016",
    "href": "practicos/07-content.html#medición-de-pobreza-multidimensional-en-cinco-dimensiones-desde-2016",
    "title": "Práctico 7. Índices y escalas",
    "section": "",
    "text": "Veamos ahora el mismo proceso, pero considerando la quinta dimensión que fue agregada en 2016 sobre Redes y Cohesión Social.\n\nEn esta operacionalización del índice de pobreza multidimensional las cuatro dimensiones originales equivalen a un 22.5% cada una, mientras que la nueva dimensión de redes y cohesión social equivale a un 10%.\nSeleccionemos solo los indicadores que son utilizados desde 2016.\n\n\nCódigo\nindicadores2016 &lt;- casen2022 %&gt;% select(asistencia, \n                                        rezago, \n                                        escolaridad, \n                                        malnutricion, \n                                        sist_salud, \n                                        atencion, \n                                        ocupacion, \n                                        seg_social, \n                                        jubilacion, \n                                        habitabilidad, \n                                        serv_basicos,\n                                        entorno,\n                                        ap_part_social,\n                                        trato,\n                                        seguridad,\n                                        area,\n                                        region) %&gt;% \n  na.omit() %&gt;% # Eliminar Na's\n  mutate_all(~(as.numeric(.))) # Convertimos todas las variables a numéricas\n\n\nSeguimos los mismos pasos que con el índice anterior, estimando un promedio simple para cada una de las dimensiones.\n\n\nCódigo\nindicadores2016 = indicadores2016 %&gt;% \n  rowwise() %&gt;%\n  mutate(educ = mean(c(asistencia, rezago, escolaridad)),\n         salud = mean(c(malnutricion, sist_salud, atencion)),\n         trabajo= mean(c(ocupacion, seg_social, jubilacion)),\n         vivienda= mean(c(habitabilidad, serv_basicos, entorno)),\n         redes_cohesion= mean(c(ap_part_social, trato, seguridad))) %&gt;% \n  ungroup()\n\n\nSin embargo, como en esta ocasión se trata de un índice ponderado (con dimensiones con distinto peso cada una), multiplicamos cada dimensión por su peso correspondiente y las sumamos.\n\n\nCódigo\nindicadores2016 = indicadores2016 %&gt;% \n  rowwise() %&gt;%\n  mutate(pobreza_pond = (educ*22.5) + (salud*22.5) + (trabajo*22.5) + (vivienda*22.5) + (redes_cohesion*10)) %&gt;%  \n  ungroup()\n\n\nLo que nos da este resultado:\n\n\nCódigo\nindicadores2016 %&gt;% select(pobreza_pond) %&gt;% head(10) # Primeros 10 casos\n\n\n# A tibble: 10 × 1\n   pobreza_pond\n          &lt;dbl&gt;\n 1        18.3 \n 2        22.5 \n 3         3.33\n 4        22.5 \n 5        15   \n 6        15   \n 7         0   \n 8        15   \n 9         0   \n10        18.3 \n\n\nCódigo\nsummary(indicadores2016$pobreza_pond) # Resumen\n\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  0.000   3.333   7.500  10.988  15.000  62.500 \n\n\n¿Cómo podemos conocer el porcentaje total de pobreza multidimensional del país?\nEl PNUD considera como límite para el índice de cinco dimensiones un 22.5% de pobreza multidimensional (lo que equivale a tener carencia en los tres indicadores de una dimensión). Por lo tanto, podemos utilizar un condicional que indique “si” existe pobreza muldimensional cuando nuestra variable “pobreza” sea mayor o igual a 22.5 y que indique que “no” existe pobreza multidimensional cuando la variable “pobreza” sea menor a 22.5.\n\n\nCódigo\nindicadores2016 &lt;- indicadores2016 %&gt;% mutate(pobreza = case_when(pobreza_pond&gt;=22.5~\"si\",\n                                                      pobreza_pond&lt;22.5~\"no\")\n                           )\n                          \nprop.table(table(indicadores2016$pobreza))*100\n\n\n\n      no       si \n84.18912 15.81088 \n\n\nSegún el análisis realizado con la submuestra aleatoria de la CASEN, considerando las cinco dimensiones que se comenzaron a utilizar en 2016, existe un 15.73% de pobreza multidimensional en Chile.\n\n\nPodemos utilizar otras variables de la CASEN para poder conocer cómo se distribuye la pobreza multidimensional en Chile. Por ejemplo, porcentaje de pobreza multidimensional por región:\n\n\nCódigo\nprop.table(table(indicadores2016$region, indicadores2016$pobreza), margin = 1)\n\n\n    \n            no        si\n  1  0.7965261 0.2034739\n  2  0.7975000 0.2025000\n  3  0.8097345 0.1902655\n  4  0.8484108 0.1515892\n  5  0.8487230 0.1512770\n  6  0.8826025 0.1173975\n  7  0.8703170 0.1296830\n  8  0.8543689 0.1456311\n  9  0.8083736 0.1916264\n  10 0.7571702 0.2428298\n  11 0.8910891 0.1089109\n  12 0.9531250 0.0468750\n  13 0.8496241 0.1503759\n  14 0.8079096 0.1920904\n  15 0.8575198 0.1424802\n  16 0.8536585 0.1463415\n\n\no pobreza multidimensional por zona geográfica 1) urbano 2) rural\n\n\nCódigo\nprop.table(table(indicadores2016$area, indicadores2016$pobreza), margin = 1)\n\n\n   \n           no        si\n  1 0.8735691 0.1264309\n  2 0.7223301 0.2776699",
    "crumbs": [
      "Prácticos",
      "Talleres",
      "07: Práctico 7"
    ]
  },
  {
    "objectID": "practicos/07-content.html#presentación-1",
    "href": "practicos/07-content.html#presentación-1",
    "title": "Práctico 7. Índices y escalas",
    "section": "Presentación",
    "text": "Presentación\nPara el taller práctico de hoy utilizaremos la base de datos del Estudio Longitudinal Social de Chile, realizado por el Centro de estudios del conflicto y la cohesión social COES.\nEl Estudio Longitudinal Social del Chile ELSOC, único en Chile y América Latina, consiste en encuestar a casi 3.000 chilenos, anualmente, a lo largo de una década. ELSOC ha sido diseñado para evaluar la manera cómo piensan, sienten y se comportan los chilenos en torno a un conjunto de temas referidos al conflicto y la cohesión social en Chile. La población objetivo son hombres y mujeres entre 15 y 75 años de edad, tiene una representación de la población nacional urbana, donde se obtuvo una muestra original de 2927 casos en el año 2016 y mantiene 1728 en 2022, además de una muestra de refresco en 2018.",
    "crumbs": [
      "Prácticos",
      "Talleres",
      "07: Práctico 7"
    ]
  },
  {
    "objectID": "practicos/07-content.html#objetivo-general-1",
    "href": "practicos/07-content.html#objetivo-general-1",
    "title": "Práctico 7. Índices y escalas",
    "section": "Objetivo general",
    "text": "Objetivo general\nEl objetivo de este ejercicio del práctico es revisar el proceso de construcción y validación de escalas en R.\n\nCargar base de datos\n\n\nCódigo\nload(url(\"https://dataverse.harvard.edu/api/access/datafile/7245118\")) #Cargar base de datos\n\n\n\n\nVisualización de datos\n\n\nCódigo\ndim(elsoc_long_2016_2022.2)\n\n\n[1] 18035   750\n\n\nDebido a la naturaleza longitudinal de ELSOC, la base de datos contiene 18035 casos (las mismas personas durante 6 años) y 750 variables (las mismas variables en 6 periodos distintos). Por lo tanto, para simplificar el proceso de análisis de este práctico trabajaremos solo con los casos y variables de quienes participaron en la primera ola (2016)",
    "crumbs": [
      "Prácticos",
      "Talleres",
      "07: Práctico 7"
    ]
  },
  {
    "objectID": "practicos/07-content.html#datos-y-variables-1",
    "href": "practicos/07-content.html#datos-y-variables-1",
    "title": "Práctico 7. Índices y escalas",
    "section": "Datos y variables",
    "text": "Datos y variables\nPara el ejercicio de escalas, utilizaremos nuevamente la base de datos de ELSOC (que ya se enceuntra cargada), específicamente el módulo de Salud y Bienestar. De este módulo utilizaremos un concepto en particular llamado Estado de ánimo: sintomatología depresiva con los ítems:\n\nFrecuencia: Poco interés o alegría\nFrecuencia: Decaimiento, pesadez o desesperanza\nFrecuencia: Dificultad para dormir o exceso de sueño\nFrecuencia: Cansancio o sensación de falta de energía\nFrecuencia: Apetito disminuido o aumentado\nFrecuencia: Dificultad para concentrarse\nFrecuencia: Mala opinión de sí mismo\nFrecuencia: Enlentecimiento físico\nFrecuencia: Pensamiento de muerte o dañarse\n\nEsta escala tiene solamente una dimensión, por lo que no es necesario crear objetos que contengan a cada dimensión (como vimos la clase pasada).",
    "crumbs": [
      "Prácticos",
      "Talleres",
      "07: Práctico 7"
    ]
  },
  {
    "objectID": "practicos/07-content.html#filtrar-base-de-datos",
    "href": "practicos/07-content.html#filtrar-base-de-datos",
    "title": "Práctico 7. Índices y escalas",
    "section": "Filtrar base de datos",
    "text": "Filtrar base de datos\nFiltraremos la base de datos para quedarnos con las observaciones correspondientes solamente a la ola 1, y además seleccionaremos los ítems de interés.\n\n\nCódigo\ndata2 &lt;- elsoc_long_2016_2022.2 %&gt;% filter(ola==1) %&gt;%  # seleccionamos solo los casos de la ola 1\n  select(s11_01,s11_02,s11_03,s11_04,s11_05,s11_06,s11_07,s11_08,s11_09) # items sintomatologia depresiva\n\nhead(data2)\n\n\n  s11_01 s11_02 s11_03 s11_04 s11_05 s11_06 s11_07 s11_08 s11_09\n1      5      3      3      5      4      3      3      3      1\n2      2      2      3      2      3      4      3      4      2\n3      2      2      3      3      4      5      4      1      2\n4      1      3      3      1      1      2      3      5      1\n5      1      1      1      2      1      3      1      2      1\n6      1      1      1      1      1      1      1      1      1\n\n\nCódigo\ntable(data2$s11_01)\n\n\n\n-999 -888    1    2    3    4    5 \n   5    1 1279 1196  158  192   96 \n\n\nCódigo\ntable(data2$s11_02)\n\n\n\n-999 -888    1    2    3    4    5 \n   5    1 1302 1316  135  120   48 \n\n\nCódigo\ntable(data2$s11_03)\n\n\n\n-999 -888    1    2    3    4    5 \n   3    1 1336 1014  179  265  129 \n\n\nCódigo\ntable(data2$s11_04)\n\n\n\n-999 -888    1    2    3    4    5 \n   1    1  887 1414  223  261  140 \n\n\nEstos ítems cuentan con las mismas categorías de respuesta: (1) Nunca, (2) Algunos dias, (3) Mas de la mitad de los dias, (4) Casi todos los dias, y (5) Todos los dias. Además de los valores codificados como -888 y -999.\n\nRecodificar\nRecodificamos los valores -888 y -999 en NA y eliminamos los NAs.\n\n\nCódigo\ndata2 &lt;- data2 %&gt;% \n  set_na(., na = c(-888, -999)) %&gt;% \n  na.omit()",
    "crumbs": [
      "Prácticos",
      "Talleres",
      "07: Práctico 7"
    ]
  },
  {
    "objectID": "practicos/07-content.html#análisis",
    "href": "practicos/07-content.html#análisis",
    "title": "Práctico 7. Índices y escalas",
    "section": "Análisis",
    "text": "Análisis\n\nEstimar correlación\nDado que la escala tiene solamente una dimensión, estimaremos la correlación de toda la escala.\n\n\nCódigo\ncor(data2)\n\n\n          s11_01    s11_02    s11_03    s11_04    s11_05    s11_06    s11_07\ns11_01 1.0000000 0.4853523 0.3737498 0.3725855 0.3574690 0.3049018 0.3021299\ns11_02 0.4853523 1.0000000 0.4994332 0.5552978 0.4226467 0.4138983 0.4251018\ns11_03 0.3737498 0.4994332 1.0000000 0.5592702 0.4858813 0.3902507 0.3691240\ns11_04 0.3725855 0.5552978 0.5592702 1.0000000 0.5169337 0.4585532 0.4035490\ns11_05 0.3574690 0.4226467 0.4858813 0.5169337 1.0000000 0.4119218 0.3685431\ns11_06 0.3049018 0.4138983 0.3902507 0.4585532 0.4119218 1.0000000 0.4286404\ns11_07 0.3021299 0.4251018 0.3691240 0.4035490 0.3685431 0.4286404 1.0000000\ns11_08 0.3007859 0.3936463 0.3492633 0.3940693 0.3572599 0.4228090 0.5060767\ns11_09 0.2347939 0.3884992 0.3026768 0.3330739 0.3040960 0.3445456 0.5080698\n          s11_08    s11_09\ns11_01 0.3007859 0.2347939\ns11_02 0.3936463 0.3884992\ns11_03 0.3492633 0.3026768\ns11_04 0.3940693 0.3330739\ns11_05 0.3572599 0.3040960\ns11_06 0.4228090 0.3445456\ns11_07 0.5060767 0.5080698\ns11_08 1.0000000 0.4560839\ns11_09 0.4560839 1.0000000\n\n\nPodemos observar que todas las correlaciones son positivas, por lo que no quedaron ítems invertidos.\n\n\nEstimar consistencia interna\n\nAlfa de Chronbach\nPrimero, estimaremos la consistencia interna de cada dimensión con un Alfa de Chronbach.\n\n\nCódigo\npsych::alpha(data2)\n\n\n\nReliability analysis   \nCall: psych::alpha(x = data2)\n\n  raw_alpha std.alpha G6(smc) average_r S/N    ase mean   sd median_r\n      0.85      0.86    0.85       0.4 6.1 0.0039  1.7 0.64     0.39\n\n    95% confidence boundaries \n         lower alpha upper\nFeldt     0.85  0.85  0.86\nDuhachek  0.85  0.85  0.86\n\n Reliability if an item is dropped:\n       raw_alpha std.alpha G6(smc) average_r S/N alpha se  var.r med.r\ns11_01      0.85      0.85    0.85      0.42 5.8   0.0041 0.0050  0.41\ns11_02      0.83      0.84    0.83      0.39 5.1   0.0046 0.0062  0.37\ns11_03      0.84      0.84    0.83      0.40 5.3   0.0045 0.0058  0.40\ns11_04      0.83      0.84    0.83      0.39 5.1   0.0047 0.0051  0.39\ns11_05      0.84      0.84    0.84      0.40 5.4   0.0044 0.0065  0.39\ns11_06      0.84      0.84    0.84      0.40 5.4   0.0044 0.0072  0.39\ns11_07      0.84      0.84    0.83      0.40 5.3   0.0044 0.0065  0.39\ns11_08      0.84      0.84    0.84      0.40 5.4   0.0043 0.0067  0.40\ns11_09      0.85      0.85    0.84      0.42 5.7   0.0042 0.0051  0.41\n\n Item statistics \n          n raw.r std.r r.cor r.drop mean   sd\ns11_01 2888  0.62  0.61  0.53   0.49  1.8 1.01\ns11_02 2888  0.74  0.74  0.71   0.66  1.7 0.85\ns11_03 2888  0.73  0.70  0.66   0.62  1.9 1.13\ns11_04 2888  0.77  0.75  0.72   0.67  2.1 1.07\ns11_05 2888  0.71  0.69  0.63   0.59  1.8 1.07\ns11_06 2888  0.68  0.68  0.62   0.57  1.6 0.96\ns11_07 2888  0.67  0.70  0.65   0.58  1.4 0.80\ns11_08 2888  0.66  0.68  0.62   0.56  1.4 0.85\ns11_09 2888  0.58  0.63  0.56   0.50  1.2 0.61\n\nNon missing response frequency for each item\n          1    2    3    4    5 miss\ns11_01 0.44 0.41 0.05 0.06 0.03    0\ns11_02 0.45 0.45 0.05 0.04 0.02    0\ns11_03 0.46 0.35 0.06 0.09 0.04    0\ns11_04 0.31 0.48 0.08 0.09 0.05    0\ns11_05 0.51 0.33 0.05 0.07 0.04    0\ns11_06 0.63 0.26 0.05 0.05 0.03    0\ns11_07 0.72 0.21 0.03 0.03 0.01    0\ns11_08 0.73 0.19 0.03 0.03 0.02    0\ns11_09 0.86 0.10 0.02 0.01 0.01    0\n\n\n\n\nCódigo\ndata2 &lt;- data2 %&gt;% \n  rowwise() %&gt;% \n  mutate(sintomatologia_depresiva = sum(s11_01,s11_02,s11_03,s11_04,s11_05,s11_06,s11_07,s11_08,s11_09))\nsummary(data2$sintomatologia_depresiva)\n\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n   9.00   11.00   14.00   14.99   17.00   45.00 \n\n\n¿Tiene sentido una escala de 9 a 45? No, por eso generalmente se recomienda que las variables ordinales partan en ‘0’ para que el comienzo de la escala también sea 0. En ese caso, deberíamos recodificar las 9 variables en una escala de 0 a 4.",
    "crumbs": [
      "Prácticos",
      "Talleres",
      "07: Práctico 7"
    ]
  },
  {
    "objectID": "practicos/index.html",
    "href": "practicos/index.html",
    "title": "Actividades prácticas en R",
    "section": "",
    "text": "En esta sección encontrarán todas las sesiones prácticas de R, realizadas durante el segundo bloque de clases, y que son fundamentales para la correcta realización de los trabajos.",
    "crumbs": [
      "Prácticos",
      "Información general",
      "Actividades prácticas en R"
    ]
  },
  {
    "objectID": "practicos/resumen-content.html",
    "href": "practicos/resumen-content.html",
    "title": "Resumen",
    "section": "",
    "text": "Como siempre, estas guías no apuntan a ser un paso a paso de lo que se debe hacer, sino que son un ejemplo concreto de cómo hacer ciertos tipos de análisis con un conjunto de datos determinados. Los procedimientos de limpieza van a depender siempre del conjunto de datos que utilicemos en nuestras investigaciones y el proceso de análisis va a depender de nuestros objetivos de investigación, en relación con las variables e hipótesis que queramos demostrar.\nEl desarrollo de esta guía tiene por objetivo revisar todos los contenidos trabajados hasta este momento del curso (07/05/2024). En términos generales, es un resumen de las cosas esenciales de los 7 prácticos anteriores como limpieza y preparación de datos, análisis descriptivo, bivariado y visualización de datos en Quarto y subida a github y visualización de github pages.\nEn concreto, un ejemplo del resultado final de un trabajo se debería poder visualizar así en un repositorio de github y en Github pages\nPor temas de orden y reproducibilidad, en este curso hemos separado en dos momentos el trabajo con datos, y dos archivos de código correspondientes:\n\nPreparación corresponde a lo que se conoce generalmente como “limpieza”, es decir, realizar las modificaciones necesarias para poder efectuar los análisis. Estas modificaciones previas al análisis son necesarias ya que los datos originales con los que se va a trabajar en general no vienen perfectamente adaptados a los análisis que se quieren hacer. Por lo tanto, en cuanto a datos también hacemos la distinción entre datos originales y datos preparados (o procesados). Este código de análisis lo podemos encontrar en la carpeta procesamiento del repositorio\nAnálisis: se relaciona tanto con análisis descriptivos asociados a las preguntas de investigación y como también modelamiento de datos para contrastar hipótesis de investigación. En este curso lo esencial es visualizar el análisis a través de quarto, por lo que el documento .qmd debería estar en el inicio del repositorio (junto al Rproject). Este documento se debe renderizar y obtenemos un archivo .html que se podría visualizar a través de github pages en, por ejemplo, el link: https://kevin-carrasco.github.io/ipo/trabajo.html. Dónde:\n\n\nVamos paso a paso",
    "crumbs": [
      "Prácticos",
      "Talleres",
      "08: Resumen"
    ]
  },
  {
    "objectID": "practicos/resumen-content.html#objetivo-de-la-práctica",
    "href": "practicos/resumen-content.html#objetivo-de-la-práctica",
    "title": "Resumen",
    "section": "",
    "text": "Como siempre, estas guías no apuntan a ser un paso a paso de lo que se debe hacer, sino que son un ejemplo concreto de cómo hacer ciertos tipos de análisis con un conjunto de datos determinados. Los procedimientos de limpieza van a depender siempre del conjunto de datos que utilicemos en nuestras investigaciones y el proceso de análisis va a depender de nuestros objetivos de investigación, en relación con las variables e hipótesis que queramos demostrar.\nEl desarrollo de esta guía tiene por objetivo revisar todos los contenidos trabajados hasta este momento del curso (07/05/2024). En términos generales, es un resumen de las cosas esenciales de los 7 prácticos anteriores como limpieza y preparación de datos, análisis descriptivo, bivariado y visualización de datos en Quarto y subida a github y visualización de github pages.\nEn concreto, un ejemplo del resultado final de un trabajo se debería poder visualizar así en un repositorio de github y en Github pages\nPor temas de orden y reproducibilidad, en este curso hemos separado en dos momentos el trabajo con datos, y dos archivos de código correspondientes:\n\nPreparación corresponde a lo que se conoce generalmente como “limpieza”, es decir, realizar las modificaciones necesarias para poder efectuar los análisis. Estas modificaciones previas al análisis son necesarias ya que los datos originales con los que se va a trabajar en general no vienen perfectamente adaptados a los análisis que se quieren hacer. Por lo tanto, en cuanto a datos también hacemos la distinción entre datos originales y datos preparados (o procesados). Este código de análisis lo podemos encontrar en la carpeta procesamiento del repositorio\nAnálisis: se relaciona tanto con análisis descriptivos asociados a las preguntas de investigación y como también modelamiento de datos para contrastar hipótesis de investigación. En este curso lo esencial es visualizar el análisis a través de quarto, por lo que el documento .qmd debería estar en el inicio del repositorio (junto al Rproject). Este documento se debe renderizar y obtenemos un archivo .html que se podría visualizar a través de github pages en, por ejemplo, el link: https://kevin-carrasco.github.io/ipo/trabajo.html. Dónde:\n\n\nVamos paso a paso",
    "crumbs": [
      "Prácticos",
      "Talleres",
      "08: Resumen"
    ]
  },
  {
    "objectID": "practicos/resumen-content.html#flujo",
    "href": "practicos/resumen-content.html#flujo",
    "title": "Resumen",
    "section": "Los procesos de preparación y análisis vinculados a datos y resultados se presentan en el siguiente esquema:",
    "text": "Los procesos de preparación y análisis vinculados a datos y resultados se presentan en el siguiente esquema:\n\nTanto la preparación como el análisis (que son parte del concepto más general de procesamiento) quedan registrados cada uno en un archivo de código.\nArchivo de código R: archivo con extensión .R donde se almacena el código de análisis. Para generarlo desde RStudio: File &gt; New File &gt; R Script (o ctrl+shift+N), y para grabarlo File &gt; Save (o ctrl+s), y darle nombre la primera vez (recordar: sin tilde ni ñ, y evitar espacios) \nEl documento de código de preparación posee 5 partes, más una sección de identificación inicial:\n\nIdentificación y descripción general: Título, autor(es), fecha, información breve sobre el contenido del documento\nLibrerías: cargar librerías a utilizar\nDatos: carga de datos\nSelección de variables a utilizar\nProcesamiento de variables: en este punto, por cada variable se realiza lo siguiente:\n\nDescriptivo básico\nRecodificación: datos perdidos y valores (en caso de ser necesario)\nEtiquetamiento: de variable y valores (en caso de ser necesario)\nOtros ajustes\n\nGeneración de base de datos preparada para el análisis.\n\n\nDe rutas, estructura de carpetas y otros \n\nEncontrando la ruta a carpeta local: lo más fácil es crear la carpeta donde se desean guardar los datos desde el administrador de archivos del computador. Luego, posicionarse con el cursor sobre la carpeta y seleccionar “Propiedades”, en la ventana emergente debería aparecer la ruta hacia la carpeta en “Ubicación”. Copiar esa ruta y agregar al final el nombre de la carpeta (separada por slash)\nSobre los “slashes” (\\ o /): en la ruta las carpetas y el archivo final aparecen separados por slashes, que según el sistema utilizado pueden ser slash (/) o backslash (\\). En R por defecto se usa slash, pero en Windows backslash, por lo que si se usa Windows hay que reemplazarlos por backslash o también puede ser por un doble slash (//).\nPor temas de compatibilidad general, en las rutas se recomienda evitar tildes, eñes, espacios, mayúsculas y guiones bajos (_).\nEstructura de carpetas: para mantener el orden se sugiere seguir un protocolo de estructura de carpetas de proyecto, para lo que recomendamos el protocolo IPO, y que se adapta al flujo de trabajo presentado anteriormente. Básicamente son tres carpetas: input, procesamiento, output. En la carpeta input crear la subcarpeta data-orig para guardar datos originales, y data-proc para los procesados. En procesamiento se guardan los archivos de código y en output las tablas y los gráficos.\n\n\n\n\nNuestras carpetas se deberían ver así:\n\nDonde lo primero que debemos hacer, siempre, es abrir el Rproject (.Rproj) para comenzar nuestro trabajo.",
    "crumbs": [
      "Prácticos",
      "Talleres",
      "08: Resumen"
    ]
  },
  {
    "objectID": "practicos/resumen-content.html#antecedentes-de-los-datos-a-utilizar",
    "href": "practicos/resumen-content.html#antecedentes-de-los-datos-a-utilizar",
    "title": "Resumen",
    "section": "Antecedentes de los datos a utilizar",
    "text": "Antecedentes de los datos a utilizar\nCohesión barrial con elsoc 2016",
    "crumbs": [
      "Prácticos",
      "Talleres",
      "08: Resumen"
    ]
  },
  {
    "objectID": "practicos/resumen-content.html#librerias",
    "href": "practicos/resumen-content.html#librerias",
    "title": "Resumen",
    "section": "1. Librerías principales (de R) a utilizar en el análisis",
    "text": "1. Librerías principales (de R) a utilizar en el análisis\n\n\nCódigo\npacman::p_load(dplyr, sjmisc, car, sjlabelled, stargazer, haven, sjPlot, ggplot2, psych)",
    "crumbs": [
      "Prácticos",
      "Talleres",
      "08: Resumen"
    ]
  },
  {
    "objectID": "practicos/resumen-content.html#cargar-base-de-datos",
    "href": "practicos/resumen-content.html#cargar-base-de-datos",
    "title": "Resumen",
    "section": "2. Cargar base de datos",
    "text": "2. Cargar base de datos\nAjustar espacio de trabajo\nPrevio a la carga de nuestra base de datos, se recomienda ejecutar los siguientes comandos:\n\n\nCódigo\nrm(list=ls())       # borrar todos los objetos en el espacio de trabajo\noptions(scipen=999) # valores sin notación científica\n\n\nLa función rm(list=ls()) permite comenzar con un espacio de trabajo (environment) vacío y sin otros objetos. Así también, la función options(scipen=999) desactiva la notación científica, es decir, veremos los valores numéricos con todos sus decimales.\nDatos\nLas bases de datos se pueden cargar de un archivo local o en línea. Para este caso utilizaremos un archivo en línea que viene en formato RData: elsoc.RData. Abrir bases de datos en otros formatos: Los formatos mas comunes en que se almacenan las bases de datos son .dta (Stata), .sav (Spss) y RData (R). Para abrir desde R utlilizamos la librería haven y sus funciones read_dta y read_sav según corresponda. Ej: datos &lt;- read_dta(\"base_casen.dta\"). Recordar antes instalar/cargar la librería: pacman::p_load(haven) \n\n\nCódigo\n#cargamos la base de datos desde internet\nload(url(\"https://dataverse.harvard.edu/api/access/datafile/7245118\")) #Cargar base de datos\n\n\nRealizamos un chequeo básico de la lectura de datos: nombres de las variables y tamaño de la base en términos de casos y variables (en este ejemplo, 18035, 750 ).\n\n\nCódigo\ndim(elsoc_long_2016_2022.2) # dimension de la base\n\n\n[1] 18035   750",
    "crumbs": [
      "Prácticos",
      "Talleres",
      "08: Resumen"
    ]
  },
  {
    "objectID": "practicos/resumen-content.html#selección-de-variables-a-utilizar",
    "href": "practicos/resumen-content.html#selección-de-variables-a-utilizar",
    "title": "Resumen",
    "section": "3. Selección de variables a utilizar",
    "text": "3. Selección de variables a utilizar\nEste paso consiste en crear un subset reducido de datos que contenga solo las variables de interés. Para ello lo más fácil es revisar el libro de códigos de cada base de datos. Además filtramos por la ola 1 para trabajar solo con datos del 2016.\n\n\nCódigo\nproc_data &lt;- elsoc_long_2016_2022.2 %&gt;% filter(ola==\"1\") %&gt;% \n  select(t02_01, # Este barrio es ideal para mi\n         t02_02, # Me siento incluido en este barrio\n         t02_03, # Me identifico con la gente de este barrio\n         t02_04, # Este barrio es parte de mi\n         m01,# nivel educacional\n         m0_sexo,# sexo\n         m0_edad# edad\n         )\n\n# Comprobar\nnames(proc_data)\n\n\n[1] \"t02_01\"  \"t02_02\"  \"t02_03\"  \"t02_04\"  \"m01\"     \"m0_sexo\" \"m0_edad\"\n\n\nMediante el comando get_label obtenemos el atributo label de las variables.\n\n\nCódigo\nsjlabelled::get_label(proc_data)\n\n\n                                                       t02_01 \n          \"Grado de acuerdo: Este es el barrio ideal para mi\" \n                                                       t02_02 \n     \"Grado de acuerdo: Me siento integrado/a en este barrio\" \n                                                       t02_03 \n\"Grado de acuerdo: Me identifico con la gente de este barrio\" \n                                                       t02_04 \n               \"Grado de acuerdo: Este barrio es parte de mi\" \n                                                          m01 \n                                          \"Nivel educacional\" \n                                                      m0_sexo \n                                      \"Sexo del entrevistado\" \n                                                      m0_edad \n                                      \"Edad del entrevistado\" \n\n\nPodemos ver que son largas o con códigos poco informativos, por lo tanto, es necesario cambiarlas por etiquetas más cortas y de fácil identificación.",
    "crumbs": [
      "Prácticos",
      "Talleres",
      "08: Resumen"
    ]
  },
  {
    "objectID": "practicos/resumen-content.html#procesamiento-de-variables",
    "href": "practicos/resumen-content.html#procesamiento-de-variables",
    "title": "Resumen",
    "section": "Procesamiento de variables",
    "text": "Procesamiento de variables\nPara el procesamiento de cada variable se seguirá el siguiente flujo de trabajo:\n\nDescriptivo general\nRecodificación: de casos perdidos y otros valores (en caso necesario)\nEtiquetado: cambio de nombres de variables y valores (en caso necesario)\nOtros ajustes\n\nY se recomienda también un descriptivo final para revisar que el procesamiento de cada variable está ok.\n\ncohesión barrial\na. Descriptivo\nPara los descriptivos se utilizará la función frq, de la librería sjmisc:\n\n\nCódigo\nfrq(proc_data$t02_01)\n\n\nGrado de acuerdo: Este es el barrio ideal para mi (x) &lt;numeric&gt; \n# total N=2927 valid N=2927 mean=3.31 sd=16.51\n\nValue |                                 Label |    N | Raw % | Valid % | Cum. %\n-------------------------------------------------------------------------------\n -999 |                           No Responde |    0 |  0.00 |    0.00 |   0.00\n -888 |                               No Sabe |    1 |  0.03 |    0.03 |   0.03\n -777 |       Valor perdido por error tecnico |    0 |  0.00 |    0.00 |   0.03\n -666 | Valor perdido por encuesta incompleta |    0 |  0.00 |    0.00 |   0.03\n    1 |              Totalmente en desacuerdo |  114 |  3.89 |    3.89 |   3.93\n    2 |                         En desacuerdo |  413 | 14.11 |   14.11 |  18.04\n    3 |        Ni de acuerdo ni en desacuerdo |  379 | 12.95 |   12.95 |  30.99\n    4 |                            De acuerdo | 1599 | 54.63 |   54.63 |  85.62\n    5 |                 Totalmente de acuerdo |  421 | 14.38 |   14.38 | 100.00\n &lt;NA&gt; |                                  &lt;NA&gt; |    0 |  0.00 |    &lt;NA&gt; |   &lt;NA&gt;\n\n\nEn esta variable vemos valores asociados a la opción “No contesta” (-999) y “No sabe” (-888), (-777) y (-666) que corresponde definirlos como casos perdidos (en el caso de R, como casos NA). El resto de los valores y etiquetas se encuentran en un orden correcto. Sin embargo, si queremos construir una escala, lo mejor es dejar los valores de 0 a 4\nb. Recodificación\nDespués de revisar el libro de códigos, no hay variables en que los valores negativos representen alguna otra característica, así que podemos usar set_na\n\n\nCódigo\nproc_data &lt;- proc_data %&gt;% set_na(., na = c(-999, -888, -777, -666))\n\n\n\n\nCódigo\nfrq(proc_data$t02_01)\n\n\nGrado de acuerdo: Este es el barrio ideal para mi (x) &lt;numeric&gt; \n# total N=2927 valid N=2926 mean=3.62 sd=1.02\n\nValue |                          Label |    N | Raw % | Valid % | Cum. %\n------------------------------------------------------------------------\n    1 |       Totalmente en desacuerdo |  114 |  3.89 |    3.90 |   3.90\n    2 |                  En desacuerdo |  413 | 14.11 |   14.11 |  18.01\n    3 | Ni de acuerdo ni en desacuerdo |  379 | 12.95 |   12.95 |  30.96\n    4 |                     De acuerdo | 1599 | 54.63 |   54.65 |  85.61\n    5 |          Totalmente de acuerdo |  421 | 14.38 |   14.39 | 100.00\n &lt;NA&gt; |                           &lt;NA&gt; |    1 |  0.03 |    &lt;NA&gt; |   &lt;NA&gt;\n\n\nPara reordenar las categorías volvemos a utilizar la función recode, de la librería car\n\n\nCódigo\nproc_data$t02_01 &lt;- recode(proc_data$t02_01, \"1=0; 2=1; 3=2; 4=3; 5=4\")\nproc_data$t02_02 &lt;- recode(proc_data$t02_02, \"1=0; 2=1; 3=2; 4=3; 5=4\")\nproc_data$t02_03 &lt;- recode(proc_data$t02_03, \"1=0; 2=1; 3=2; 4=3; 5=4\")\nproc_data$t02_04 &lt;- recode(proc_data$t02_04, \"1=0; 2=1; 3=2; 4=3; 5=4\")\n\n\nc - Etiquetado\nVamos a dar un nombre más sustantivo a las variables con la función rename, de la librería dplyr:\n\n\nCódigo\nproc_data &lt;- proc_data %&gt;% rename(\"ideal\"=t02_01, \n                                  \"integracion\"=t02_02, \n                                  \"identificacion\"=t02_03, \n                                  \"pertenencia\"=t02_04)\n\n\nAdemás de cambiar el nombre, queremos cambiar las etiquetas de las variables.\n\n\nCódigo\nproc_data$ideal &lt;- set_label(x = proc_data$ideal,label = \"Este barrio es ideal para mi\")\nget_label(proc_data$ideal)\n\n\n[1] \"Este barrio es ideal para mi\"\n\n\nCódigo\nproc_data$integracion  &lt;- set_label(x = proc_data$integracion, label = \"Me siento integrado en este barrio\")\nget_label(proc_data$integracion)\n\n\n[1] \"Me siento integrado en este barrio\"\n\n\nCódigo\nproc_data$identificacion  &lt;- set_label(x = proc_data$identificacion, label = \"Me identifico con la gente de este barrio\")\nget_label(proc_data$identificacion)\n\n\n[1] \"Me identifico con la gente de este barrio\"\n\n\nCódigo\nproc_data$pertenencia  &lt;- set_label(x = proc_data$pertenencia, label = \"Me siento parte de este barrio\")\nget_label(proc_data$pertenencia)\n\n\n[1] \"Me siento parte de este barrio\"\n\n\nRevisión final\nNuevamente un descriptivo de cada variable para confirmar que el procesamiento está ok:\n\n\nCódigo\nfrq(proc_data$ideal)\n\n\nEste barrio es ideal para mi (x) &lt;numeric&gt; \n# total N=2927 valid N=2926 mean=2.62 sd=1.02\n\nValue |                          Label |    N | Raw % | Valid % | Cum. %\n------------------------------------------------------------------------\n    0 |                              0 |  114 |  3.89 |    3.90 |   3.90\n    1 |       Totalmente en desacuerdo |  413 | 14.11 |   14.11 |  18.01\n    2 |                  En desacuerdo |  379 | 12.95 |   12.95 |  30.96\n    3 | Ni de acuerdo ni en desacuerdo | 1599 | 54.63 |   54.65 |  85.61\n    4 |                     De acuerdo |  421 | 14.38 |   14.39 | 100.00\n    5 |          Totalmente de acuerdo |    0 |  0.00 |    0.00 | 100.00\n &lt;NA&gt; |                           &lt;NA&gt; |    1 |  0.03 |    &lt;NA&gt; |   &lt;NA&gt;\n\n\nCódigo\nfrq(proc_data$integracion)\n\n\nMe siento integrado en este barrio (x) &lt;numeric&gt; \n# total N=2927 valid N=2923 mean=2.57 sd=1.00\n\nValue |                          Label |    N | Raw % | Valid % | Cum. %\n------------------------------------------------------------------------\n    0 |                              0 |  109 |  3.72 |    3.73 |   3.73\n    1 |       Totalmente en desacuerdo |  436 | 14.90 |   14.92 |  18.65\n    2 |                  En desacuerdo |  408 | 13.94 |   13.96 |  32.60\n    3 | Ni de acuerdo ni en desacuerdo | 1633 | 55.79 |   55.87 |  88.47\n    4 |                     De acuerdo |  337 | 11.51 |   11.53 | 100.00\n    5 |          Totalmente de acuerdo |    0 |  0.00 |    0.00 | 100.00\n &lt;NA&gt; |                           &lt;NA&gt; |    4 |  0.14 |    &lt;NA&gt; |   &lt;NA&gt;\n\n\nCódigo\nfrq(proc_data$identificacion)\n\n\nMe identifico con la gente de este barrio (x) &lt;numeric&gt; \n# total N=2927 valid N=2923 mean=2.52 sd=0.99\n\nValue |                          Label |    N | Raw % | Valid % | Cum. %\n------------------------------------------------------------------------\n    0 |                              0 |  106 |  3.62 |    3.63 |   3.63\n    1 |       Totalmente en desacuerdo |  453 | 15.48 |   15.50 |  19.12\n    2 |                  En desacuerdo |  460 | 15.72 |   15.74 |  34.86\n    3 | Ni de acuerdo ni en desacuerdo | 1612 | 55.07 |   55.15 |  90.01\n    4 |                     De acuerdo |  292 |  9.98 |    9.99 | 100.00\n    5 |          Totalmente de acuerdo |    0 |  0.00 |    0.00 | 100.00\n &lt;NA&gt; |                           &lt;NA&gt; |    4 |  0.14 |    &lt;NA&gt; |   &lt;NA&gt;\n\n\nCódigo\nfrq(proc_data$pertenencia)\n\n\nMe siento parte de este barrio (x) &lt;numeric&gt; \n# total N=2927 valid N=2925 mean=2.63 sd=0.99\n\nValue |                          Label |    N | Raw % | Valid % | Cum. %\n------------------------------------------------------------------------\n    0 |                              0 |   91 |  3.11 |    3.11 |   3.11\n    1 |       Totalmente en desacuerdo |  422 | 14.42 |   14.43 |  17.54\n    2 |                  En desacuerdo |  362 | 12.37 |   12.38 |  29.91\n    3 | Ni de acuerdo ni en desacuerdo | 1660 | 56.71 |   56.75 |  86.67\n    4 |                     De acuerdo |  390 | 13.32 |   13.33 | 100.00\n    5 |          Totalmente de acuerdo |    0 |  0.00 |    0.00 | 100.00\n &lt;NA&gt; |                           &lt;NA&gt; |    2 |  0.07 |    &lt;NA&gt; |   &lt;NA&gt;\n\n\nVemos que los valores (labels) de cada categoría de las variables que recodificamos no se corresponden con el nuevo valor. Para re-etiquetar valores usamos la función set_labels, de la librería sjlabelled\n\n\nCódigo\nproc_data$ideal &lt;- set_labels(proc_data$ideal,\n            labels=c( \"Totalmente en desacuerdo\"=0,\n                      \"En desacuerdo\"=1,\n                      \"Ni de acuerdo ni en desacuerdo\"=2,\n                      \"De acuerdo\"=3,\n                      \"Totalmente de acuerdo\"=4))\n\nproc_data$integracion &lt;- set_labels(proc_data$integracion,\n            labels=c( \"Totalmente en desacuerdo\"=0,\n                      \"En desacuerdo\"=1,\n                      \"Ni de acuerdo ni en desacuerdo\"=2,\n                      \"De acuerdo\"=3,\n                      \"Totalmente de acuerdo\"=4))\n\nproc_data$identificacion &lt;- set_labels(proc_data$identificacion,\n            labels=c( \"Totalmente en desacuerdo\"=0,\n                      \"En desacuerdo\"=1,\n                      \"Ni de acuerdo ni en desacuerdo\"=2,\n                      \"De acuerdo\"=3,\n                      \"Totalmente de acuerdo\"=4))\n\nproc_data$pertenencia &lt;- set_labels(proc_data$pertenencia,\n            labels=c( \"Totalmente en desacuerdo\"=0,\n                      \"En desacuerdo\"=1,\n                      \"Ni de acuerdo ni en desacuerdo\"=2,\n                      \"De acuerdo\"=3,\n                      \"Totalmente de acuerdo\"=4))\n\n\ny volvemos a revisar\n\n\nCódigo\nfrq(proc_data$ideal)\n\n\nEste barrio es ideal para mi (x) &lt;numeric&gt; \n# total N=2927 valid N=2926 mean=2.62 sd=1.02\n\nValue |                          Label |    N | Raw % | Valid % | Cum. %\n------------------------------------------------------------------------\n    0 |       Totalmente en desacuerdo |  114 |  3.89 |    3.90 |   3.90\n    1 |                  En desacuerdo |  413 | 14.11 |   14.11 |  18.01\n    2 | Ni de acuerdo ni en desacuerdo |  379 | 12.95 |   12.95 |  30.96\n    3 |                     De acuerdo | 1599 | 54.63 |   54.65 |  85.61\n    4 |          Totalmente de acuerdo |  421 | 14.38 |   14.39 | 100.00\n &lt;NA&gt; |                           &lt;NA&gt; |    1 |  0.03 |    &lt;NA&gt; |   &lt;NA&gt;\n\n\nCódigo\nfrq(proc_data$pertenencia)\n\n\nMe siento parte de este barrio (x) &lt;numeric&gt; \n# total N=2927 valid N=2925 mean=2.63 sd=0.99\n\nValue |                          Label |    N | Raw % | Valid % | Cum. %\n------------------------------------------------------------------------\n    0 |       Totalmente en desacuerdo |   91 |  3.11 |    3.11 |   3.11\n    1 |                  En desacuerdo |  422 | 14.42 |   14.43 |  17.54\n    2 | Ni de acuerdo ni en desacuerdo |  362 | 12.37 |   12.38 |  29.91\n    3 |                     De acuerdo | 1660 | 56.71 |   56.75 |  86.67\n    4 |          Totalmente de acuerdo |  390 | 13.32 |   13.33 | 100.00\n &lt;NA&gt; |                           &lt;NA&gt; |    2 |  0.07 |    &lt;NA&gt; |   &lt;NA&gt;\n\n\n\n4.2. Educación\n\n[m01] = Nivel de estudios alcanzado - Entrevistado\n\na. Descriptivo\n\n\nCódigo\nfrq(proc_data$m01)\n\n\nNivel educacional (x) &lt;numeric&gt; \n# total N=2927 valid N=2925 mean=5.26 sd=2.20\n\nValue |                                       Label |   N | Raw % | Valid % | Cum. %\n------------------------------------------------------------------------------------\n    1 |                                Sin estudios |  37 |  1.26 |    1.26 |   1.26\n    2 |  Educacion Basica o Preparatoria incompleta | 322 | 11.00 |   11.01 |  12.27\n    3 |    Educacion Basica o Preparatoria completa | 297 | 10.15 |   10.15 |  22.43\n    4 |    Educacion Media o Humanidades incompleta | 394 | 13.46 |   13.47 |  35.90\n    5 |      Educacion Media o Humanidades completa | 857 | 29.28 |   29.30 |  65.20\n    6 |                 Tecnica Superior incompleta | 102 |  3.48 |    3.49 |  68.68\n    7 |                   Tecnica Superior completa | 381 | 13.02 |   13.03 |  81.71\n    8 |                    Universitaria incompleta | 186 |  6.35 |    6.36 |  88.07\n    9 |                      Universitaria completa | 303 | 10.35 |   10.36 |  98.43\n   10 | Estudios de posgrado (magister o doctorado) |  46 |  1.57 |    1.57 | 100.00\n &lt;NA&gt; |                                        &lt;NA&gt; |   2 |  0.07 |    &lt;NA&gt; |   &lt;NA&gt;\n\n\nEsta vez la vamos a dejar así\n\n\n\n4.3. Sexo\n\n[m0_sexo] = SEXO Sexo\n\na. Descriptivo\n\n\nCódigo\nfrq(proc_data$m0_sexo)\n\n\nSexo del entrevistado (x) &lt;numeric&gt; \n# total N=2927 valid N=2927 mean=1.60 sd=0.49\n\nValue |  Label |    N | Raw % | Valid % | Cum. %\n------------------------------------------------\n    1 | Hombre | 1163 | 39.73 |   39.73 |  39.73\n    2 |  Mujer | 1764 | 60.27 |   60.27 | 100.00\n &lt;NA&gt; |   &lt;NA&gt; |    0 |  0.00 |    &lt;NA&gt; |   &lt;NA&gt;\n\n\n\n\n4.4 Edad\n\n[m0_edad] = EDAD Edad.\n\na. Descriptivo\n\n\nCódigo\nsummary(proc_data$m0_edad)\n\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  18.00   33.00   46.00   46.09   58.00   88.00",
    "crumbs": [
      "Prácticos",
      "Talleres",
      "08: Resumen"
    ]
  },
  {
    "objectID": "practicos/resumen-content.html#generación-de-base-de-datos-procesada-para-el-análisis",
    "href": "practicos/resumen-content.html#generación-de-base-de-datos-procesada-para-el-análisis",
    "title": "Resumen",
    "section": "5. Generación de base de datos procesada para el análisis",
    "text": "5. Generación de base de datos procesada para el análisis\nAntes de guardar la base procesada, revisamos nuevamente todas las variables con una tabla descriptiva general mediante la función stargazer (de la librería homónima)\nPrimero vamos a reformatear el objeto proc_data como base de datos (as.data.frame), paso necesario para que sea reconocido como tal por stargazer\n\n\nCódigo\nproc_data &lt;-as.data.frame(proc_data)\nstargazer(proc_data, type=\"text\")\n\n\n\n============================================\nStatistic        N    Mean  St. Dev. Min Max\n--------------------------------------------\nideal          2,926 2.615   1.020    0   4 \nintegracion    2,923 2.566   0.999    0   4 \nidentificacion 2,923 2.524   0.988    0   4 \npertenencia    2,925 2.628   0.988    0   4 \nm01            2,925 5.261   2.202    1  10 \nm0_sexo        2,927 1.603   0.489    1   2 \nm0_edad        2,927 46.091  15.287  18  88 \n--------------------------------------------\n\n\n\nGuardar base de datos procesada: en carpeta local La ruta hacia su carpeta local si está trabajando en windows debería ser algo como “C:/Users/Lenovo/Clases/y aquí nombre del archivo a grabar\n\nEl comando para guardar es save:\n\n\nCódigo\nsave(proc_data,file = \"[ruta hacia carpeta local en su computador]/ELSOC_ess_merit2016.RData\")\n\n\nEn este caso, seguimos una estructura de carpetas de datos, separando en una carpeta los datos originales, y en otra (proc) los datos procesados:\n\n\nCódigo\nsave(proc_data,file = \"input/data/elsoc2016_proc.RData\")",
    "crumbs": [
      "Prácticos",
      "Talleres",
      "08: Resumen"
    ]
  },
  {
    "objectID": "syllabus.html",
    "href": "syllabus.html",
    "title": "Programa",
    "section": "",
    "text": "Kevin Carrasco\n   ?var:instructor.office\n   &lt;a href=“mailto:kevin.carrasco@ug.uchile.cl”&gt;kevin.carrasco@ug.uchile.cl\n   kevincarrascoq1\n\n\n\n\n\n   Martes\n   Marzo 12 - Julio 15 2024\n   16:00 a 17:20 y 17:30 a 18:50\n   Sala E67"
  },
  {
    "objectID": "syllabus.html#propósito-general-del-curso",
    "href": "syllabus.html#propósito-general-del-curso",
    "title": "Programa",
    "section": "Propósito general del curso",
    "text": "Propósito general del curso\nSe espera que al término del curso los y las estudiantes puedan elaborar y analizar diseños de investigación social de carácter cuantitativo, así como describir cuantitativamente un conjunto de datos utilizando el lenguaje R. En ese sentido, se profundizará el uso de R y la interfaz de RStudio para su uso en contextos académicos, así como el uso de otros sistemas de publicaciones como Quarto. Al mismo tiempo, el curso profundiza en temas relevantes para las ciencias sociales como el análisis estadístico, pero con un foco específico en la presentación de resultados (visualización de datos) a través de documentos dinámicos.\n\nObjetivos específicos\n\nConocer y aplicar instrumentos de medición y tipos de estudios cuantitativos.\nInterpretar y analizar los elementos centrales de una base de datos con información social.\nPresentar resultados a partir de la visualización de datos y construcción de documentos dinámicos en R (Quarto).\nAplicar, interpretar y visualizar técnicas de estadística descriptiva según las distintas características de los datos en R.\nAplicar e interpretar técnicas de estadística correlacional e inferencia estadística para muestras complejas en R.\nAplicar, interpretar y visualizar técnicas de regresión lineal y logística para variables numéricas y variables categóricas en R."
  },
  {
    "objectID": "syllabus.html#contenidos",
    "href": "syllabus.html#contenidos",
    "title": "Programa",
    "section": "Contenidos",
    "text": "Contenidos\n\nUnidad 1: Elementos y herramientas de R\n1.1 R enviroment: interfaz de RStudio, elementos de script, workspace\n1.2 Herramientas para la colaboración y comunicación: Rproject, GitHub, Zotero y Slack\n1.3 Protocolo IPO para la reproducibilidad de investigaciones sociales\n1.4 Construcción de reportes automáticos, reproducibles e integrados con código: Quarto\n\n\nUnidad 2: Operacionalización y análisis descriptivo de datos\n2.1 Operacionalización y niveles de medición\n2.2 Tidy data: unir, dividir, filtrar, ordenar y exportar datos en R\n2.3 Recodificación de variables: descriptivos básicos, casos perdidos, etiquetamiento de variables\n2.4 Agrupación de datos y construcción de variables a partir de datos existentes\n2.5 Tablas descriptivas y tablas de contingencia\n2.6 ggplot2: gráficos de barra, de caja, dispersión e histograma\n\n\nUnidad 3: Análisis estadístico inferencial en R\n3.1 Análisis bivariado: Correlación de Pearson y ANOVA\n3.2 Muestras complejas e inferencia estadística con survey y srvyr\n\n\nUnidad 4: Regresión lineal y regresión logística\n4.2 Regresiones lineales de mínimos cuadrados ordinarios\n4.3 Interpretación de coeficientes (variables cuantitativas y cualitativas)\n4.4 Aspectos básicos de regresión logística\n4.5 Representación gráfica de coeficientes de regresión lineal y logística (probabilidades predichas)"
  },
  {
    "objectID": "syllabus.html#metodología",
    "href": "syllabus.html#metodología",
    "title": "Programa",
    "section": "Metodología",
    "text": "Metodología\nSe tendrán tres espacios principales de aprendizaje:\n\nSesiones de clases lectivas, donde se presentarán los aspectos centrales de los contenidos correspondientes a la semana. Estas se desarrollarán en el primer bloque del martes.\nPrácticas guiadas: cada tema de las sesiones se acompaña de una guía práctica de aplicación de contenidos. Estas guías están diseñadas para ser desarrolladas de manera autónoma por cada estudiante semana a semana. También serán desarrolladas y revisadas cada semana por el profesor y/o ayudantes para dar mayor oportunidad de participación y resolver las dudas respectivas. Estas se desarrollan en el segundo bloque del martes.\nEvaluaciones: se desarrollarán trabajos periódicos que permitirán a las/os estudiantes aplicar contenidos y replicar lo aprendido en los prácticos en base a una base de datos seleccionada por ellas/os a inicio de semestre. Esto permitirá no solo recibir retroalimentación constante, sino que aprender con datos que puedan ser útiles para otros proyectos de investigación. Al finalizar el curso, el/la estudiante deberá entregar un proyecto de investigación que incluya todo el trabajo de estas tareas, así como la incorporación de comentarios y sugerencias de retroalimentación de las evaluaciones. Además, el/la estudiante deberá realizar una presentación de resultados en formato académico/conferencia.\n\nLas instrucciones de las tareas serán publicadas con una semana de anticipación a su entrega."
  },
  {
    "objectID": "syllabus.html#recursos-principales-de-aprendizaje-y-comunicación",
    "href": "syllabus.html#recursos-principales-de-aprendizaje-y-comunicación",
    "title": "Programa",
    "section": "Recursos principales de aprendizaje y comunicación",
    "text": "Recursos principales de aprendizaje y comunicación\n\nSitio web\n\nEl curso estará disponible en un sitio web programado por el docente, en tanto permite integrar texto y código de R.\n\nR, RStudio y RStudio Cloud\n\nEl software que se utilizará principalmente será R y su interfaz RStudio. Ahora bien, muchos usuario/as de R presentan problemas de instalación dada la capacidad de sus computadores y sistemas operativos. Por ello, para quienes tengan estos problemas se promoverá el uso del servicio gratuito de RStudio.cloud\n\nSlack\n\nSlack es una herramienta de uso frecuente en equipos de trabajo que utilizan R pues permite integrar script de distintos lenguajes en el chat. Se tendrá un espacio de trabajo en la app Slack que permite que cualquier persona del curso pueda hacer preguntas y cualquiera pueda responder. Esta es una de las prácticas que se promoverán en el curso pues es probable que los/as estudiantes tengan dudas similares a las de sus compañeros, por lo que las respuestas del docente, ayudantes y otros compañeros/as serán de libre disposición de todo el curso. Dentro de Slack se tendrán canales específicos para hacer preguntas sobre las sesiones, tareas y proyectos, y el link que permite unirse a este estará disponible en el sitio del curso.\n\nGitHub\n\nGithub es una plataforma online que permite depositar archivos y el control de versiones (VCS), por lo que se ha transformado en una herramienta fácil y popular para corregir, colaborar y compartir códigos de distintos lenguajes (no solo R). Utilizaremos esta plataforma para subir las tareas, ayudarlos/as de manera directa con su código y darles feedback."
  },
  {
    "objectID": "syllabus.html#evaluación-de-aprendizaje",
    "href": "syllabus.html#evaluación-de-aprendizaje",
    "title": "Programa",
    "section": "Evaluación de aprendizaje",
    "text": "Evaluación de aprendizaje\nLas evaluaciones del curso se componen de tareas (60% de la nota final), la entrega de una investigación (30% de la nota final) y una presentación (10% de la nota final), en dónde en todos los casos la/el estudiante deberá seleccionar datos y temas de interés de modo de acercar la aplicación del software a contextos de investigación propios de la/el estudiante. En concreto, cada evaluación consiste en:\n\nTrabajos (60% de la nota final): consisten en evaluaciones parciales temáticas que buscan poner en práctica los aprendizajes expuestos en la sesión de clases y herramientas reforzadas en los prácticos. Durante el semestre se realizarán 4 tareas (15% c/u).\nPresentación final (10% de la nota final): Consiste en una presentación final individual que resuma el trabajo realizado en el proyecto de investigación. Al tratarse de un curso metodológico, más que los fundamentos teóricos de la investigación, el foco de la presentación debe estar centrado en los resultados de la investigación (visualización de resultados) y en reflexiones de toma de decisiones metodológicas en términos de apertura y reproducibilidad.\nInvestigación final (examen) (30% de la nota final): consiste en una evaluación final individual que aplica los conocimientos y herramientas entregadas a lo largo del curso y en las tareas realizadas, a un proyecto de investigación de elección por el/la estudiante. Se espera que este proyecto incluya todo el trabajo de estas tareas, así como la incorporación de comentarios y sugerencias de retroalimentación de las evaluaciones."
  },
  {
    "objectID": "syllabus.html#información-general",
    "href": "syllabus.html#información-general",
    "title": "Programa",
    "section": "Información general",
    "text": "Información general\nLos/as alumnas/os que no se presenten o entreguen una evaluación por enfermedad deben hacer llegar el certificado médico a coordinación en el plazo establecido por el reglamento. Quienes no lo hagan serán evaluados con nota 1,0. Las pruebas atrasadas serán reprogramadas la primera semana de junio.\nNingún curso podrá ser aprobado si no cuenta con el mínimo del 70% de asistencia. Tendrán derecho a rendir los exámenes todos los/as estudiantes que hayan cumplido con la exigencia de asistencia mínima al curso y cuyo promedio de notas sea igual o superior a 3,5.\nLos/as estudiantes podrán eximirse de la obligación de rendir los exámenes finales de cada curso. Al iniciarse el semestre académico, cada profesor/a deberá indicar a los/as estudiantes en el programa del curso si existe la posibilidad de eximirse y bajo qué condiciones. Con todo, no será posible eximirse de examen alguno si el/a estudiante no tiene una nota promedio igual o superior a 5,5 y una asistencia igual o superior al 70% de las clases efectivamente realizadas en el respectivo curso."
  },
  {
    "objectID": "syllabus.html#reglamento-académico-del-estudiante-de-pregrado.",
    "href": "syllabus.html#reglamento-académico-del-estudiante-de-pregrado.",
    "title": "Programa",
    "section": "Reglamento Académico del Estudiante de Pregrado.",
    "text": "Reglamento Académico del Estudiante de Pregrado.\nArt. 23.- Cualquier conducta de un estudiante que tienda a viciar la evaluación de actividades académicas o que constituya fraude académico, figura que contempla irregularidades tales como copia, suplantación o alteración de evaluaciones, plagio, faltas a la ética profesional, sin que esta enumeración sea taxativa, dará origen a las siguientes sanciones, según la gravedad de la falta cometida: (i) nota mínima 1,0 (uno) en la respectiva evaluación; (ii) reprobación del curso respectivo; (iii) amonestación; (iv) permanencia condicional; (v) suspensión de actividades académicas por un período académico; (vi) expulsión de la Universidad.\nAsimismo, toda actividad de un estudiante que entorpezca gravemente y/o dificulte el normal desarrollo académico, podrá ser sancionada de conformidad a las disposiciones establecidas en el Reglamento de Conducta y Convivencia de la Universidad Alberto Hurtado.\nArt. 24.- Las dos primeras sanciones previstas en el artículo anterior, a saber (i) Nota mínima 1,0; y (ii) Reprobación del Curso respectivo, son prerrogativa del docente a cargo de la asignatura, quien deberá informarlas a la Dirección de la Carrera.\n***Para evitar el plagio todo trabajo, composición o material documental que los estudiantes realicen debe citar adecuadamente las fuentes utilizadas, ya sea a través del sistema APA (American Psychological Association) http://www.apastyle.org o MLA (Modern Language Association) http://www.mla.org/."
  }
]